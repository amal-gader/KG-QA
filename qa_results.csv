,Question,GT SPARQL,Generated SPARQL,BLEU,Jaccard,BERTScore,answer,gt_answer,metrics
0,Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9655172413793104,"(0.9834764003753662, 0.9826014637947083, 0.9830387830734253)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
1,List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Word Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Word Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9343348130467294,0.9615384615384616,"(0.9819260239601135, 0.9743067026138306, 0.9781014919281006)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130786'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Neural Sequence Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130803'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models with Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130852'}, 'paper_lbl': {'type': 'literal', 'value': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130871'}, 'paper_lbl': {'type': 'literal', 'value': 'Partially Shuffling the Training Data to Improve Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130890'}, 'paper_lbl': {'type': 'literal', 'value': 'Regularizing and Optimizing LSTM Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130909'}, 'paper_lbl': {'type': 'literal', 'value': 'Trellis Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130920'}, 'paper_lbl': {'type': 'literal', 'value': 'Fraternal Dropout'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130930'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Equilibrium Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130946'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Search with Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130962'}, 'paper_lbl': {'type': 'literal', 'value': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130975'}, 'paper_lbl': {'type': 'literal', 'value': 'An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131002'}, 'paper_lbl': {'type': 'literal', 'value': 'R-Transformer: Recurrent Neural Network Enhanced Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130601'}, 'paper_lbl': {'type': 'literal', 'value': 'Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129805'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Modeling via Adversarial Training'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130786'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Neural Sequence Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130803'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models with Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130852'}, 'paper_lbl': {'type': 'literal', 'value': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130871'}, 'paper_lbl': {'type': 'literal', 'value': 'Partially Shuffling the Training Data to Improve Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130890'}, 'paper_lbl': {'type': 'literal', 'value': 'Regularizing and Optimizing LSTM Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130909'}, 'paper_lbl': {'type': 'literal', 'value': 'Trellis Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130920'}, 'paper_lbl': {'type': 'literal', 'value': 'Fraternal Dropout'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130930'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Equilibrium Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130946'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Search with Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130962'}, 'paper_lbl': {'type': 'literal', 'value': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130975'}, 'paper_lbl': {'type': 'literal', 'value': 'An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131002'}, 'paper_lbl': {'type': 'literal', 'value': 'R-Transformer: Recurrent Neural Network Enhanced Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130601'}, 'paper_lbl': {'type': 'literal', 'value': 'Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129805'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Modeling via Adversarial Training'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
2,What models are being evaluated on the UrbanSound8k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UrbanSound8k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UrbanSound8k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.982176661491394, 0.9769747257232666, 0.9795687794685364)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122343'}, 'model_lbl': {'type': 'literal', 'value': 'SB-CNN aug'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122344'}, 'model_lbl': {'type': 'literal', 'value': 'SB-CNN noaug'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122343'}, 'model_lbl': {'type': 'literal', 'value': 'SB-CNN aug'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122344'}, 'model_lbl': {'type': 'literal', 'value': 'SB-CNN noaug'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
3,Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9607843137254902,"(0.9819803237915039, 0.9742938280105591, 0.9781219363212585)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129331'}, 'paper_lbl': {'type': 'literal', 'value': 'Generalizing Natural Language Analysis through Span-relation Representations'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129331'}, 'paper_lbl': {'type': 'literal', 'value': 'Generalizing Natural Language Analysis through Span-relation Representations'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
4,What is the top benchmark score and its metric on the MAZEA dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MAZEA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MAZEA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9829088449478149, 0.9808987379074097, 0.9819027781486511)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
5,What models are being evaluated on the TDMSci dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDMSci"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDMSci"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9822309017181396, 0.9768361449241638, 0.9795261025428772)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116717'}, 'model_lbl': {'type': 'literal', 'value': 'SciIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226756'}, 'model_lbl': {'type': 'literal', 'value': 'Flair-TDM'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116717'}, 'model_lbl': {'type': 'literal', 'value': 'SciIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226756'}, 'model_lbl': {'type': 'literal', 'value': 'Flair-TDM'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
6,What is the mean capacity of a carbon-based fuel?,"SELECT (AVG(?numerical_capacity) AS ?mean) 
WHERE {
  ?paper a orkgc:Paper;
         orkgp:P31 [
           orkgp:P15483 ?capacity
         ];
         rdfs:label ?title.
  BIND(
    xsd:double(
      REPLACE(
        STR(
          REPLACE(
            ?capacity,
            ""([0-9]+),([0-9]+)"",
            ""$1$2""
          )
        ),
        ""([0-9]+).*"",
        ""$1""
      ) 
    ) AS ?numerical_capacity
  )
  FILTER(REGEX(STR(?title), ""(fuel|CO2)""))
}","SELECT (AVG(?capacity_value) AS ?average_capacity_value)
WHERE {
  orkgr:R153801 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P43135 ?fuel_sources.
  ?fuel_sources rdfs:label ?fuel_sources_labels;
                  orkgp:P43136 ?capacity.
  FILTER(REGEX(?fuel_sources_labels, ""carbon-based""))
  ?capacity orkgp:HAS_VALUE ?value.
  BIND(xsd:float(?value) AS ?capacity_value)
}",3.595258534491728e-155,0.8055555555555556,"(0.8593724966049194, 0.8765783905982971, 0.8678901195526123)","[{'average_capacity_value': {'datatype': 'http://www.w3.org/2001/XMLSchema#double', 'type': 'literal', 'value': '0.0'}}]","[{'mean': {'datatype': 'http://www.w3.org/2001/XMLSchema#double', 'type': 'literal', 'value': '2857.3636363636365'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
7,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Russian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Russian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9636363636363636,"(0.9816900491714478, 0.9743434190750122, 0.9780029058456421)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131642'}, 'paper_lbl': {'type': 'literal', 'value': 'MultiFiT: Efficient Multi-lingual Language Model Fine-tuning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131658'}, 'paper_lbl': {'type': 'literal', 'value': 'A Corpus for Multilingual Document Classification in Eight Languages'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131694'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131718'}, 'paper_lbl': {'type': 'literal', 'value': 'Bridging the domain gap in cross-lingual document classification'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131642'}, 'paper_lbl': {'type': 'literal', 'value': 'MultiFiT: Efficient Multi-lingual Language Model Fine-tuning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131658'}, 'paper_lbl': {'type': 'literal', 'value': 'A Corpus for Multilingual Document Classification in Eight Languages'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131694'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131718'}, 'paper_lbl': {'type': 'literal', 'value': 'Bridging the domain gap in cross-lingual document classification'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
8,Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kuzushiji-MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kuzushiji-MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9666666666666668,"(0.9830747842788696, 0.9816679954528809, 0.982370913028717)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126100'}, 'model_lbl': {'type': 'literal', 'value': 'VGG8B(2x) + LocalLearning + CO'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126100'}, 'model_lbl': {'type': 'literal', 'value': 'VGG8B(2x) + LocalLearning + CO'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
9,Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Romanian-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Romanian-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9666666666666668,"(0.9825652241706848, 0.9811160564422607, 0.9818401336669922)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
10,"What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9689827775496296,0.9672131147540984,"(0.9820621013641357, 0.9814574718475342, 0.9817596673965454)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '959'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '959'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
11,What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9655172413793104,"(0.9823071956634521, 0.9809268116950989, 0.9816165566444397)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
12,What are the titles and IDs of research papers that include a benchmark for the arXiv dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""arXiv"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""arXiv"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9819304943084717, 0.9744428396224976, 0.9781723618507385)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131759'}, 'paper_lbl': {'type': 'literal', 'value': 'PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131759'}, 'paper_lbl': {'type': 'literal', 'value': 'PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
13,Can you list the metrics used to evaluate models on the TDM Tagged Corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDM Tagged Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TDM Tagged Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8981503502402635,0.9622641509433962,"(0.9803930521011353, 0.9748791456222534, 0.9776283502578735)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
14,Provide a list of research paper titles and IDs that have benchmarked models on the BC5CDR-disease dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9816900491714478, 0.9741960763931274, 0.9779286980628967)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
15,What is the name of the top performing model in terms of Score score when benchmarked on the Lunar Lander (OpenAI Gym) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Lunar Lander (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Lunar Lander (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9655172413793104,"(0.9835283756256104, 0.9817230701446533, 0.982624888420105)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
16,What evaluation metrics are commonly used when benchmarking models on the FSNS - Test dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8981503502402635,0.9622641509433962,"(0.9805922508239746, 0.9752985239028931, 0.9779382348060608)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114165'}, 'metric_lbl': {'type': 'literal', 'value': 'Sequence error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114165'}, 'metric_lbl': {'type': 'literal', 'value': 'Sequence error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
17,What are the titles and IDs of research papers that include a benchmark for the ImageNet 64x64 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9629629629629628,"(0.9816904067993164, 0.9742177724838257, 0.9779398441314697)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129926'}, 'paper_lbl': {'type': 'literal', 'value': 'Generating Long Sequences with Sparse Transformers'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129926'}, 'paper_lbl': {'type': 'literal', 'value': 'Generating Long Sequences with Sparse Transformers'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
18,"What are the metrics of evaluation over the Classical music, 5 seconds at 12 kHz dataset?","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9419661180380056,0.9655172413793104,"(0.9816387295722961, 0.9749853610992432, 0.9783007502555847)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121003'}, 'metric_lbl': {'type': 'literal', 'value': 'Bits per byte'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121003'}, 'metric_lbl': {'type': 'literal', 'value': 'Bits per byte'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
19,Provide a list of papers that have utilized the Flair-TDM model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Flair-TDM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Flair-TDM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9830144643783569, 0.9739124774932861, 0.9784423112869263)","[{'code': {'type': 'literal', 'value': 'https://github.com/davidjurgens/citation-function'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/davidjurgens/citation-function'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
20,Can you provide links to code used in papers that benchmark the Transformer-XL Base model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Transformer-XL Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Transformer-XL Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9818449020385742, 0.9724525809288025, 0.9771261811256409)","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/benkrause/dynamiceval-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cmunnis/BERT_vs_Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cedrickchee/pytorch-pretrained-BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/threelittlemonkeys/transformer-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/inzva/fake-academic-paper-generation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/nlp-attentions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sh951011/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TimDettmers/transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/okkteam/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/code-prediction-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxt1997/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/conformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn/tree/master/labml_nn/transformers/xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/transformer-xl'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/benkrause/dynamiceval-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cmunnis/BERT_vs_Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cedrickchee/pytorch-pretrained-BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/threelittlemonkeys/transformer-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/inzva/fake-academic-paper-generation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/nlp-attentions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sh951011/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TimDettmers/transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/okkteam/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/code-prediction-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxt1997/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/conformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn/tree/master/labml_nn/transformers/xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/transformer-xl'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
21,What is the best performing model benchmarking the BUCC German-to-English dataset in terms of F1 score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9655172413793104,"(0.9820001125335693, 0.9806634187698364, 0.9813312888145447)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
22,Provide a list of papers that have utilized the SAN (single) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAN (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAN (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9836001396179199, 0.9746967554092407, 0.9791281819343567)","[{'code': {'type': 'literal', 'value': 'https://github.com/lduml/blog'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Xaniar87/SAN_SQuAD2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yongbowin/san_mrc_annotation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/om00839/machine-suneung'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kevinduh/san_mrc'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/lduml/blog'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Xaniar87/SAN_SQuAD2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yongbowin/san_mrc_annotation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/om00839/machine-suneung'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kevinduh/san_mrc'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
23,What are the models that have been benchmarked on the ACE 2005 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACE 2005"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACE 2005"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9642857142857144,"(0.9818190336227417, 0.9765559434890747, 0.9791803956031799)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116615'}, 'model_lbl': {'type': 'literal', 'value': 'Table-Sequence'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116626'}, 'model_lbl': {'type': 'literal', 'value': 'Multi-turn QA'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116629'}, 'model_lbl': {'type': 'literal', 'value': 'SPTree'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116630'}, 'model_lbl': {'type': 'literal', 'value': 'DYGIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116638'}, 'model_lbl': {'type': 'literal', 'value': 'DYGIE++'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116645'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence ALB'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116615'}, 'model_lbl': {'type': 'literal', 'value': 'Table-Sequence'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116626'}, 'model_lbl': {'type': 'literal', 'value': 'Multi-turn QA'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116629'}, 'model_lbl': {'type': 'literal', 'value': 'SPTree'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116630'}, 'model_lbl': {'type': 'literal', 'value': 'DYGIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116638'}, 'model_lbl': {'type': 'literal', 'value': 'DYGIE++'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116645'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence ALB'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
24,Where can I find code references in papers that have used the PNDec model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PNDec"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PNDec"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.983248770236969, 0.9741892218589783, 0.9786980152130127)","[{'code': {'type': 'literal', 'value': 'https://github.com/nusnlp/PtrNetDecoding4JERE'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/nusnlp/PtrNetDecoding4JERE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
25,Where can I find code references in papers that have used the CATTS-XSUM model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CATTS-XSUM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CATTS-XSUM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9825853109359741, 0.9730203151702881, 0.9777794480323792)","[{'code': {'type': 'literal', 'value': 'https://github.com/allenai/scitldr'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/allenai/scitldr'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
26,What is the top benchmark result (metric and value) over the dataset IMDb-B?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9819406270980835, 0.9799405336380005, 0.9809395670890808)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '71.46%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '71.46%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
27,What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot German-to-French?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot German-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot German-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9666666666666668,"(0.9802640676498413, 0.9800904393196106, 0.9801772236824036)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '75.45'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '75.45'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
28,Where can I find code references in papers that have used the SemExp model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SemExp"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SemExp"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9839426279067993, 0.9752280712127686, 0.9795659780502319)","[{'code': {'type': 'literal', 'value': 'https://github.com/devendrachaplot/Object-Goal-Navigation'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/devendrachaplot/Object-Goal-Navigation'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
29,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Up and Down dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9383861709333506,0.9642857142857144,"(0.9824631214141846, 0.9760634899139404, 0.9792528748512268)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
30,What is the name of the top performing model in terms of Number of params score when benchmarked on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9674687404175402,0.9649122807017544,"(0.9823681116104126, 0.9810054302215576, 0.9816862940788269)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120924'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-4'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120924'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-4'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
31,Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9343348130467294,0.9615384615384616,"(0.9819121956825256, 0.9743461012840271, 0.9781145453453064)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131085'}, 'paper_lbl': {'type': 'literal', 'value': 'Discrete Flows: Invertible Generative Models of Discrete Data'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130909'}, 'paper_lbl': {'type': 'literal', 'value': 'Trellis Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130946'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Search with Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130975'}, 'paper_lbl': {'type': 'literal', 'value': 'An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131002'}, 'paper_lbl': {'type': 'literal', 'value': 'R-Transformer: Recurrent Neural Network Enhanced Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130545'}, 'paper_lbl': {'type': 'literal', 'value': 'Addressing Some Limitations of Transformers with Feedback Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130712'}, 'paper_lbl': {'type': 'literal', 'value': 'An Analysis of Neural Language Modeling at Multiple Scales'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130749'}, 'paper_lbl': {'type': 'literal', 'value': 'Fast-Slow Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130777'}, 'paper_lbl': {'type': 'literal', 'value': 'HyperNetworks'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131085'}, 'paper_lbl': {'type': 'literal', 'value': 'Discrete Flows: Invertible Generative Models of Discrete Data'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130909'}, 'paper_lbl': {'type': 'literal', 'value': 'Trellis Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130946'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Search with Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130975'}, 'paper_lbl': {'type': 'literal', 'value': 'An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131002'}, 'paper_lbl': {'type': 'literal', 'value': 'R-Transformer: Recurrent Neural Network Enhanced Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130545'}, 'paper_lbl': {'type': 'literal', 'value': 'Addressing Some Limitations of Transformers with Feedback Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130712'}, 'paper_lbl': {'type': 'literal', 'value': 'An Analysis of Neural Language Modeling at Multiple Scales'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130749'}, 'paper_lbl': {'type': 'literal', 'value': 'Fast-Slow Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130777'}, 'paper_lbl': {'type': 'literal', 'value': 'HyperNetworks'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
32,What are the metrics of evaluation over the Atari 2600 Double Dunk dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.9014996327760888,0.9642857142857144,"(0.9813137650489807, 0.9759019017219543, 0.9786003828048706)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
33,Which model has achieved the highest Top 1 Accuracy score on the ImageNet V2 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top 1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top 1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9655172413793104,"(0.9809311628341675, 0.9796520471572876, 0.9802911877632141)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126097'}, 'model_lbl': {'type': 'literal', 'value': 'CAIT-M36-448'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126097'}, 'model_lbl': {'type': 'literal', 'value': 'CAIT-M36-448'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
34,What is the most common Knowledge representation method?,"SELECT (COUNT(?repr) AS ?cnt) ?repr
WHERE {
  orkgr:R8364 orkgp:compareContribution ?cont.
  ?cont orkgp:P7046 ?sys.
  ?sys orkgp:P7056 ?repr.
}
GROUP BY ?repr
ORDER BY DESC(?cnt)
LIMIT 1","SELECT ?method (COUNT(?dataset) AS ?count)
WHERE {
  ?dataset a orkgc:Dataset.
  ?dataset orkgp:USES_KNOWLEDGE_REPRESENTATION_METHOD ?method.
}
GROUP BY ?method
ORDER BY DESC(?count)
LIMIT 1",3.0390702359534887e-78,0.711864406779661,"(0.8905354738235474, 0.8720377683639526, 0.8811895847320557)",[],"[{'cnt': {'datatype': 'http://www.w3.org/2001/XMLSchema#integer', 'type': 'literal', 'value': '3'}, 'repr': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R5048'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
35,Where can all the data sets used in the compared studies be found?,"SELECT DISTINCT ?URL
WHERE {
  orkgr:R112387 orkgp:compareContribution ?contrib.
  ?contrib orkgp:HAS_DATASET ?URL.
  FILTER(!REGEX(?URL, ""Not""))
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?dataset   rdfs:label ?dataset_lbl.
}",7.293108985295422e-155,0.5818181818181818,"(0.8557394742965698, 0.8487162590026855, 0.852213442325592)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111484'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM40'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111483'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM20'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111555'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM60'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111557'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM100'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111556'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM80'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R162694'}, 'dataset_lbl': {'type': 'literal', 'value': 'CommonsenseQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R163852'}, 'dataset_lbl': {'type': 'literal', 'value': 'Visual Event Classification Dataset (VisE-D)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114259'}, 'dataset_lbl': {'type': 'literal', 'value': 'nuScenes'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159414'}, 'dataset_lbl': {'type': 'literal', 'value': 'OpenML (Adult, Letter, Higgs, MNIST, Optdigits, Poker)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159415'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cifar A'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159416'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cifar B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159417'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cifar C'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159418'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cifar-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159419'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cifar-100'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159420'}, 'dataset_lbl': {'type': 'literal', 'value': ' ImageNet16-120'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R159421'}, 'dataset_lbl': {'type': 'literal', 'value': 'UCI regression datasets (Protein Structure, Slice Localization, Naval Propulsion, Parkinsons Telemonitoring)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R157441'}, 'dataset_lbl': {'type': 'literal', 'value': 'Primarily ImageNet. But also other datasets like CIFAR-10 and CIFAR-100 for additional experiments.'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R171890'}, 'dataset_lbl': {'type': 'literal', 'value': 'SOCIAL IQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R151106'}, 'dataset_lbl': {'type': 'literal', 'value': '69'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R151109'}, 'dataset_lbl': {'type': 'literal', 'value': '69'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R151113'}, 'dataset_lbl': {'type': 'literal', 'value': '69'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R148633'}, 'dataset_lbl': {'type': 'literal', 'value': '69'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R151118'}, 'dataset_lbl': {'type': 'literal', 'value': '69'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147683'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147684'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147686'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147685'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116789'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116792'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-100'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121347'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126694'}, 'dataset_lbl': {'type': 'literal', 'value': 'SVHN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117710'}, 'dataset_lbl': {'type': 'literal', 'value': 'Fashion-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126717'}, 'dataset_lbl': {'type': 'literal', 'value': 'Flowers-102'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123801'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford-IIIT Pets'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126249'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet ReaL'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126722'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2018'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117830'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford 102 Flowers'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117682'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Cars'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119383'}, 'dataset_lbl': {'type': 'literal', 'value': 'CUB-200-2011'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117572'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Dogs'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123732'}, 'dataset_lbl': {'type': 'literal', 'value': 'FGVC Aircraft'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123808'}, 'dataset_lbl': {'type': 'literal', 'value': 'Food-101'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128070'}, 'dataset_lbl': {'type': 'literal', 'value': 'PWC Leaderboards (restricted)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128074'}, 'dataset_lbl': {'type': 'literal', 'value': 'NLP-TDMS (Exp, arXiv only)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125972'}, 'dataset_lbl': {'type': 'literal', 'value': 'Classic'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125973'}, 'dataset_lbl': {'type': 'literal', 'value': 'Recipe'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114586'}, 'dataset_lbl': {'type': 'literal', 'value': 'Twitter'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125974'}, 'dataset_lbl': {'type': 'literal', 'value': 'WOS-11967'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125977'}, 'dataset_lbl': {'type': 'literal', 'value': 'WOS-5736'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125978'}, 'dataset_lbl': {'type': 'literal', 'value': 'WOS-46985'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125979'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reuters De-En'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125982'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reuters En-De'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126031'}, 'dataset_lbl': {'type': 'literal', 'value': 'VTAB-1k'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126667'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet (Bounding Box)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126744'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126080'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2019'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126096'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet V2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126098'}, 'dataset_lbl': {'type': 'literal', 'value': 'Kuzushiji-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114182'}, 'dataset_lbl': {'type': 'literal', 'value': 'MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117736'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126855'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10, 1000 Labels'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126832'}, 'dataset_lbl': {'type': 'literal', 'value': 'Birdsnap'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124962'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Zaxxon'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124963'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Assault'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124964'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Demon Attack'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124965'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 River Raid'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124966'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Amidar'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124967'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Asteroids'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124969'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Krull'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124970'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Beam Rider'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124971'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Freeway'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124981'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Alien'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124982'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Enduro'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124984'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Fishing Derby'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124986'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Venture'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124989'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Time Pilot'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124990'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Bank Heist'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124991'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Kangaroo'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124992'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Up and Down'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124993'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Wizard of Wor'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124994'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Asterix'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124998'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Ice Hockey'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124999'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Tutankham'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125000'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Tennis'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125005'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Frostbite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125007'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Private Eye'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125009'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Bowling'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125010'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Battle Zone'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125011'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Road Runner'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125013'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Boxing'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125014'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Space Invaders'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125019'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Q*Bert'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125021'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Video Pinball'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125022'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Chopper Command'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125023'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Star Gunner'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125024'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Gravitar'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125025'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Robotank'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124885'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Seaquest'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124930'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Crazy Climber'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124954'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Pong'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124955'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Breakout'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125012'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Phoenix'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124947'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Ms. Pacman'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125015'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 James Bond'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124933'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Double Dunk'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124957'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Centipede'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124959'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Atlantis'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124960'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Berzerk'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124995'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Defender'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124935'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari-57'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124968'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Kung-Fu Master'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124988'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Skiing'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125016'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 HERO'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125001'}, 'dataset_lbl': {'type': 'literal', 'value': ""Atari 2600 Montezuma's Revenge""}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124951'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Pitfall!'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124983'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Solaris'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124996'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Yars Revenge'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114616'}, 'dataset_lbl': {'type': 'literal', 'value': 'IMDb'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119113'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reuters-21578'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123966'}, 'dataset_lbl': {'type': 'literal', 'value': 'AAPD'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125981'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-14'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125943'}, 'dataset_lbl': {'type': 'literal', 'value': 'Ohsumed'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117241'}, 'dataset_lbl': {'type': 'literal', 'value': '20NEWS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125964'}, 'dataset_lbl': {'type': 'literal', 'value': 'BBCSport'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114568'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128146'}, 'dataset_lbl': {'type': 'literal', 'value': 'MUTAG'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128180'}, 'dataset_lbl': {'type': 'literal', 'value': 'REDDIT-B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125965'}, 'dataset_lbl': {'type': 'literal', 'value': 'IMDb-M'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128189'}, 'dataset_lbl': {'type': 'literal', 'value': 'PROTEINS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128199'}, 'dataset_lbl': {'type': 'literal', 'value': 'IMDb-B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124928'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Name This Game'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124929'}, 'dataset_lbl': {'type': 'literal', 'value': 'Atari 2600 Gopher'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123802'}, 'dataset_lbl': {'type': 'literal', 'value': 'CINIC-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123819'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-10 Image Classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123828'}, 'dataset_lbl': {'type': 'literal', 'value': 'DTD'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124045'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reuters RCV1/RCV2 English-to-German'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124049'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reuters RCV1/RCV2 German-to-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124050'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-Japanese'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124054'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-German'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124058'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-Spanish'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124060'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-Russian'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124061'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-Chinese'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124062'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-French'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124063'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot English-to-Italian'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124057'}, 'dataset_lbl': {'type': 'literal', 'value': 'MLDoc Zero-Shot German-to-French'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127150'}, 'dataset_lbl': {'type': 'literal', 'value': 'BUCC German-to-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127153'}, 'dataset_lbl': {'type': 'literal', 'value': 'BUCC French-to-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127154'}, 'dataset_lbl': {'type': 'literal', 'value': 'BUCC Chinese-to-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127155'}, 'dataset_lbl': {'type': 'literal', 'value': 'BUCC Russian-to-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121069'}, 'dataset_lbl': {'type': 'literal', 'value': 'BIOSSES'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121068'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedSTS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124625'}, 'dataset_lbl': {'type': 'literal', 'value': 'Barabasi-Albert'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114581'}, 'dataset_lbl': {'type': 'literal', 'value': 'FB15k'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114519'}, 'dataset_lbl': {'type': 'literal', 'value': 'Pubmed'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124736'}, 'dataset_lbl': {'type': 'literal', 'value': 'arXiv'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124737'}, 'dataset_lbl': {'type': 'literal', 'value': 'GigaWord'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124775'}, 'dataset_lbl': {'type': 'literal', 'value': 'AESLC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119716'}, 'dataset_lbl': {'type': 'literal', 'value': 'CNN / Daily Mail'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124725'}, 'dataset_lbl': {'type': 'literal', 'value': 'X-Sum'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124758'}, 'dataset_lbl': {'type': 'literal', 'value': 'CL-SciSumm'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121022'}, 'dataset_lbl': {'type': 'literal', 'value': 'WikiText-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121031'}, 'dataset_lbl': {'type': 'literal', 'value': 'Penn Treebank (Character Level)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121041'}, 'dataset_lbl': {'type': 'literal', 'value': 'Text8'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121351'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cornell Grasp Dataset'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121359'}, 'dataset_lbl': {'type': 'literal', 'value': ' Jacquard dataset'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121391'}, 'dataset_lbl': {'type': 'literal', 'value': 'TempEval-3'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122332'}, 'dataset_lbl': {'type': 'literal', 'value': 'AudioSet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127290'}, 'dataset_lbl': {'type': 'literal', 'value': 'ModelNet40'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122340'}, 'dataset_lbl': {'type': 'literal', 'value': 'ESC-50'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122342'}, 'dataset_lbl': {'type': 'literal', 'value': 'UrbanSound8k'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122621'}, 'dataset_lbl': {'type': 'literal', 'value': 'SST-5 Fine-grained classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122719'}, 'dataset_lbl': {'type': 'literal', 'value': 'SST-2 Binary classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125923'}, 'dataset_lbl': {'type': 'literal', 'value': 'TREC-6'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122689'}, 'dataset_lbl': {'type': 'literal', 'value': 'MPQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123292'}, 'dataset_lbl': {'type': 'literal', 'value': 'Finger, spin (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123294'}, 'dataset_lbl': {'type': 'literal', 'value': 'Ball in cup, catch (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123295'}, 'dataset_lbl': {'type': 'literal', 'value': 'Walker, walk (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123310'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reacher, easy (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123319'}, 'dataset_lbl': {'type': 'literal', 'value': 'Finger, spin (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123329'}, 'dataset_lbl': {'type': 'literal', 'value': 'Reacher, easy (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123342'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cartpole, swingup (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123344'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cheetah, run (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123347'}, 'dataset_lbl': {'type': 'literal', 'value': 'Ball in cup, catch (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123348'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cheetah, run (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123359'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cartpole, swingup (DMControl100k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123364'}, 'dataset_lbl': {'type': 'literal', 'value': 'Walker, walk (DMControl500k)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123333'}, 'dataset_lbl': {'type': 'literal', 'value': 'Lunar Lander (OpenAI Gym)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123346'}, 'dataset_lbl': {'type': 'literal', 'value': 'Cart Pole (OpenAI Gym)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123467'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Point Nav test-std'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123476'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Object Nav test-std'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123480'}, 'dataset_lbl': {'type': 'literal', 'value': 'Gibson PointGoal Navigation'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123487'}, 'dataset_lbl': {'type': 'literal', 'value': 'Dmlab-30'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120909'}, 'dataset_lbl': {'type': 'literal', 'value': 'Hutter Prize'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120926'}, 'dataset_lbl': {'type': 'literal', 'value': 'Penn Treebank (Word Level)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120966'}, 'dataset_lbl': {'type': 'literal', 'value': 'WikiText-103'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116334'}, 'dataset_lbl': {'type': 'literal', 'value': 'Penn Treebank'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127024'}, 'dataset_lbl': {'type': 'literal', 'value': 'Sequential CIFAR-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128449'}, 'dataset_lbl': {'type': 'literal', 'value': 'Nottingham'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127014'}, 'dataset_lbl': {'type': 'literal', 'value': 'Sequential MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121029'}, 'dataset_lbl': {'type': 'literal', 'value': 'enwiki8'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122149'}, 'dataset_lbl': {'type': 'literal', 'value': 'MRPC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120246'}, 'dataset_lbl': {'type': 'literal', 'value': 'One Billion Word'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120286'}, 'dataset_lbl': {'type': 'literal', 'value': 'Rotowire (Content Selection)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120298'}, 'dataset_lbl': {'type': 'literal', 'value': 'RotoWire (Relation Generation)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120301'}, 'dataset_lbl': {'type': 'literal', 'value': 'RotoWire (Content Ordering)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120303'}, 'dataset_lbl': {'type': 'literal', 'value': 'RotoWire'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120580'}, 'dataset_lbl': {'type': 'literal', 'value': 'OpenBookQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119541'}, 'dataset_lbl': {'type': 'literal', 'value': 'CommonsenseQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120873'}, 'dataset_lbl': {'type': 'literal', 'value': 'enwik8'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119751'}, 'dataset_lbl': {'type': 'literal', 'value': 'Natural Questions (long)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119479'}, 'dataset_lbl': {'type': 'literal', 'value': 'Natural Questions'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119565'}, 'dataset_lbl': {'type': 'literal', 'value': 'SQuAD1.1 dev'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119654'}, 'dataset_lbl': {'type': 'literal', 'value': 'SQuAD1.1'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119758'}, 'dataset_lbl': {'type': 'literal', 'value': 'SQuAD2.0'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120656'}, 'dataset_lbl': {'type': 'literal', 'value': 'Supervised:'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120776'}, 'dataset_lbl': {'type': 'literal', 'value': 'SNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122117'}, 'dataset_lbl': {'type': 'literal', 'value': 'OntoNotes'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122914'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoNLL++'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122925'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoNLL 2003 (English)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125991'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127900'}, 'dataset_lbl': {'type': 'literal', 'value': 'PolyAI Reddit'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119645'}, 'dataset_lbl': {'type': 'literal', 'value': 'TriviaQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117257'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2014 English-German'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117245'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2014 German-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117125'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2014 English-French'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117250'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 German-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117193'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2014 French-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117303'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 English-German'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117312'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 Romanian-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117220'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 English-Romanian'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119459'}, 'dataset_lbl': {'type': 'literal', 'value': 'DROP Test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119491'}, 'dataset_lbl': {'type': 'literal', 'value': 'MultiRC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119496'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119507'}, 'dataset_lbl': {'type': 'literal', 'value': 'BoolQ'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119611'}, 'dataset_lbl': {'type': 'literal', 'value': 'WebQuestions'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119629'}, 'dataset_lbl': {'type': 'literal', 'value': 'COPA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119651'}, 'dataset_lbl': {'type': 'literal', 'value': 'Story Cloze Test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119739'}, 'dataset_lbl': {'type': 'literal', 'value': 'QuAC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119130'}, 'dataset_lbl': {'type': 'literal', 'value': 'RACE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120577'}, 'dataset_lbl': {'type': 'literal', 'value': 'ARC (Challenge)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120578'}, 'dataset_lbl': {'type': 'literal', 'value': 'PIQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120582'}, 'dataset_lbl': {'type': 'literal', 'value': 'ARC (Easy)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120663'}, 'dataset_lbl': {'type': 'literal', 'value': 'Words in Context'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120726'}, 'dataset_lbl': {'type': 'literal', 'value': 'RTE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120746'}, 'dataset_lbl': {'type': 'literal', 'value': 'CommitmentBank'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120905'}, 'dataset_lbl': {'type': 'literal', 'value': 'LAMBADA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120590'}, 'dataset_lbl': {'type': 'literal', 'value': 'Winograd Schema Challenge'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124257'}, 'dataset_lbl': {'type': 'literal', 'value': 'WSC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119425'}, 'dataset_lbl': {'type': 'literal', 'value': 'Hendrycks Test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120747'}, 'dataset_lbl': {'type': 'literal', 'value': 'ANLI test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121002'}, 'dataset_lbl': {'type': 'literal', 'value': 'The Pile'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117685'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet 64x64'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126023'}, 'dataset_lbl': {'type': 'literal', 'value': 'Classical music, 5 seconds at 12 kHz'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119437'}, 'dataset_lbl': {'type': 'literal', 'value': 'Quasart-T'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119452'}, 'dataset_lbl': {'type': 'literal', 'value': 'Natural Questions (short)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119792'}, 'dataset_lbl': {'type': 'literal', 'value': 'SearchQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118532'}, 'dataset_lbl': {'type': 'literal', 'value': 'Multimodal PISA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118766'}, 'dataset_lbl': {'type': 'literal', 'value': 'HMDB51 (finetuned)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118363'}, 'dataset_lbl': {'type': 'literal', 'value': 'Kinetics-600'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118775'}, 'dataset_lbl': {'type': 'literal', 'value': 'UCF101 (finetuned)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118776'}, 'dataset_lbl': {'type': 'literal', 'value': 'HMDB51'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118612'}, 'dataset_lbl': {'type': 'literal', 'value': 'UCF101'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122338'}, 'dataset_lbl': {'type': 'literal', 'value': 'DCASE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120850'}, 'dataset_lbl': {'type': 'literal', 'value': 'WNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122670'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Fine-grained classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122706'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Binary classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123632'}, 'dataset_lbl': {'type': 'literal', 'value': 'ClueWeb09-B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125894'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125897'}, 'dataset_lbl': {'type': 'literal', 'value': 'DBpedia'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116787'}, 'dataset_lbl': {'type': 'literal', 'value': 'AG News'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125913'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125919'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-5'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116370'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-5'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119620'}, 'dataset_lbl': {'type': 'literal', 'value': 'Quora Question Pairs'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119742'}, 'dataset_lbl': {'type': 'literal', 'value': 'SQuAD2.0 dev'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120730'}, 'dataset_lbl': {'type': 'literal', 'value': 'MultiNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120855'}, 'dataset_lbl': {'type': 'literal', 'value': 'QNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122130'}, 'dataset_lbl': {'type': 'literal', 'value': 'STS Benchmark'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116782'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoLA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122141'}, 'dataset_lbl': {'type': 'literal', 'value': 'SentEval'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117054'}, 'dataset_lbl': {'type': 'literal', 'value': '200k Short Texts for Humor Detection'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116694'}, 'dataset_lbl': {'type': 'literal', 'value': 'NYT-single'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116582'}, 'dataset_lbl': {'type': 'literal', 'value': 'TACRED'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128520'}, 'dataset_lbl': {'type': 'literal', 'value': 'Open Entity'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116687'}, 'dataset_lbl': {'type': 'literal', 'value': 'SemEval-2010 Task 8'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116604'}, 'dataset_lbl': {'type': 'literal', 'value': 'NYT29'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116704'}, 'dataset_lbl': {'type': 'literal', 'value': 'NYT24'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116608'}, 'dataset_lbl': {'type': 'literal', 'value': 'NYT'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116613'}, 'dataset_lbl': {'type': 'literal', 'value': 'DuIE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122887'}, 'dataset_lbl': {'type': 'literal', 'value': 'NCBI-disease'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122958'}, 'dataset_lbl': {'type': 'literal', 'value': 'BC5CDR'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125985'}, 'dataset_lbl': {'type': 'literal', 'value': 'Paper Field'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125993'}, 'dataset_lbl': {'type': 'literal', 'value': 'ScienceCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127779'}, 'dataset_lbl': {'type': 'literal', 'value': 'EBM-NLP'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116681'}, 'dataset_lbl': {'type': 'literal', 'value': 'ChemProt'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116695'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciERC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122283'}, 'dataset_lbl': {'type': 'literal', 'value': 'GENIA - UAS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122302'}, 'dataset_lbl': {'type': 'literal', 'value': 'GENIA - LAS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116611'}, 'dataset_lbl': {'type': 'literal', 'value': 'JNLPBA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125986'}, 'dataset_lbl': {'type': 'literal', 'value': 'PubMed 20k RCT'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125988'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116614'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoNLL04'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116627'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACE 2004'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116636'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACE 2005'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116696'}, 'dataset_lbl': {'type': 'literal', 'value': 'ADE Corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116702'}, 'dataset_lbl': {'type': 'literal', 'value': 'WLPC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116678'}, 'dataset_lbl': {'type': 'literal', 'value': 'GAD'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116705'}, 'dataset_lbl': {'type': 'literal', 'value': 'DDI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119467'}, 'dataset_lbl': {'type': 'literal', 'value': 'PubMedQA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119490'}, 'dataset_lbl': {'type': 'literal', 'value': 'BioASQ'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122891'}, 'dataset_lbl': {'type': 'literal', 'value': 'BC5CDR-chemical'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122912'}, 'dataset_lbl': {'type': 'literal', 'value': 'BC2GM'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122954'}, 'dataset_lbl': {'type': 'literal', 'value': 'BC5CDR-disease'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122956'}, 'dataset_lbl': {'type': 'literal', 'value': 'NCBI Disease'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125976'}, 'dataset_lbl': {'type': 'literal', 'value': 'HoC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121401'}, 'dataset_lbl': {'type': 'literal', 'value': 'DDI extraction 2013 corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120774'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123000'}, 'dataset_lbl': {'type': 'literal', 'value': 'ShARe/CLEF eHealth corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117119'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 English-Russian'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117194'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 English-Czech'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117310'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 Russian-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117311'}, 'dataset_lbl': {'type': 'literal', 'value': 'WMT2016 Czech-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117205'}, 'dataset_lbl': {'type': 'literal', 'value': 'IWSLT2014 German-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117316'}, 'dataset_lbl': {'type': 'literal', 'value': 'IWSLT2015 English-German'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117285'}, 'dataset_lbl': {'type': 'literal', 'value': 'IWSLT2015 German-English'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114163'}, 'dataset_lbl': {'type': 'literal', 'value': 'FSNS - Test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122123'}, 'dataset_lbl': {'type': 'literal', 'value': 'CoNLL 2012'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116573'}, 'dataset_lbl': {'type': 'literal', 'value': 'WebNLG'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R108740'}, 'dataset_lbl': {'type': 'literal', 'value': 'seel.cse.lsu.edu/data/refsq17.zip'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R108123'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yes'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R108767'}, 'dataset_lbl': {'type': 'literal', 'value': 'seel.cse.lsu.edu/data/re17.zip '}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111275'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111304'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111257'}, 'dataset_lbl': {'type': 'literal', 'value': 'Set'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R112195'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R112199'}, 'dataset_lbl': {'type': 'literal', 'value': 'EmpiricalData'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R171913'}, 'dataset_lbl': {'type': 'literal', 'value': 'STORYCS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R186391'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM-50'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R187541'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM(1,0)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R187492'}, 'dataset_lbl': {'type': 'literal', 'value': 'GALEN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R188816'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM-160'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R188822'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM-160'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R198290'}, 'dataset_lbl': {'type': 'literal', 'value': 'LUBM-10240'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R212127'}, 'dataset_lbl': {'type': 'literal', 'value': 'Fruithut'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R212120'}, 'dataset_lbl': {'type': 'literal', 'value': 'Chainstore'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R212017'}, 'dataset_lbl': {'type': 'literal', 'value': 'V2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R212021'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACM'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R212012'}, 'dataset_lbl': {'type': 'literal', 'value': 'V1'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R219097'}, 'dataset_lbl': {'type': 'literal', 'value': 'Multimodal Event Representation'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R164005'}, 'dataset_lbl': {'type': 'literal', 'value': 'SoMeSci'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206327'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciFACT'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R146855'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciREX'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R223113'}, 'dataset_lbl': {'type': 'literal', 'value': 'Car speed in Liuliqiao District, Beijing'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206389'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciTLDR'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R146083'}, 'dataset_lbl': {'type': 'literal', 'value': 'FTD dataset'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R75321'}, 'dataset_lbl': {'type': 'literal', 'value': 'SemEval-2021 Task 11'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R69289'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciERC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R149721'}, 'dataset_lbl': {'type': 'literal', 'value': 'TDM Tagged Corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147087'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL Anthology'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206393'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciGEN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R217582'}, 'dataset_lbl': {'type': 'literal', 'value': 'smallNLP-KG'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R69283'}, 'dataset_lbl': {'type': 'literal', 'value': 'ScienceIE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R207044'}, 'dataset_lbl': {'type': 'literal', 'value': 'Annotated development corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R146874'}, 'dataset_lbl': {'type': 'literal', 'value': 'ARC-PDN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147659'}, 'dataset_lbl': {'type': 'literal', 'value': 'AAN Corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R146359'}, 'dataset_lbl': {'type': 'literal', 'value': 'STEM-ECR v1.0'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R69286'}, 'dataset_lbl': {'type': 'literal', 'value': 'OA-STM'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R146718'}, 'dataset_lbl': {'type': 'literal', 'value': 'AI-KG'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R149711'}, 'dataset_lbl': {'type': 'literal', 'value': 'ORKG-TDM'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206415'}, 'dataset_lbl': {'type': 'literal', 'value': 'MAZEA'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R207016'}, 'dataset_lbl': {'type': 'literal', 'value': 'ART/CoreSC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206399'}, 'dataset_lbl': {'type': 'literal', 'value': 'CS-NER'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206412'}, 'dataset_lbl': {'type': 'literal', 'value': 'CORLL'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R145759'}, 'dataset_lbl': {'type': 'literal', 'value': 'SemEval-2018 Task 7 dataset'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R207063'}, 'dataset_lbl': {'type': 'literal', 'value': 'Automatically labeled Medline abstracts corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R220302'}, 'dataset_lbl': {'type': 'literal', 'value': 'DocRED (Distantly Supervised)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R207070'}, 'dataset_lbl': {'type': 'literal', 'value': ""Abstracts' entities and relations annotated corpus""}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R172698'}, 'dataset_lbl': {'type': 'literal', 'value': 'DocRED (Human-annotated)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R203385'}, 'dataset_lbl': {'type': 'literal', 'value': 'TDMSci'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206124'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206159'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R195907'}, 'dataset_lbl': {'type': 'literal', 'value': 'ner_dataset_recognition'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R166503'}, 'dataset_lbl': {'type': 'literal', 'value': 'Softcite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206179'}, 'dataset_lbl': {'type': 'literal', 'value': 'Dataset mentions in Social Sciences'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R217408'}, 'dataset_lbl': {'type': 'literal', 'value': 'NLP-TDMS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R209701'}, 'dataset_lbl': {'type': 'literal', 'value': 'DRI Corpus'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147724'}, 'dataset_lbl': {'type': 'literal', 'value': 'TSE-NER'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R147640'}, 'dataset_lbl': {'type': 'literal', 'value': 'Scholarly entity usage detection'}}]","[{'URL': {'type': 'literal', 'value': 'https://seel.cse.lsu.edu/data/re17.zip'}}, {'URL': {'type': 'literal', 'value': 'https://mast.informatik.uni-hamburg.de/wp-content/uploads/2014/03/REJ_data.zip'}}, {'URL': {'type': 'literal', 'value': 'https://sites.google.com/site/appsuserreviews/'}}, {'URL': {'type': 'literal', 'value': 'https://seel.cse.lsu.edu/data/refsq17.zip'}}, {'URL': {'type': 'literal', 'value': 'https://mast.informatik.uni-hamburg.de/wp-content/uploads/2014/03/REJ_data.zip '}}, {'URL': {'type': 'literal', 'value': 'https://zenodo.org/record/56907#.YKT_NudCRPY'}}, {'URL': {'type': 'literal', 'value': 'https://sites.google.com/site/appsimilarity/'}}, {'URL': {'type': 'literal', 'value': 'https://github.com/saltlab/Minning-App-Stores'}}, {'URL': {'type': 'literal', 'value': 'https://github.com/SAILResearch/replication-prioritize_devices_test_app'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
36,What are the most commonly used benchmark datasets for the Entity Disambiguation research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Entity Disambiguation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Entity Disambiguation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9629629629629628,"(0.9835095405578613, 0.9766074419021606, 0.9800463318824768)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R164005'}, 'dataset_lbl': {'type': 'literal', 'value': 'SoMeSci'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R164005'}, 'dataset_lbl': {'type': 'literal', 'value': 'SoMeSci'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
37,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the BIOSSES dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BIOSSES"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BIOSSES"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9816701412200928, 0.9742963314056396, 0.9779692888259888)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131730'}, 'paper_lbl': {'type': 'literal', 'value': 'BioSentVec: creating sentence embeddings for biomedical texts'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131730'}, 'paper_lbl': {'type': 'literal', 'value': 'BioSentVec: creating sentence embeddings for biomedical texts'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
38,Which model has achieved the highest F1 score score on the BUCC Chinese-to-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC Chinese-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC Chinese-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9649122807017544,"(0.9819515943527222, 0.9806110262870789, 0.9812808632850647)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
39,Provide a list of research paper titles and IDs that have benchmarked models on the ImageNet ReaL dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9607843137254902,"(0.9815329313278198, 0.9740623831748962, 0.9777833819389343)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134962'}, 'paper_lbl': {'type': 'literal', 'value': 'CvT: Introducing Convolutions to Vision Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134998'}, 'paper_lbl': {'type': 'literal', 'value': 'Training data-efficient image transformers & distillation through attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134578'}, 'paper_lbl': {'type': 'literal', 'value': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134713'}, 'paper_lbl': {'type': 'literal', 'value': 'Going deeper with Image Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134775'}, 'paper_lbl': {'type': 'literal', 'value': ""LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference""}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134962'}, 'paper_lbl': {'type': 'literal', 'value': 'CvT: Introducing Convolutions to Vision Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134998'}, 'paper_lbl': {'type': 'literal', 'value': 'Training data-efficient image transformers & distillation through attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134578'}, 'paper_lbl': {'type': 'literal', 'value': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134713'}, 'paper_lbl': {'type': 'literal', 'value': 'Going deeper with Image Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134775'}, 'paper_lbl': {'type': 'literal', 'value': ""LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference""}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
40,What are the titles and IDs of research papers that include a benchmark for the Gibson PointGoal Navigation dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.8169276475307028,0.9629629629629628,"(0.9807305335998535, 0.9726428985595703, 0.97666996717453)",[],"[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131287'}, 'paper_lbl': {'type': 'literal', 'value': 'DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
41,What is the top benchmark result (metric and value) over the dataset CoNLL++?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9819127321243286, 0.9798928499221802, 0.9809017777442932)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '93.42'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '93.42'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
42,What is the best performing model benchmarking the PIQA dataset in terms of Accuracy metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PIQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PIQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9661016949152542,"(0.9818407297134399, 0.9809473752975464, 0.9813938736915588)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
43,Indicate the model that performed best in terms of Score metric on the Atari 2600 Crazy Climber benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Crazy Climber"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Crazy Climber"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9672131147540984,"(0.9814749360084534, 0.9802649617195129, 0.9808695912361145)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
44,Provide a list of papers that have utilized the Table-Sequence model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Table-Sequence"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Table-Sequence"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9807692307692308,"(0.9836772680282593, 0.9747205972671509, 0.9791784882545471)","[{'code': {'type': 'literal', 'value': 'https://github.com/saarahasad/Relation-Extraction'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LorrinWWW/two-are-better-than-one'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/saarahasad/Relation-Extraction'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LorrinWWW/two-are-better-than-one'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
45,Provide a list of papers that have utilized the Funnel Transformer model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Funnel Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Funnel Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.98369300365448, 0.9747248888015747, 0.9791884422302246)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
46,What evaluation metrics are commonly used when benchmarking models on the Reuters De-En dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters De-En"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters De-En"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9629629629629628,"(0.9828750491142273, 0.9766041040420532, 0.9797295928001404)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
47,Indicate the model that performed best in terms of F1 metric on the PubMed 20k RCT benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.983328640460968, 0.9820665121078491, 0.9826971292495728)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
48,List the code links in papers that use the DocRED-BiLSTM model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DocRED-BiLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DocRED-BiLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9840937852859497, 0.9754190444946289, 0.9797372221946716)","[{'code': {'type': 'literal', 'value': 'https://github.com/thunlp/DocRED'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/thunlp/DocRED'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
49,What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of FLOPS metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9661016949152542,"(0.9835574626922607, 0.9824984073638916, 0.9830276370048523)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126364'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-TDN(ResNet-101)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126364'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-TDN(ResNet-101)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
50,What is the top benchmark result (metric and value) over the dataset AESLC?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9828859567642212, 0.9808868765830994, 0.9818854331970215)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120314'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-1'}, 'score': {'type': 'literal', 'value': '37.68'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116360'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-L'}, 'score': {'type': 'literal', 'value': '36.51'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124684'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-2'}, 'score': {'type': 'literal', 'value': '21.25'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120314'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-1'}, 'score': {'type': 'literal', 'value': '37.68'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116360'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-L'}, 'score': {'type': 'literal', 'value': '36.51'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124684'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-2'}, 'score': {'type': 'literal', 'value': '21.25'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
51,What are the titles and IDs of research papers that include a benchmark for the Oxford-IIIT Pets dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9629629629629628,"(0.9811832904815674, 0.9730277061462402, 0.9770885109901428)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134962'}, 'paper_lbl': {'type': 'literal', 'value': 'CvT: Introducing Convolutions to Vision Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134578'}, 'paper_lbl': {'type': 'literal', 'value': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134924'}, 'paper_lbl': {'type': 'literal', 'value': 'Sharpness-Aware Minimization for Efficiently Improving Generalization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134962'}, 'paper_lbl': {'type': 'literal', 'value': 'CvT: Introducing Convolutions to Vision Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134578'}, 'paper_lbl': {'type': 'literal', 'value': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134924'}, 'paper_lbl': {'type': 'literal', 'value': 'Sharpness-Aware Minimization for Efficiently Improving Generalization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
52,What is the top benchmark score and its metric on the WOS-46985 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-46985"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-46985"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.96875,"(0.9822559356689453, 0.9805885553359985, 0.9814215302467346)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '76.58'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '76.58'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
53,Provide a list of papers that have utilized the AcrE model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AcrE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AcrE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9833713173866272, 0.9746427536010742, 0.9789875745773315)","[{'code': {'type': 'literal', 'value': 'https://github.com/neukg/AcrE'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/neukg/AcrE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
54,What is the best performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SemEval 2013"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SemEval 2013"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9661016949152542,"(0.9808259606361389, 0.9797115921974182, 0.9802684783935547)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120662'}, 'model_lbl': {'type': 'literal', 'value': 'ELMo'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120662'}, 'model_lbl': {'type': 'literal', 'value': 'ELMo'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
55,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciERC dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9820276498794556, 0.9744079113006592, 0.9782029390335083)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129488'}, 'paper_lbl': {'type': 'literal', 'value': 'Span-based Joint Entity and Relation Extraction with Transformer Pre-training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129585'}, 'paper_lbl': {'type': 'literal', 'value': 'Entity, Relation, and Event Extraction with Contextualized Span Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129595'}, 'paper_lbl': {'type': 'literal', 'value': 'A Frustratingly Easy Approach for Entity and Relation Extraction'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129488'}, 'paper_lbl': {'type': 'literal', 'value': 'Span-based Joint Entity and Relation Extraction with Transformer Pre-training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129585'}, 'paper_lbl': {'type': 'literal', 'value': 'Entity, Relation, and Event Extraction with Contextualized Span Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129595'}, 'paper_lbl': {'type': 'literal', 'value': 'A Frustratingly Easy Approach for Entity and Relation Extraction'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
56,What quantity of iron oxide was discovered on Elorza crater?,"SELECT ?properties_values, ?property_description
WHERE {
  ?papers rdf:type orkgc:Paper.
  ?papers rdfs:label ?papers_labels.
  FILTER(REGEX(?papers_labels, ""Elorza crater"", ""i""))
  ?papers orkgp:P31 ?contrib.
  ?contrib ?properties ?properties_values.
  ?properties rdfs:label ?properties_labels.
  FILTER(REGEX(?properties_labels, ""FeO""))
  ?properties orkgp:description ?property_description.
}","SELECT ?quantity ?quantity_lbl
WHERE {
  ?discovery a orkgc:Discovery;
            orkgp:HAS_LOCATION ?location;
            orkgp:HAS_MATERIAL ?material.
  ?location rdfs:label ""Elorza crater"".
  ?material rdfs:label ""iron oxide"";
            orkgp:HAS_QUANTITY ?quantity.
  ?quantity rdfs:label ?quantity_lbl. 
}",4.120062942869799e-155,0.6610169491525424,"(0.854080080986023, 0.8444998264312744, 0.8492629528045654)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
57,Can you list the models that have been evaluated on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.9815679788589478, 0.9762949347496033, 0.9789243936538696)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126043'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126047'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126034'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-H/14'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126037'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126038'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16 (""ImageNet-21k"")'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126043'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126047'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126034'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-H/14'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126037'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126038'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16 (""ImageNet-21k"")'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
58,Provide a list of papers that have utilized the DQN-PixelCNN model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQN-PixelCNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQN-PixelCNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9636363636363636,"(0.9837719202041626, 0.974897027015686, 0.979314386844635)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
59,Can you list the metrics used to evaluate models on the Atari 2600 Freeway dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9649122807017544,"(0.9830590486526489, 0.9766072034835815, 0.9798225164413452)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
60,List the code links in papers that use the Dynamic Coattention Networks (single model) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Dynamic Coattention Networks (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Dynamic Coattention Networks (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9343348130467294,0.9622641509433962,"(0.983991265296936, 0.974959135055542, 0.9794543981552124)","[{'code': {'type': 'literal', 'value': 'https://github.com/andreiilie1/dynamic_coattention_networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wasimusu/MachineRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AdvancedML-Project-Dynamic-Coattention-Networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AML-Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lmn-extracts/dcn_plus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/andreiilie1/dynamic_coattention_networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wasimusu/MachineRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AdvancedML-Project-Dynamic-Coattention-Networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AML-Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lmn-extracts/dcn_plus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
61,"Indicate the model that performed best in terms of Macro Precision metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9669306597086388,0.967741935483871,"(0.9827260971069336, 0.9816851615905762, 0.9822053909301758)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
62,What is the top benchmark score and its metric on the Atari 2600 Tennis dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9824159741401672, 0.9803896546363831, 0.9814017415046692)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '5.1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '5.1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
63,What are the metrics of evaluation over the DuIE dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9622641509433962,"(0.9829262495040894, 0.9766364097595215, 0.9797712564468384)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
64,"List the metrics that are used to evaluate models on the Cheetah, run (DMControl500k) benchmark dataset?","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8981503502402635,0.9642857142857144,"(0.9796733856201172, 0.9744076728820801, 0.9770334362983704)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
65,Could you provide a list of models that have been tested on the Reuters RCV1/RCV2 English-to-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters RCV1/RCV2 English-to-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters RCV1/RCV2 English-to-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9666666666666668,"(0.9818412065505981, 0.9768989682197571, 0.9793638586997986)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124046'}, 'model_lbl': {'type': 'literal', 'value': 'Biinclusion (Euro500kReuters)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124047'}, 'model_lbl': {'type': 'literal', 'value': 'Bi+'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124046'}, 'model_lbl': {'type': 'literal', 'value': 'Biinclusion (Euro500kReuters)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124047'}, 'model_lbl': {'type': 'literal', 'value': 'Bi+'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
66,What types of nanocarriers do have therapeutic effect?,"SELECT ?types_of_nanocarriers, ?types_of_nanocarriers_labels
WHERE {
  orkgr:R144364 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41740 ?types_of_nanocarriers.
  ?contrib orkgp:P41743 ?therapeutic_effect.
  FILTER(?therapeutic_effect = ""T""^^xsd:string)
  ?types_of_nanocarriers rdfs:label ?types_of_nanocarriers_labels.
}","SELECT DISTINCT ?nanocarrier ?nanocarrier_lbl 
WHERE {
  ?nanocarrier a orkgc:Nanocarrier;
              rdfs:label ?nanocarrier_lbl.
  ?effect orkgp:HAS_NANOCARRIER ?nanocarrier;
          orkgp:IS_THERAPEUTIC ?therapeuticEffect.
}",4.668667896057321e-155,0.6,"(0.8586308360099792, 0.8512259721755981, 0.8549124002456665)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
67,What is the name of the top performing model in terms of ROUGE-2 score when benchmarked on the CL-SciSumm dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CL-SciSumm"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CL-SciSumm"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9661016949152542,"(0.9840764999389648, 0.9824793934822083, 0.9832773208618164)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124759'}, 'model_lbl': {'type': 'literal', 'value': 'GCN Hybrid'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124759'}, 'model_lbl': {'type': 'literal', 'value': 'GCN Hybrid'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
68,List the code links in papers that use the Unsupervised NMT + weight-sharing model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Unsupervised NMT + weight-sharing"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Unsupervised NMT + weight-sharing"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9321022168949714,0.9642857142857144,"(0.9839295744895935, 0.9749355316162109, 0.9794119000434875)","[{'code': {'type': 'literal', 'value': 'https://github.com/ZhenYangIACAS/unsupervised-NMT'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ZhenYangIACAS/unsupervised-NMT'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
69,Which model has achieved the highest Permuted Accuracy score on the Sequential MNIST benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Permuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Permuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9827586206896552,"(0.9838991165161133, 0.9827950596809387, 0.9833468198776245)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120964'}, 'model_lbl': {'type': 'literal', 'value': 'R-Transformer'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120964'}, 'model_lbl': {'type': 'literal', 'value': 'R-Transformer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
70,Can you list the models that have been evaluated on the SciTLDR dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9824195504188538, 0.9773416519165039, 0.9798740744590759)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R225027'}, 'model_lbl': {'type': 'literal', 'value': 'CATTS-XSUM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R225011'}, 'model_lbl': {'type': 'literal', 'value': 'CATTS'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R225027'}, 'model_lbl': {'type': 'literal', 'value': 'CATTS-XSUM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R225011'}, 'model_lbl': {'type': 'literal', 'value': 'CATTS'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
71,List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9807764291763306, 0.9754014015197754, 0.9780815243721008)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
72,"What is the highest benchmark result achieved on the IMDb-M dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-M"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IMDb-M"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9819827079772949, 0.9799740314483643, 0.9809772968292236)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '48.92%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '48.92%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
73,"Can you provide the highest benchmark result, including the metric and score, for the Scholarly entity usage detection dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Scholarly entity usage detection"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Scholarly entity usage detection dataset"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.914208565914368,0.9661016949152542,"(0.9812965393066406, 0.9800971150398254, 0.980696439743042)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
74,Can you list the models that have been evaluated on the MultiNLI dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.982239842414856, 0.9768710136413574, 0.9795480966567993)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
75,List the metrics that are used to evaluate models on the 200k Short Texts for Humor Detection benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.9075772733559514,0.9642857142857144,"(0.9796255826950073, 0.9742904901504517, 0.9769507646560669)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117528'}, 'metric_lbl': {'type': 'literal', 'value': 'F1-score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117528'}, 'metric_lbl': {'type': 'literal', 'value': 'F1-score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
76,"Can you provide the highest benchmark result, including the metric and score, for the Sequential MNIST dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential MNIST"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9827586206896552,"(0.9819064140319824, 0.9799303412437439, 0.9809173345565796)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127017'}, 'metric_lbl': {'type': 'literal', 'value': 'Unpermuted Accuracy'}, 'score': {'type': 'literal', 'value': '99.1%'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127016'}, 'metric_lbl': {'type': 'literal', 'value': 'Permuted Accuracy'}, 'score': {'type': 'literal', 'value': '97.2%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127017'}, 'metric_lbl': {'type': 'literal', 'value': 'Unpermuted Accuracy'}, 'score': {'type': 'literal', 'value': '99.1%'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127016'}, 'metric_lbl': {'type': 'literal', 'value': 'Permuted Accuracy'}, 'score': {'type': 'literal', 'value': '97.2%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
77,Provide a list of papers that have utilized the CRF with sentence expansion model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CRF with sentence expansion"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CRF with sentence expansion"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9321022168949714,0.9622641509433962,"(0.9827627539634705, 0.9736250042915344, 0.9781725406646729)","[{'code': {'type': 'literal', 'value': 'https://github.com/mvallet91/SmartPub-TSENER'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/mvallet91/SmartPub-TSENER'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
78,What is the top benchmark result (metric and value) over the dataset NYT-single?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9820455312728882, 0.9799783229827881, 0.9810108542442322)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '59'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '59'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
79,List the metrics that are used to evaluate models on the SciTLDR benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciTLDR"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9615384615384616,"(0.9828228950500488, 0.9765130281448364, 0.9796578288078308)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
80,Can you list the models that have been evaluated on the WMT2016 English-German dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9666666666666668,"(0.9815800189971924, 0.9762568473815918, 0.9789111614227295)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117323'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + NMT (tuning and joint refinement)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117324'}, 'model_lbl': {'type': 'literal', 'value': 'SMT as posterior regularization'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117120'}, 'model_lbl': {'type': 'literal', 'value': 'Attentional encoder-decoder + BPE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117122'}, 'model_lbl': {'type': 'literal', 'value': 'PBSMT + NMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117164'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + iterative backtranslation (unsupervised)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117251'}, 'model_lbl': {'type': 'literal', 'value': 'Linguistic Input Features'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117252'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + weight-sharing'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117253'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised S2S with attention'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117323'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + NMT (tuning and joint refinement)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117324'}, 'model_lbl': {'type': 'literal', 'value': 'SMT as posterior regularization'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117120'}, 'model_lbl': {'type': 'literal', 'value': 'Attentional encoder-decoder + BPE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117122'}, 'model_lbl': {'type': 'literal', 'value': 'PBSMT + NMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117164'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + iterative backtranslation (unsupervised)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117251'}, 'model_lbl': {'type': 'literal', 'value': 'Linguistic Input Features'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117252'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + weight-sharing'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117253'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised S2S with attention'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
81,Indicate the model that performed best in terms of FLOPS metric on the CIFAR-100 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-100"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""FLOPS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-100"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9661016949152542,"(0.9808176159858704, 0.9796729683876038, 0.9802449941635132)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126158'}, 'model_lbl': {'type': 'literal', 'value': 'EffNet-L2 (SAM)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126158'}, 'model_lbl': {'type': 'literal', 'value': 'EffNet-L2 (SAM)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
82,What is the top benchmark result (metric and value) over the dataset RotoWire (Relation Generation)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9655172413793104,"(0.9802765846252441, 0.9796038269996643, 0.9799401164054871)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116363'}, 'metric_lbl': {'type': 'literal', 'value': 'Precision'}, 'score': {'type': 'literal', 'value': '89.46%'}}, {'score': {'type': 'literal', 'value': '87.47%'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120300'}, 'metric_lbl': {'type': 'literal', 'value': 'count'}, 'score': {'type': 'literal', 'value': '34.28'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116363'}, 'metric_lbl': {'type': 'literal', 'value': 'Precision'}, 'score': {'type': 'literal', 'value': '89.46%'}}, {'score': {'type': 'literal', 'value': '87.47%'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120300'}, 'metric_lbl': {'type': 'literal', 'value': 'count'}, 'score': {'type': 'literal', 'value': '34.28'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
83,"What is the best performing model benchmarking the Reacher, easy (DMControl100k) dataset in terms of Score metric?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9832115173339844, 0.9814070463180542, 0.9823084473609924)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
84,Can you list the models that have been evaluated on the Atari 2600 Assault dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9655172413793104,"(0.9825507402420044, 0.9773553013801575, 0.9799460768699646)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
85,Where can I find code references in papers that have used the DQNMMCe+SR model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQNMMCe+SR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DQNMMCe+SR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.983649730682373, 0.9748618006706238, 0.9792360663414001)","[{'code': {'type': 'literal', 'value': 'https://github.com/bonniesjli/DQN_SR'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mcmachado/count_based_exploration_sr'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/bonniesjli/DQN_SR'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mcmachado/count_based_exploration_sr'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
86,"Can you provide the highest benchmark result, including the metric and score, for the Ball in cup, catch (DMControl100k) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9689827775496296,0.9672131147540984,"(0.9821004867553711, 0.9814754724502563, 0.9817878603935242)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '769'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '769'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
87,What is the name of the top performing model in terms of F1 score when benchmarked on the NYT-single dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT-single"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9649122807017544,"(0.9836288094520569, 0.9825632572174072, 0.9830957651138306)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116579'}, 'model_lbl': {'type': 'literal', 'value': 'ETL-Span'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116579'}, 'model_lbl': {'type': 'literal', 'value': 'ETL-Span'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
88,Can you provide links to code used in papers that benchmark the MEMEN (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9607843137254902,"(0.9836467504501343, 0.9747911095619202, 0.9791988730430603)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
89,Provide a list of papers that have utilized the MMV TSM-50x2 model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV TSM-50x2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV TSM-50x2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9642857142857144,"(0.9831308126449585, 0.9741475582122803, 0.9786185622215271)","[{'code': {'type': 'literal', 'value': 'https://github.com/deepmind/deepmind-research/tree/master/mmv'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/deepmind/deepmind-research/tree/master/mmv'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
90,Which model has achieved the highest Accuracy score on the Yelp-5 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-5"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-5"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9661016949152542,"(0.9807149171829224, 0.9796316623687744, 0.9801729917526245)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
91,What is the best performing model benchmarking the WMT2016 German-English dataset in terms of BLEU score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9824775457382202, 0.9810343384742737, 0.9817553758621216)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
92,Provide a list of papers that have utilized the SAC model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SAC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9832374453544617, 0.9738827347755432, 0.9785377383232117)","[{'code': {'type': 'literal', 'value': 'https://github.com/ToolManChang/DRLseminar_code_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cindycia/Atari-SAC-Discrete'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rltorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rljax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ac-93/soft-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ToolManChang/DRLseminar_code_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cindycia/Atari-SAC-Discrete'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rltorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rljax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ac-93/soft-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
93,Provide a list of papers that have utilized the MEMEN model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MEMEN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9833110570907593, 0.9742626547813416, 0.9787659645080566)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
94,Where can I find code references in papers that have used the Past Decode Reg. + AWD-LSTM-MoS + dyn. eval. model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Past Decode Reg. + AWD-LSTM-MoS + dyn. eval."")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Past Decode Reg. + AWD-LSTM-MoS + dyn. eval."")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9402297675816912,0.9636363636363636,"(0.9826323986053467, 0.9739487171173096, 0.9782713055610657)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
95,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Assault dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Assault"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.981756329536438, 0.9807684421539307, 0.9812620878219604)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
96,What is the best performing model benchmarking the 200k Short Texts for Humor Detection dataset in terms of F1-score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1-score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""200k Short Texts for Humor Detection"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9262685672663884,0.95,"(0.9818987846374512, 0.9805671572685242, 0.9812325239181519)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127506'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet Large Cased'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127506'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet Large Cased'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
97,Where can I find code references in papers that have used the STREET model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""STREET"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""STREET"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9833400845527649, 0.9742617607116699, 0.9787799119949341)","[{'code': {'type': 'literal', 'value': 'https://github.com/LinearPi/OCR_Chinese'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OzHsu23/chineseocr'}}, {'code': {'type': 'literal', 'value': 'https://github.com/witcher425/CHINESEOCR'}}, {'code': {'type': 'literal', 'value': 'https://github.com/xiaofengShi/CHINESE-OCR'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/LinearPi/OCR_Chinese'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OzHsu23/chineseocr'}}, {'code': {'type': 'literal', 'value': 'https://github.com/witcher425/CHINESEOCR'}}, {'code': {'type': 'literal', 'value': 'https://github.com/xiaofengShi/CHINESE-OCR'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
98,Can you list the models that have been evaluated on the enwiki8 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwiki8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwiki8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9642857142857144,"(0.980877161026001, 0.9755933284759521, 0.9782280921936035)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121030'}, 'model_lbl': {'type': 'literal', 'value': 'PAR Transformer 24B'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121030'}, 'model_lbl': {'type': 'literal', 'value': 'PAR Transformer 24B'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
99,Provide a list of research paper titles and IDs that have benchmarked models on the SciERC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9818910360336304, 0.9745588898658752, 0.9782111644744873)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129488'}, 'paper_lbl': {'type': 'literal', 'value': 'Span-based Joint Entity and Relation Extraction with Transformer Pre-training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129585'}, 'paper_lbl': {'type': 'literal', 'value': 'Entity, Relation, and Event Extraction with Contextualized Span Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129595'}, 'paper_lbl': {'type': 'literal', 'value': 'A Frustratingly Easy Approach for Entity and Relation Extraction'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129488'}, 'paper_lbl': {'type': 'literal', 'value': 'Span-based Joint Entity and Relation Extraction with Transformer Pre-training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129585'}, 'paper_lbl': {'type': 'literal', 'value': 'Entity, Relation, and Event Extraction with Contextualized Span Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129595'}, 'paper_lbl': {'type': 'literal', 'value': 'A Frustratingly Easy Approach for Entity and Relation Extraction'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
100,Indicate the model that performed best in terms of Accuracy metric on the CommonsenseQA benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9835009574890137, 0.9826014041900635, 0.9830509424209595)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120581'}, 'model_lbl': {'type': 'literal', 'value': 'QA-GNN'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120581'}, 'model_lbl': {'type': 'literal', 'value': 'QA-GNN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
101,What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9642857142857144,"(0.9811180830001831, 0.9757307767868042, 0.9784169793128967)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
102,What evaluation metrics are commonly used when benchmarking models on the WMT2014 English-German dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9655172413793104,"(0.9828984141349792, 0.9764092564582825, 0.9796431064605713)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
103,Provide a list of benchmarked datasets related to the Reading Comprehension research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Reading Comprehension"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Reading Comprehension"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9615384615384616,"(0.9838790893554688, 0.9769290685653687, 0.980391800403595)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119130'}, 'dataset_lbl': {'type': 'literal', 'value': 'RACE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120850'}, 'dataset_lbl': {'type': 'literal', 'value': 'WNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122670'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Fine-grained classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114616'}, 'dataset_lbl': {'type': 'literal', 'value': 'IMDb'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122706'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Binary classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123632'}, 'dataset_lbl': {'type': 'literal', 'value': 'ClueWeb09-B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125894'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125897'}, 'dataset_lbl': {'type': 'literal', 'value': 'DBpedia'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116787'}, 'dataset_lbl': {'type': 'literal', 'value': 'AG News'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125913'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125919'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-5'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116370'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-5'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119130'}, 'dataset_lbl': {'type': 'literal', 'value': 'RACE'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120850'}, 'dataset_lbl': {'type': 'literal', 'value': 'WNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122670'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Fine-grained classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114616'}, 'dataset_lbl': {'type': 'literal', 'value': 'IMDb'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122706'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp Binary classification'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123632'}, 'dataset_lbl': {'type': 'literal', 'value': 'ClueWeb09-B'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125894'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125897'}, 'dataset_lbl': {'type': 'literal', 'value': 'DBpedia'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116787'}, 'dataset_lbl': {'type': 'literal', 'value': 'AG News'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125913'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125919'}, 'dataset_lbl': {'type': 'literal', 'value': 'Yelp-5'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116370'}, 'dataset_lbl': {'type': 'literal', 'value': 'Amazon-5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
104,Which model has achieved the highest RE+ Micro F1 score on the CoNLL04 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL04"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL04"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9822232723236084, 0.9806650280952454, 0.9814435839653015)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116615'}, 'model_lbl': {'type': 'literal', 'value': 'Table-Sequence'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116615'}, 'model_lbl': {'type': 'literal', 'value': 'Table-Sequence'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
105,Provide a list of papers that have utilized the XLNet (base) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet (base)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet (base)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9816189408302307, 0.9719259142875671, 0.9767484068870544)","[{'code': {'type': 'literal', 'value': 'https://github.com/Kabongosalomon/task-dataset-metric-nli-extraction'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Kabongosalomon/task-dataset-metric-nli-extraction'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
106,List the title and ID of research papers that contain a benchmark over the Ohsumed dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Ohsumed"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Ohsumed"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9822269082069397, 0.9745192527770996, 0.9783579111099243)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134434'}, 'paper_lbl': {'type': 'literal', 'value': 'Text classification with word embedding regularization and soft similarity measure'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134448'}, 'paper_lbl': {'type': 'literal', 'value': 'Rep the Set: Neural Networks for Learning Set Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134476'}, 'paper_lbl': {'type': 'literal', 'value': ""Speeding up Word Mover's Distance and its variants via properties of distances between embeddings""}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134434'}, 'paper_lbl': {'type': 'literal', 'value': 'Text classification with word embedding regularization and soft similarity measure'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134448'}, 'paper_lbl': {'type': 'literal', 'value': 'Rep the Set: Neural Networks for Learning Set Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134476'}, 'paper_lbl': {'type': 'literal', 'value': ""Speeding up Word Mover's Distance and its variants via properties of distances between embeddings""}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
107,Could you provide a list of models that have been tested on the NYT29 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT29"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT29"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9642857142857144,"(0.9821706414222717, 0.9766937494277954, 0.9794245362281799)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116605'}, 'model_lbl': {'type': 'literal', 'value': 'WDec'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116606'}, 'model_lbl': {'type': 'literal', 'value': 'PNDec'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116607'}, 'model_lbl': {'type': 'literal', 'value': 'HRLRE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116605'}, 'model_lbl': {'type': 'literal', 'value': 'WDec'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116606'}, 'model_lbl': {'type': 'literal', 'value': 'PNDec'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116607'}, 'model_lbl': {'type': 'literal', 'value': 'HRLRE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
108,Which are 3 the most common variables for the atmosphere models?,"SELECT ?variables
WHERE {
  orkgr:R68871 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P7144 ?models.
  ?models rdfs:label ?models_labels.
  FILTER(REGEX(?models_labels, ""tmospher""))
  ?models orkgp:P26032 ?variables.
}
ORDER BY DESC(COUNT(?variables))
LIMIT 3","SELECT ?variable ?variable_lbl
WHERE {
  ?models orkgp:HAS_VARIABLE ?variable.
  ?variable rdfs:label ?variable_lbl.
}
ORDER BY DESC(COUNT(?variable))
LIMIT 3",2.703611762679282e-78,0.65625,"(0.8811187744140625, 0.8941059708595276, 0.8875648975372314)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
109,List the code links in papers that use the DDQN-PC model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DDQN-PC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DDQN-PC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9622641509433962,"(0.9817493557929993, 0.9722079038619995, 0.9769552946090698)","[{'code': {'type': 'literal', 'value': 'https://github.com/RLAgent/state-marginal-matching'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/RLAgent/state-marginal-matching'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
110,List the title and ID of research papers that contain a benchmark over the TREC-6 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TREC-6"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TREC-6"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9826480150222778, 0.9749802947044373, 0.9787991642951965)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
111,Can you provide links to code used in papers that benchmark the Rational DQN Average model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rational DQN Average"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rational DQN Average"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9622641509433962,"(0.9836442470550537, 0.9746502637863159, 0.9791265726089478)","[{'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_sl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_activations'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_sl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ml-research/rational_activations'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
112,What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-French dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-French"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9830201864242554, 0.9809898138046265, 0.9820039868354797)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124055'}, 'model_lbl': {'type': 'literal', 'value': 'XLMft UDA'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124055'}, 'model_lbl': {'type': 'literal', 'value': 'XLMft UDA'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
113,Indicate the model that performed best in terms of 1-of-100 Accuracy metric on the PolyAI Reddit benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""1-of-100 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PolyAI Reddit"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""1-of-100 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""PolyAI Reddit"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9666666666666668,"(0.9834403395652771, 0.981918215751648, 0.9826787710189819)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127904'}, 'model_lbl': {'type': 'literal', 'value': 'ELMO'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127904'}, 'model_lbl': {'type': 'literal', 'value': 'ELMO'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
114,List the code links in papers that use the Long Short Transformer model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Long Short Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Long Short Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.96,"(0.9836611747741699, 0.9746637940406799, 0.9791418313980103)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
115,What is the name of the top performing model in terms of Accuracy score when benchmarked on the TriviaQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""TriviaQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""TriviaQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9821984171867371, 0.9813052415847778, 0.9817516207695007)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119646'}, 'model_lbl': {'type': 'literal', 'value': 'S-Norm'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119646'}, 'model_lbl': {'type': 'literal', 'value': 'S-Norm'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
116,What is Raman spectroscopy?,"SELECT ?definitions
WHERE {
  ?terms orkgp:P24009 ?definitions.
  ?terms rdfs:label ?terms_labels.
  FILTER(REGEX(?terms_labels, ""Raman spectroscopy""))
}","SELECT DISTINCT ?technique ?technique_labels WHERE { ?papers orkgp:P31 ?techniques. ?techniques rdfs:label ""Raman spectroscopy""^^xsd:string. ?techniques rdfs:label ?technique_labels. }",5.74867560479262e-155,0.6607142857142857,"(0.8729122877120972, 0.8819736838340759, 0.8774195909500122)",[],"[{'definitions': {'type': 'literal', 'value': 'Raman Spectroscopy is a non-destructive chemical analysis technique which provides detailed information about chemical structure, phase and polymorphy, crystallinity and molecular interactions.  Raman is a light scattering technique, whereby a molecule scatters incident light from a high intensity laser light source.'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
117,"Can you provide the highest benchmark result, including the metric and score, for the DTD dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DTD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DTD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9820150136947632, 0.9804956912994385, 0.9812547564506531)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '79.1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '6.3M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '560M'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '79.1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '6.3M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '560M'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
118,What is the top benchmark score and its metric on the CINIC-10 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CINIC-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CINIC-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9672131147540984,"(0.9821933507919312, 0.9805325269699097, 0.9813622236251831)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '94.8'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '9.1M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '710M'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '94.8'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '9.1M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '710M'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
119,What are the titles and IDs of research papers that include a benchmark for the SemEval-2018 Task 7 dataset dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SemEval-2018 Task 7 dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SemEval-2018 Task 7 dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9343348130467294,0.9649122807017544,"(0.9818745851516724, 0.9743777513504028, 0.9781118035316467)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
120,List the metrics that are used to evaluate models on the AG News benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AG News"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AG News"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9629629629629628,"(0.980489194393158, 0.9751303791999817, 0.9778024554252625)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
121,What is the name of the top performing model in terms of F1 entity level score when benchmarked on the NCBI Disease dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 entity level"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NCBI Disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 entity level"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NCBI Disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9649122807017544,"(0.9814547896385193, 0.9802147150039673, 0.9808343648910522)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
122,Provide a list of research paper titles and IDs that have benchmarked models on the NCBI-disease dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.981490969657898, 0.9738637804985046, 0.9776625037193298)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
123,Can you provide links to code used in papers that benchmark the GCN Hybrid model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GCN Hybrid"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GCN Hybrid"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9622641509433962,"(0.981634259223938, 0.9721952676773071, 0.9768919348716736)","[{'code': {'type': 'literal', 'value': 'https://github.com/WING-NUS/scisumm-corpus'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/WING-NUS/scisumm-corpus'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
124,What data format does CHEMDNER corpus have?,"SELECT ?data_format, ?data_format_label
WHERE {
  orkgr:R150596 orkgp:P31 ?contrib.
  ?contrib orkgp:P42011 ?data_format.
  ?data_format rdfs:label ?data_format_label.
}","SELECT DISTINCT ?format ?format_lbl
WHERE {
  ?corpus a orkgc:Corpus;
          rdfs:label ?corpus_lbl.
  FILTER (str(?corpus_lbl) = ""CHEMDNER"")
  ?corpus orkgc:HAS_FORMAT ?format.
  OPTIONAL {?format rdfs:label ?format_lbl.}
}",4.506889438070446e-155,0.5517241379310345,"(0.8684547543525696, 0.836834192276001, 0.8523513674736023)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
125,What are the titles and IDs of research papers that include a benchmark for the CUB-200-2011 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CUB-200-2011"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CUB-200-2011"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9636363636363636,"(0.9815057516098022, 0.9738590717315674, 0.9776674509048462)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135170'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135170'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
126,Can you provide links to code used in papers that benchmark the SEE model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SEE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SEE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9834596514701843, 0.9745402932167053, 0.9789796471595764)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
127,Provide a list of papers that have utilized the Duel hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9833879470825195, 0.974387526512146, 0.9788670539855957)","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/DeepQNetwork'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nathanin/pad'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kshitij-ingale/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mohit8935/Deep-Q-Learning-Paper'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling_Network_Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling-Network-Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/botforge/simplementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jezzarax/drlnd_p1_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fengsterooni/dql'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shehrum/RL_Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mightypirate1/DRL-Tetris'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZainRaza14/deepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/FaboNo/DRLND'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/Chez'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/chezjulia'}}, {'code': {'type': 'literal', 'value': 'https://github.com/170928/-Review-Dueling-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/opplieam/Pong-Deep-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jsztompka/DuelDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/R-Sweke/DeepQ-Decoding'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gouxiangchen/dueling-DQN-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KDL-umass/saliency_maps'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alessandrositta/Flatland_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Continuous-Control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zynk13/dueling-dqn-Reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abryeemessi/Wednesday'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JBGUIMBAUD/deep-reenforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sirorezka/DeepRL_modules'}}, {'code': {'type': 'literal', 'value': 'https://github.com/manvibharat/Stock-price-pridiction-using-Deep-reienforcement-learning'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/DeepQNetwork'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nathanin/pad'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kshitij-ingale/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mohit8935/Deep-Q-Learning-Paper'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling_Network_Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling-Network-Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/botforge/simplementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jezzarax/drlnd_p1_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fengsterooni/dql'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shehrum/RL_Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mightypirate1/DRL-Tetris'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZainRaza14/deepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/FaboNo/DRLND'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/Chez'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/chezjulia'}}, {'code': {'type': 'literal', 'value': 'https://github.com/170928/-Review-Dueling-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/opplieam/Pong-Deep-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jsztompka/DuelDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/R-Sweke/DeepQ-Decoding'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gouxiangchen/dueling-DQN-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KDL-umass/saliency_maps'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alessandrositta/Flatland_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Continuous-Control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zynk13/dueling-dqn-Reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abryeemessi/Wednesday'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JBGUIMBAUD/deep-reenforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sirorezka/DeepRL_modules'}}, {'code': {'type': 'literal', 'value': 'https://github.com/manvibharat/Stock-price-pridiction-using-Deep-reienforcement-learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
128,What is the top benchmark result (metric and value) over the dataset DocRED (Human-annotated)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DocRED (Human-annotated)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""DocRED (Human-annotated)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9661016949152542,"(0.9802048206329346, 0.9793956875801086, 0.9798001050949097)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
129,Provide a list of papers that have utilized the Adaptive Input Large model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Adaptive Input Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Adaptive Input Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9622641509433962,"(0.9836504459381104, 0.9747303128242493, 0.9791700839996338)","[{'code': {'type': 'literal', 'value': 'https://github.com/AranKomat/adapinp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pytorch/fairseq'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/AranKomat/adapinp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pytorch/fairseq'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
130,What models are being evaluated on the Atari 2600 Solaris dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Solaris"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Solaris"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9649122807017544,"(0.9822676777839661, 0.9770693778991699, 0.9796616435050964)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124952'}, 'model_lbl': {'type': 'literal', 'value': 'Go-Explore'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124953'}, 'model_lbl': {'type': 'literal', 'value': 'RND'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124978'}, 'model_lbl': {'type': 'literal', 'value': 'DQNMMCe'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124952'}, 'model_lbl': {'type': 'literal', 'value': 'Go-Explore'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124953'}, 'model_lbl': {'type': 'literal', 'value': 'RND'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124978'}, 'model_lbl': {'type': 'literal', 'value': 'DQNMMCe'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
131,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SNLI dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9607843137254902,"(0.9819685220718384, 0.9742876291275024, 0.9781129956245422)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130368'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep contextualized word representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R194309'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Contextualized Word Representations'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130368'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep contextualized word representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R194309'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Contextualized Word Representations'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
132,Where can I find code references in papers that have used the MMV model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MMV"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9838141202926636, 0.9746551513671875, 0.9792131781578064)","[{'code': {'type': 'literal', 'value': 'https://github.com/deepmind/deepmind-research/tree/master/mmv'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/deepmind/deepmind-research/tree/master/mmv'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
133,What is the top benchmark score and its metric on the Atari 2600 Centipede dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9814450740814209, 0.9801660776138306, 0.9808051586151123)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9646.0'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9646.0'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
134,What are the models that have been benchmarked on the MNIST dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9622641509433962,"(0.9818068742752075, 0.9765613675117493, 0.9791770577430725)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126124'}, 'model_lbl': {'type': 'literal', 'value': 'VGG8B + LocalLearning + CO'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126151'}, 'model_lbl': {'type': 'literal', 'value': 'ANODE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126152'}, 'model_lbl': {'type': 'literal', 'value': 'Zhao et al. (2015) (auto-encoder)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126153'}, 'model_lbl': {'type': 'literal', 'value': 'ProjectionNet'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126154'}, 'model_lbl': {'type': 'literal', 'value': 'Weighted Tsetlin Machine'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126155'}, 'model_lbl': {'type': 'literal', 'value': 'Tsetlin Machine'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126124'}, 'model_lbl': {'type': 'literal', 'value': 'VGG8B + LocalLearning + CO'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126151'}, 'model_lbl': {'type': 'literal', 'value': 'ANODE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126152'}, 'model_lbl': {'type': 'literal', 'value': 'Zhao et al. (2015) (auto-encoder)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126153'}, 'model_lbl': {'type': 'literal', 'value': 'ProjectionNet'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126154'}, 'model_lbl': {'type': 'literal', 'value': 'Weighted Tsetlin Machine'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126155'}, 'model_lbl': {'type': 'literal', 'value': 'Tsetlin Machine'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
135,Where did the study with maximal geographic scale take place?,"SELECT ?location, ?location_label
WHERE {
  {
    SELECT (MAX(?geo_scale) AS ?max_geo_scale)
    WHERE {
      orkgr:R149849 orkgp:compareContribution ?contrib.
      ?contrib orkgp:P41568 ?geo_scale.
    }
  }
  orkgr:R149849 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41568 ?geo_scale;
           orkgp:P37524 ?location.
  ?location rdfs:label ?location_label.
  FILTER(?geo_scale = ?max_geo_scale)
}","SELECT DISTINCT ?location ?location_lbl
WHERE {
  ?study a orkgc:Study.
  ?study orkgc:HAS_GEOGRAPHIC_SCALE ?scale.
  ?study orkgc:HAS_LOCATION ?location.
  OPTIONAL {?location rdfs:label ?location_lbl.}
} ORDER BY DESC(?scale) LIMIT 1",3.504956248828668e-155,0.625,"(0.8467983603477478, 0.8511331081390381, 0.8489601612091064)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
136,Provide a list of research paper titles and IDs that have benchmarked models on the WLPC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WLPC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WLPC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9607843137254902,"(0.9818339347839355, 0.9741618633270264, 0.9779828786849976)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129331'}, 'paper_lbl': {'type': 'literal', 'value': 'Generalizing Natural Language Analysis through Span-relation Representations'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129569'}, 'paper_lbl': {'type': 'literal', 'value': 'A General Framework for Information Extraction using Dynamic Span Graphs'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129331'}, 'paper_lbl': {'type': 'literal', 'value': 'Generalizing Natural Language Analysis through Span-relation Representations'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
137,What are the titles and IDs of research papers that include a benchmark for the TempEval-3 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9817887544631958, 0.9742224216461182, 0.977990984916687)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131118'}, 'paper_lbl': {'type': 'literal', 'value': 'A Structured Learning Approach to Temporal Relation Extraction'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131118'}, 'paper_lbl': {'type': 'literal', 'value': 'A Structured Learning Approach to Temporal Relation Extraction'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
138,Could you provide a list of models that have been tested on the SciERC benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciERC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9823178052902222, 0.9769380688667297, 0.9796205759048462)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116620'}, 'model_lbl': {'type': 'literal', 'value': 'SpERT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116700'}, 'model_lbl': {'type': 'literal', 'value': 'SpERT (with overlap)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116703'}, 'model_lbl': {'type': 'literal', 'value': 'DyGIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116715'}, 'model_lbl': {'type': 'literal', 'value': 'DyGIE++'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116718'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116717'}, 'model_lbl': {'type': 'literal', 'value': 'SciIE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116620'}, 'model_lbl': {'type': 'literal', 'value': 'SpERT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116700'}, 'model_lbl': {'type': 'literal', 'value': 'SpERT (with overlap)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116703'}, 'model_lbl': {'type': 'literal', 'value': 'DyGIE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116715'}, 'model_lbl': {'type': 'literal', 'value': 'DyGIE++'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116718'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116717'}, 'model_lbl': {'type': 'literal', 'value': 'SciIE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
139,Indicate the model that performed best in terms of F1 metric on the CoNLL 2012 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2012"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2012"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9655172413793104,"(0.9836058616638184, 0.9825600385665894, 0.9830827116966248)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116338'}, 'model_lbl': {'type': 'literal', 'value': 'SpanRel'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116338'}, 'model_lbl': {'type': 'literal', 'value': 'SpanRel'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
140,What are the models that have been benchmarked on the WMT2014 English-German dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9666666666666668,"(0.9814099669456482, 0.9760918021202087, 0.9787436723709106)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117323'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + NMT (tuning and joint refinement)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117324'}, 'model_lbl': {'type': 'literal', 'value': 'SMT as posterior regularization'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117122'}, 'model_lbl': {'type': 'literal', 'value': 'PBSMT + NMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117123'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised PBSMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117124'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117154'}, 'model_lbl': {'type': 'literal', 'value': 'Rfa-Gate-arccos'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117164'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + iterative backtranslation (unsupervised)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117221'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+4 iterations'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117225'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+1 iterations'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117228'}, 'model_lbl': {'type': 'literal', 'value': 'NAT +FT + NPD'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117229'}, 'model_lbl': {'type': 'literal', 'value': 'Denoising autoencoders (non-autoregressive)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117264'}, 'model_lbl': {'type': 'literal', 'value': 'Transformer Big + adversarial MLE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117323'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + NMT (tuning and joint refinement)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117324'}, 'model_lbl': {'type': 'literal', 'value': 'SMT as posterior regularization'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117122'}, 'model_lbl': {'type': 'literal', 'value': 'PBSMT + NMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117123'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised PBSMT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117124'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117154'}, 'model_lbl': {'type': 'literal', 'value': 'Rfa-Gate-arccos'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117164'}, 'model_lbl': {'type': 'literal', 'value': 'SMT + iterative backtranslation (unsupervised)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117221'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+4 iterations'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117225'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+1 iterations'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117228'}, 'model_lbl': {'type': 'literal', 'value': 'NAT +FT + NPD'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117229'}, 'model_lbl': {'type': 'literal', 'value': 'Denoising autoencoders (non-autoregressive)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117264'}, 'model_lbl': {'type': 'literal', 'value': 'Transformer Big + adversarial MLE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
141,"What is the highest benchmark result achieved on the Yelp-14 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-14"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Yelp-14"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9672131147540984,"(0.9821300506591797, 0.9805548191070557, 0.9813418388366699)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '69.4'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '69.4'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
142,List the code links in papers that use the A3C FF (1 day) hs model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF (1 day) hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF (1 day) hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9343348130467294,0.9622641509433962,"(0.983875036239624, 0.9748057126998901, 0.9793193936347961)","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
143,Could you provide a list of models that have been tested on the RTE benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RTE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RTE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9622641509433962,"(0.9817632436752319, 0.9764800071716309, 0.9791144728660583)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
144,"What is the highest benchmark result achieved on the WOS-5736 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-5736"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WOS-5736"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9682539682539684,"(0.9821559190750122, 0.9804902076721191, 0.9813223481178284)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90.93'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90.93'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
145,Provide a list of research paper titles and IDs that have benchmarked models on the WebQuestions dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WebQuestions"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WebQuestions"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9819873571395874, 0.9743384122848511, 0.9781479239463806)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
146,List the metrics that are used to evaluate models on the ART/CoreSC benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ART/CoreSC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ART/CoreSC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9808750748634338, 0.9754723310470581, 0.9781662225723267)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
147,What are the models that have been benchmarked on the Natural Questions (short) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9642857142857144,"(0.9821732044219971, 0.9770628809928894, 0.979611337184906)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119441'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Attention'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119444'}, 'model_lbl': {'type': 'literal', 'value': 'DrQA'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119453'}, 'model_lbl': {'type': 'literal', 'value': 'BERTwwm + SQuAD 2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119455'}, 'model_lbl': {'type': 'literal', 'value': 'BERTjoint'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119441'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Attention'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119444'}, 'model_lbl': {'type': 'literal', 'value': 'DrQA'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119453'}, 'model_lbl': {'type': 'literal', 'value': 'BERTwwm + SQuAD 2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119455'}, 'model_lbl': {'type': 'literal', 'value': 'BERTjoint'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
148,"Can you provide the highest benchmark result, including the metric and score, for the WMT2014 French-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9682539682539684,"(0.9812673926353455, 0.9800264239311218, 0.9806464910507202)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}, 'score': {'type': 'literal', 'value': '39.2'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '25.87'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}, 'score': {'type': 'literal', 'value': '39.2'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '25.87'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
149,Which model has achieved the highest Test perplexity score on the WikiText-2 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9666666666666668,"(0.98070228099823, 0.9795161485671997, 0.9801088571548462)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121028'}, 'model_lbl': {'type': 'literal', 'value': 'Grave et al. (2016) - LSTM'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121028'}, 'model_lbl': {'type': 'literal', 'value': 'Grave et al. (2016) - LSTM'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
150,Where can I find code references in papers that have used the All-attention network - 18 layers model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""All-attention network - 18 layers"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""All-attention network - 18 layers"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9343348130467294,0.9642857142857144,"(0.9836023449897766, 0.97464919090271, 0.9791052937507629)","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/x-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/adaptive-span'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/memory-transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/routing-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/reformer-pytorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/x-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/adaptive-span'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/memory-transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/routing-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/reformer-pytorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
151,"Does paper ""Disambiguating authors in citations on the web and authorship correlations"" employe Cosine similarity?","ASK
WHERE {
  orkgr:R6187 orkgp:compareContribution ?cont.
  ?paper orkgp:P31 ?cont;
         rdfs:label ?paper_title.
  ?cont orkgp:P5002 orkgr:R6006.
  FILTER(REGEX(STR(?paper_title), ""Disambiguating authors in citations on the web and authorship correlations"", ""i""))
}","SELECT ?evidence
WHERE {
  orkgr:R6751 orkgp:compareContribution ?cont.
  ?paper orkgp:P31 ?cont;
         rdfs:label ""Disambiguating authors in citations on the web and authorship correlations"".
  ?cont orkgp:P5004 ?evidence.
}",0.5009682558924408,0.7627118644067796,"(0.9181976318359375, 0.9523090124130249, 0.9349423050880432)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
152,Can you list the models that have been evaluated on the STS Benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9622641509433962,"(0.9824426174163818, 0.9772778153419495, 0.9798534512519836)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
153,Indicate the model that performed best in terms of Score metric on the Atari 2600 Freeway benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9834461212158203, 0.982441246509552, 0.9829434752464294)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
154,What are the titles and IDs of research papers that include a benchmark for the DCASE dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DCASE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DCASE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9607843137254902,"(0.982038140296936, 0.9743505716323853, 0.9781792163848877)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129977'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised Learning by Cross-Modal Audio-Video Clustering'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129977'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised Learning by Cross-Modal Audio-Video Clustering'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
155,What evaluation metrics are commonly used when benchmarking models on the Yelp Fine-grained classification dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9629629629629628,"(0.9815306663513184, 0.9757275581359863, 0.9786205291748047)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
156,Which model has achieved the highest Score score on the Atari 2600 River Raid benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 River Raid"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 River Raid"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9661016949152542,"(0.9833972454071045, 0.9823788404464722, 0.9828877449035645)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
157,Provide a list of papers that have utilized the BERT + BiLSTM + CRF Decoding model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERT + BiLSTM + CRF Decoding"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERT + BiLSTM + CRF Decoding"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9364250605898116,0.9615384615384616,"(0.9835399389266968, 0.9749209880828857, 0.9792115092277527)","[{'code': {'type': 'literal', 'value': 'https://github.com/allenai/SciREX'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/allenai/SciREX'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
158,Indicate the model that performed best in terms of Pearson Correlation metric on the MedSTS benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Pearson Correlation"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MedSTS"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Pearson Correlation"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MedSTS"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9814355373382568, 0.9802877306938171, 0.9808613061904907)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
159,What are the titles and IDs of research papers that include a benchmark for the WSC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WSC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WSC dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.8038019482772603,0.9607843137254902,"(0.9802080392837524, 0.9719148874282837, 0.9760438799858093)",[],"[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
160,List the code links in papers that use the linear-chain CRFs model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""linear-chain CRFs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""linear-chain CRFs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9823724031448364, 0.9740492701530457, 0.9781931638717651)","[{'code': {'type': 'literal', 'value': 'https://github.com/howisonlab/softcite-dataset'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/howisonlab/softcite-dataset'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
161,List the code links in papers that use the DrQA model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DrQA"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DrQA"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9822442531585693, 0.9730115532875061, 0.9776061773300171)","[{'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sachit-n/drqa_doc_reader'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aaronbae/AnaQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Raman-Raje/Machine-Reading-Comprehension-Neural-Question-Answer-'}}, {'code': {'type': 'literal', 'value': 'https://github.com/xiangyue9607/CliniRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HKUST-KnowComp/MnemonicReader'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hitvoice/DrQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/DrQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ParlAI'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sachit-n/drqa_doc_reader'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aaronbae/AnaQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Raman-Raje/Machine-Reading-Comprehension-Neural-Question-Answer-'}}, {'code': {'type': 'literal', 'value': 'https://github.com/xiangyue9607/CliniRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HKUST-KnowComp/MnemonicReader'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hitvoice/DrQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/DrQA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ParlAI'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
162,Which model has achieved the highest Accuracy score on the SST-5 Fine-grained classification benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.983741819858551, 0.9821940660476685, 0.9829673171043396)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122623'}, 'model_lbl': {'type': 'literal', 'value': 'BCN+ELMo'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122623'}, 'model_lbl': {'type': 'literal', 'value': 'BCN+ELMo'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
163,What evaluation metrics are commonly used when benchmarking models on the ARC-PDN dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ARC-PDN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ARC-PDN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9807524085044861, 0.9754234552383423, 0.978080689907074)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
164,Which QA benchmarks incorporating more than 10000 questions?,"SELECT ?papers, ?papers_labels
WHERE {
  ?papers rdf:type orkgc:Paper;
          orkgp:P31 ?contrib;
          rdfs:label ?papers_labels.
  ?contrib orkgp:P41923 ?questions_number_str.
  BIND(REPLACE(?questions_number_str, ""[+]"", """") AS ?questions_number_preprocessed)
  BIND(xsd:integer(REPLACE(?questions_number_preprocessed, """","""", """")) AS ?questions_number)
  FILTER(?questions_number > 10000)
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?dataset a orkgc:Dataset;
           rdfs:label ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  
}
ORDER BY DESC(?value)
LIMIT 1",3.6231213058724153e-155,0.6363636363636364,"(0.8619124889373779, 0.8589844703674316, 0.8604459762573242)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120855'}, 'dataset_lbl': {'type': 'literal', 'value': 'QNLI'}}]",,"{'exact_match': False, 'precision': 0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
165,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Berzerk dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9649122807017544,"(0.9833235144615173, 0.9771640300750732, 0.9802340269088745)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
166,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Stanford Cars dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9607843137254902,"(0.9815467596054077, 0.9738684296607971, 0.9776924848556519)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134998'}, 'paper_lbl': {'type': 'literal', 'value': 'Training data-efficient image transformers & distillation through attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135045'}, 'paper_lbl': {'type': 'literal', 'value': 'EfficientNetV2: Smaller Models and Faster Training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135170'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134713'}, 'paper_lbl': {'type': 'literal', 'value': 'Going deeper with Image Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134775'}, 'paper_lbl': {'type': 'literal', 'value': ""LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference""}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134924'}, 'paper_lbl': {'type': 'literal', 'value': 'Sharpness-Aware Minimization for Efficiently Improving Generalization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134998'}, 'paper_lbl': {'type': 'literal', 'value': 'Training data-efficient image transformers & distillation through attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135045'}, 'paper_lbl': {'type': 'literal', 'value': 'EfficientNetV2: Smaller Models and Faster Training'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135097'}, 'paper_lbl': {'type': 'literal', 'value': 'Sequential Random Network for Fine-grained Image Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135170'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-grained Visual Categorization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134633'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating Convolution Designs into Visual Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134713'}, 'paper_lbl': {'type': 'literal', 'value': 'Going deeper with Image Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134775'}, 'paper_lbl': {'type': 'literal', 'value': ""LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference""}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134924'}, 'paper_lbl': {'type': 'literal', 'value': 'Sharpness-Aware Minimization for Efficiently Improving Generalization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
167,What are the titles and IDs of research papers that include a benchmark for the BUCC German-to-English dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9636363636363636,"(0.9819813966751099, 0.9744136333465576, 0.9781829118728638)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131694'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131694'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
168,What are the metrics of evaluation over the Stanford Cars dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Stanford Cars"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9615384615384616,"(0.9829189777374268, 0.9767968058586121, 0.9798482656478882)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
169,What are the titles and IDs of research papers that include a benchmark for the ShARe/CLEF eHealth corpus dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9622641509433962,"(0.9814082384109497, 0.9739503264427185, 0.9776650667190552)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
170,For what piezoresistive material the least response time was obtained?,"SELECT ?piezoresistive_materials WHERE {
  orkgr:R138374 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P41021 ?piezoresistive_materials.
  ?contrib orkgp:P41022 ?response_time.
}
ORDER BY ASC(?response_time)
LIMIT 1","SELECT ?material ?material_label
WHERE {
  orkgr:RXXXX orkgp:compareContribution ?contrib.
  ?contrib orkgp:PYYYY ?material;
           orkgp:PZZZZ ?response_time.
  ?material rdfs:label ?material_label.
  ?response_time rdfs:label ?response_time_label.
}
ORDER BY ASC(xsd:float(?response_time_label))
LIMIT 1",3.6758472052604416e-78,0.7288135593220338,"(0.8985854387283325, 0.8778405785560608, 0.8880918622016907)",[],"[{'piezoresistive_materials': {'type': 'literal', 'value': 'Graphene-based cellular elastomer\n(G-elastomer)'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
171,List the code links in papers that use the GPT-2 (small) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GPT-2 (small)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""GPT-2 (small)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9629629629629628,"(0.9838470220565796, 0.9750328063964844, 0.9794200658798218)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
172,List the metrics that are used to evaluate models on the Atari 2600 Fishing Derby benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Fishing Derby"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Fishing Derby"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.9014996327760888,0.9642857142857144,"(0.9808427095413208, 0.9753069281578064, 0.9780670404434204)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
173,What is the best performing model benchmarking the ImageNet dataset in terms of Number of params metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Number of params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9642857142857144,"(0.9816993474960327, 0.9807636737823486, 0.9812312722206116)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126160'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (ResNet)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126160'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (ResNet)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
174,Can you list the models that have been evaluated on the Atari 2600 Battle Zone dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9655172413793104,"(0.9821510910987854, 0.9769313335418701, 0.9795342683792114)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
175,List the code links in papers that use the BiT-M model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.983250617980957, 0.974349856376648, 0.9787800312042236)","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
176,"What is the highest benchmark result achieved on the Atari 2600 Star Gunner dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Star Gunner"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Star Gunner"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9684940092844068,0.9672131147540984,"(0.9814749956130981, 0.9801815748214722, 0.9808278679847717)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '90804.0'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '90804.0'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
177,Can you provide links to code used in papers that benchmark the NASCell model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""NASCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""NASCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9822104573249817, 0.9726970791816711, 0.9774306416511536)","[{'code': {'type': 'literal', 'value': 'https://github.com/tensorflow/models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abcp4/DAPytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YaCpotato/deepaugmentFix'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TreeLimes/QANAS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bschifferer/alphaxenas'}}, {'code': {'type': 'literal', 'value': 'https://github.com/GiuliaLanzillotta/INAS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YaCpotato/B4ResearchDeepaugment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cshannonn/blackscholes_nas'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DataCanvasIO/Hypernets'}}, {'code': {'type': 'literal', 'value': 'https://github.com/barisozmen/deepaugment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/carpedm20/ENAS-pytorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/tensorflow/models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abcp4/DAPytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YaCpotato/deepaugmentFix'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TreeLimes/QANAS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bschifferer/alphaxenas'}}, {'code': {'type': 'literal', 'value': 'https://github.com/GiuliaLanzillotta/INAS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YaCpotato/B4ResearchDeepaugment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cshannonn/blackscholes_nas'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DataCanvasIO/Hypernets'}}, {'code': {'type': 'literal', 'value': 'https://github.com/barisozmen/deepaugment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/carpedm20/ENAS-pytorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
178,Where can I find code references in papers that have used the TCN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""TCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""TCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9830803871154785, 0.9737440347671509, 0.9783899188041687)","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
179,What is the top benchmark result (metric and value) over the dataset BUCC French-to-English?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9661016949152542,"(0.9819291234016418, 0.9808336496353149, 0.9813810586929321)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}, 'score': {'type': 'literal', 'value': '93.91'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}, 'score': {'type': 'literal', 'value': '93.91'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
180,What is the top benchmark result (metric and value) over the dataset SQuAD2.0?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD2.0"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9672131147540984,"(0.9812929630279541, 0.9802298545837402, 0.9807611107826233)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '90.689'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}, 'score': {'type': 'literal', 'value': '87.926'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '90.689'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}, 'score': {'type': 'literal', 'value': '87.926'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
181,What is the top benchmark result (metric and value) over the dataset BC2GM?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC2GM"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC2GM"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9829460382461548, 0.9810365438461304, 0.981990396976471)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}, 'score': {'type': 'literal', 'value': '87.81'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}, 'score': {'type': 'literal', 'value': '87.81'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
182,List the metrics that are used to evaluate models on the Story Cloze Test benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Story Cloze Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9629629629629628,"(0.9825645089149475, 0.976056694984436, 0.979299783706665)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
183,Who has contributed to the largest number of articles about coronavirus?,"SELECT ?author_name
WHERE {
  {
    SELECT (COUNT(?paper_) as ?max_n_papers)
    WHERE {
      ?paper_ a orkgc:Paper;
      rdfs:label ?title_;
      orkgp:P27 ?author_.
      FILTER(REGEX(STR(?title_), ""2019-nCoV""))
    }
    GROUP BY ?author_
    ORDER BY DESC(?max_n_papers)
    LIMIT 1
  }
  ?paper a orkgc:Paper;
  rdfs:label ?title;
  orkgp:P27 ?author.
  OPTIONAL {
    ?author rdfs:label ?author_label
  }
  BIND(IF(BOUND(?author_label), ?author_label, ?author) as ?author_name)
  FILTER(REGEX(STR(?title), ""2019-nCoV""))
}
GROUP BY ?author ?type ?author_name ?max_n_papers
HAVING(COUNT(?paper) = ?max_n_papers)","SELECT DISTINCT ?author ?author_lbl (COUNT(?article) AS ?count)
WHERE {
  ?article a orkgc:Article;
           rdfs:label ?article_lbl;
           orkgp:HAS_AUTHOR ?author.
  ?author rdfs:label ?author_lbl.
  FILTER regex(?article_lbl, ""coronavirus"", ""i"") 
}
GROUP BY ?author ?author_lbl
ORDER BY DESC(?count)
LIMIT 1",0.0565651496535853,0.803030303030303,"(0.8764097690582275, 0.8793551921844482, 0.8778800368309021)",[],"[{'author_name': {'type': 'literal', 'value': 'Guangpu Yang'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
184,What are the models that have been benchmarked on the DuIE dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DuIE"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9818393588066101, 0.9765666127204895, 0.9791958928108215)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116610'}, 'model_lbl': {'type': 'literal', 'value': 'BiTT'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116610'}, 'model_lbl': {'type': 'literal', 'value': 'BiTT'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
185,What coolant does ASTRID reactor use?,"SELECT ?coolant ?coolant_label
WHERE {
  ?ASTRID_reactor ?rdfs_label ""ASTRID""^^xsd:string.
  ?contrib ?reactor_predicate ?ASTRID_reactor.
  ?contrib ?predicates ?coolant.
  ?predicates rdfs:label ?predicates_label.
  FILTER(REGEX(?predicates_label, ""coolant""))
  ?coolant rdfs:label ?coolant_label.
}","SELECT ?coolant ?coolant_label
WHERE {
  ?reactor a orkgp:Reactor;
           rdfs:label ""ASTRID"";
           orkgp:P31 ?type.
  ?type orkgp:P5008 ?coolant. 
  ?coolant rdfs:label ?coolant_label.
}",0.2722483571354569,0.6296296296296297,"(0.8796737194061279, 0.8616516590118408, 0.8705694079399109)",[],"[{'coolant': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R109906'}, 'coolant_label': {'type': 'literal', 'value': 'sodium'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
186,"Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Berzerk dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Berzerk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.967741935483871,"(0.9815078973770142, 0.98023921251297, 0.9808731079101562)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '910.6'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '910.6'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
187,Can you list the models that have been evaluated on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9649122807017544,"(0.9818528890609741, 0.9766508936882019, 0.9792450070381165)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124952'}, 'model_lbl': {'type': 'literal', 'value': 'Go-Explore'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124952'}, 'model_lbl': {'type': 'literal', 'value': 'Go-Explore'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
188,What are the most commonly used benchmark datasets for the Text Summarization research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Text Summarization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Text Summarization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9636363636363636,"(0.9840143918991089, 0.9770405888557434, 0.9805150628089905)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114519'}, 'dataset_lbl': {'type': 'literal', 'value': 'Pubmed'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124736'}, 'dataset_lbl': {'type': 'literal', 'value': 'arXiv'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124737'}, 'dataset_lbl': {'type': 'literal', 'value': 'GigaWord'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124775'}, 'dataset_lbl': {'type': 'literal', 'value': 'AESLC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119716'}, 'dataset_lbl': {'type': 'literal', 'value': 'CNN / Daily Mail'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124725'}, 'dataset_lbl': {'type': 'literal', 'value': 'X-Sum'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124758'}, 'dataset_lbl': {'type': 'literal', 'value': 'CL-SciSumm'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206389'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciTLDR'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114519'}, 'dataset_lbl': {'type': 'literal', 'value': 'Pubmed'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124736'}, 'dataset_lbl': {'type': 'literal', 'value': 'arXiv'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124737'}, 'dataset_lbl': {'type': 'literal', 'value': 'GigaWord'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124775'}, 'dataset_lbl': {'type': 'literal', 'value': 'AESLC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119716'}, 'dataset_lbl': {'type': 'literal', 'value': 'CNN / Daily Mail'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124725'}, 'dataset_lbl': {'type': 'literal', 'value': 'X-Sum'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124758'}, 'dataset_lbl': {'type': 'literal', 'value': 'CL-SciSumm'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206389'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciTLDR'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
189,What are the metrics of evaluation over the Atari 2600 Tutankham dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9642857142857144,"(0.9831973314285278, 0.9767705202102661, 0.9799733757972717)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
190,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Tutankham dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tutankham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9815250039100647, 0.9802764654159546, 0.9809002876281738)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
191,Can you list the models that have been evaluated on the PROTEINS dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PROTEINS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PROTEINS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9622641509433962,"(0.9823144674301147, 0.9768326878547668, 0.9795658588409424)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
192,What is the name of the top performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9649122807017544,"(0.9810711145401001, 0.9797695875167847, 0.980419933795929)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
193,What are the metrics of evaluation over the CommitmentBank dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommitmentBank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommitmentBank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9806033372879028, 0.9751870036125183, 0.9778876900672913)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
194,Can you provide links to code used in papers that benchmark the BiT-M (ResNet) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-M (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9826816320419312, 0.974051833152771, 0.978347659111023)","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
195,What is the best performing model benchmarking the ACE 2004 dataset in terms of RE+ Micro F1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2004"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""RE+ Micro F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2004"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9666666666666668,"(0.9789839386940002, 0.9776766896247864, 0.9783298969268799)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116645'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence ALB'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116645'}, 'model_lbl': {'type': 'literal', 'value': 'Ours: cross-sentence ALB'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
196,What is the top benchmark score and its metric on the Nottingham dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9829528331756592, 0.98093581199646, 0.9819432497024536)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116774'}, 'metric_lbl': {'type': 'literal', 'value': 'NLL'}, 'score': {'type': 'literal', 'value': '4.05'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116774'}, 'metric_lbl': {'type': 'literal', 'value': 'NLL'}, 'score': {'type': 'literal', 'value': '4.05'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
197,What evaluation metrics are commonly used when benchmarking models on the STEM-ECR v1.0 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STEM-ECR v1.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STEM-ECR v1.0"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9636363636363636,"(0.9814680814743042, 0.9751157760620117, 0.9782816171646118)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
198,Can you provide links to code used in papers that benchmark the Multi-Perspective Matching (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.833078701050083,0.9636363636363636,"(0.9838905334472656, 0.9769608974456787, 0.9804134964942932)",[],"[{'code': {'type': 'literal', 'value': 'https://github.com/bloomsburyai/question-generation'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
199,What models are being evaluated on the GAD dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GAD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GAD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9818522930145264, 0.9766262769699097, 0.9792323112487793)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
200,What are the metrics of evaluation over the PubMed 20k RCT dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9636363636363636,"(0.9826648235321045, 0.9762808084487915, 0.9794623851776123)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
201,List the metrics that are used to evaluate models on the Gibson PointGoal Navigation benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9622641509433962,"(0.9827554225921631, 0.9763097763061523, 0.9795219898223877)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123482'}, 'metric_lbl': {'type': 'literal', 'value': 'spl'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123482'}, 'metric_lbl': {'type': 'literal', 'value': 'spl'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
202,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AAPD dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AAPD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AAPD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9607843137254902,"(0.9820231199264526, 0.9743509292602539, 0.9781720042228699)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134423'}, 'paper_lbl': {'type': 'literal', 'value': 'DocBERT: BERT for Document Classification'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134423'}, 'paper_lbl': {'type': 'literal', 'value': 'DocBERT: BERT for Document Classification'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
203,Where can I find code references in papers that have used the AxCell model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AxCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AxCell"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9822632670402527, 0.9727628231048584, 0.9774899482727051)","[{'code': {'type': 'literal', 'value': 'https://github.com/paperswithcode/axcell'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/paperswithcode/axcell'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
204,Can you provide links to code used in papers that benchmark the AWD-LSTM model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AWD-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""AWD-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9834237694740295, 0.9746751189231873, 0.9790298938751221)","[{'code': {'type': 'literal', 'value': 'https://github.com/castorini/hedwig'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/lookahead-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/awd-lstm-test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/soyoung97/awd-lstm-gru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arvieFrydenlund/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/llppff/ptb-lstmorqrnn-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Asteur/RERITES-AvgWeightDescentLSTM-PoetryGeneration'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ari-holtzman/genlm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/treelangrnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SachinIchake/KALM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jhave/RERITES-AvgWeightDescentLSTM-PoetryGeneration'}}, {'code': {'type': 'literal', 'value': 'https://github.com/uclanlp/NamedEntityLanguageModel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/salesforce/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nkcr/overlap-ml'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tdmeeste/SparseSeqModels'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cstorm125/thai2fit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JessikaSmith/language_model'}}, {'code': {'type': 'literal', 'value': 'https://github.com/uchange/ulangel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/varshinireddyt/ULMFiT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muellerzr/CodeFest_2019'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vganesh46/awd-lstm-pytorch-implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/liuruoruo/awd-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jkkummerfeld/emnlp20lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BenjiKCF/AWD-LSTM-sentiment-classifier'}}, {'code': {'type': 'literal', 'value': 'https://github.com/S-Abdelnabi/awt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rajs96/ULMFiT-Twitter-US-Airline-Sentiment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NightmareVoid/LSTM_for_EEG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chris-tng/semi-supervised-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ahmetumutdurmus/awd-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/idiap/drill'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/awd-lstm-tensorflow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Noahs-ARK/groc'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexandra-chron/ntua-slp-wassa-iest2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexandra-chron/wassa-2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mamamot/Russian-ULMFit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/noise-field/Russian-ULMFit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/AggMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajjwal1/language-modelling'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Han-JD/GRU-D'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iwangjian/ByteCup2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/castorini/Castor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/google-research/tree/master/enas_lm'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/castorini/hedwig'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/lookahead-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/awd-lstm-test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/soyoung97/awd-lstm-gru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arvieFrydenlund/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/llppff/ptb-lstmorqrnn-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Asteur/RERITES-AvgWeightDescentLSTM-PoetryGeneration'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ari-holtzman/genlm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/treelangrnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SachinIchake/KALM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jhave/RERITES-AvgWeightDescentLSTM-PoetryGeneration'}}, {'code': {'type': 'literal', 'value': 'https://github.com/uclanlp/NamedEntityLanguageModel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/salesforce/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nkcr/overlap-ml'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tdmeeste/SparseSeqModels'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cstorm125/thai2fit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JessikaSmith/language_model'}}, {'code': {'type': 'literal', 'value': 'https://github.com/uchange/ulangel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/varshinireddyt/ULMFiT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muellerzr/CodeFest_2019'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vganesh46/awd-lstm-pytorch-implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/liuruoruo/awd-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jkkummerfeld/emnlp20lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BenjiKCF/AWD-LSTM-sentiment-classifier'}}, {'code': {'type': 'literal', 'value': 'https://github.com/S-Abdelnabi/awt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rajs96/ULMFiT-Twitter-US-Airline-Sentiment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NightmareVoid/LSTM_for_EEG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chris-tng/semi-supervised-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ahmetumutdurmus/awd-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/idiap/drill'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/awd-lstm-tensorflow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Noahs-ARK/groc'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexandra-chron/ntua-slp-wassa-iest2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexandra-chron/wassa-2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mamamot/Russian-ULMFit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/noise-field/Russian-ULMFit'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/AggMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajjwal1/language-modelling'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Han-JD/GRU-D'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iwangjian/ByteCup2018'}}, {'code': {'type': 'literal', 'value': 'https://github.com/castorini/Castor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/google-research/tree/master/enas_lm'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
205,What are the titles and IDs of research papers that include a benchmark for the PubMedQA dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMedQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMedQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9824844598770142, 0.9748513102531433, 0.9786530137062073)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
206,Name the datasets that have been used for benchmarking in the Image Classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9615384615384616,"(0.981421709060669, 0.9743568897247314, 0.9778765439987183)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116789'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116792'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-100'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121347'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126694'}, 'dataset_lbl': {'type': 'literal', 'value': 'SVHN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117710'}, 'dataset_lbl': {'type': 'literal', 'value': 'Fashion-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126717'}, 'dataset_lbl': {'type': 'literal', 'value': 'Flowers-102'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123801'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford-IIIT Pets'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126249'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet ReaL'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126722'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2018'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117830'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford 102 Flowers'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117682'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Cars'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119383'}, 'dataset_lbl': {'type': 'literal', 'value': 'CUB-200-2011'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117572'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Dogs'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123732'}, 'dataset_lbl': {'type': 'literal', 'value': 'FGVC Aircraft'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123808'}, 'dataset_lbl': {'type': 'literal', 'value': 'Food-101'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126031'}, 'dataset_lbl': {'type': 'literal', 'value': 'VTAB-1k'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126667'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet (Bounding Box)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126744'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126080'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2019'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126096'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet V2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126098'}, 'dataset_lbl': {'type': 'literal', 'value': 'Kuzushiji-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114182'}, 'dataset_lbl': {'type': 'literal', 'value': 'MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117736'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126855'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10, 1000 Labels'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126832'}, 'dataset_lbl': {'type': 'literal', 'value': 'Birdsnap'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116789'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116792'}, 'dataset_lbl': {'type': 'literal', 'value': 'CIFAR-100'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121347'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126694'}, 'dataset_lbl': {'type': 'literal', 'value': 'SVHN'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117710'}, 'dataset_lbl': {'type': 'literal', 'value': 'Fashion-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126717'}, 'dataset_lbl': {'type': 'literal', 'value': 'Flowers-102'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123801'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford-IIIT Pets'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126249'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet ReaL'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126722'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2018'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117830'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford 102 Flowers'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117682'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Cars'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119383'}, 'dataset_lbl': {'type': 'literal', 'value': 'CUB-200-2011'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117572'}, 'dataset_lbl': {'type': 'literal', 'value': 'Stanford Dogs'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123732'}, 'dataset_lbl': {'type': 'literal', 'value': 'FGVC Aircraft'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123808'}, 'dataset_lbl': {'type': 'literal', 'value': 'Food-101'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126031'}, 'dataset_lbl': {'type': 'literal', 'value': 'VTAB-1k'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126667'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet (Bounding Box)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126744'}, 'dataset_lbl': {'type': 'literal', 'value': 'ObjectNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126080'}, 'dataset_lbl': {'type': 'literal', 'value': 'iNaturalist 2019'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126096'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet V2'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126098'}, 'dataset_lbl': {'type': 'literal', 'value': 'Kuzushiji-MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114182'}, 'dataset_lbl': {'type': 'literal', 'value': 'MNIST'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117736'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126855'}, 'dataset_lbl': {'type': 'literal', 'value': 'STL-10, 1000 Labels'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126832'}, 'dataset_lbl': {'type': 'literal', 'value': 'Birdsnap'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
207,"Can you provide the highest benchmark result, including the metric and score, for the Gibson PointGoal Navigation dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Gibson PointGoal Navigation"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9655172413793104,"(0.9815042018890381, 0.9803141355514526, 0.9809088110923767)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123482'}, 'metric_lbl': {'type': 'literal', 'value': 'spl'}, 'score': {'type': 'literal', 'value': '0.917'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123482'}, 'metric_lbl': {'type': 'literal', 'value': 'spl'}, 'score': {'type': 'literal', 'value': '0.917'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
208,"Which model has achieved the highest Score score on the Cheetah, run (DMControl500k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9831647872924805, 0.9810736775398254, 0.9821181893348694)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
209,What is the top benchmark score and its metric on the Stanford Dogs dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Dogs"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Dogs"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9655172413793104,"(0.9830742478370667, 0.9811486005783081, 0.9821104407310486)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
210,Indicate the model that performed best in terms of Senseval 2 metric on the Supervised: benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Senseval 2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Senseval 2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.983109712600708, 0.9820069074630737, 0.982558012008667)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120662'}, 'model_lbl': {'type': 'literal', 'value': 'ELMo'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120662'}, 'model_lbl': {'type': 'literal', 'value': 'ELMo'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
211,Indicate the model that performed best in terms of Test perplexity metric on the WikiText-103 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-103"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Test perplexity"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WikiText-103"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9672131147540984,"(0.9806355834007263, 0.9795043468475342, 0.980069637298584)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114443'}, 'model_lbl': {'type': 'literal', 'value': 'LSTM'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114443'}, 'model_lbl': {'type': 'literal', 'value': 'LSTM'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
212,"What is the highest benchmark result achieved on the WMT2016 English-Russian dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9682539682539684,"(0.9814286231994629, 0.9801546335220337, 0.9807912111282349)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '7.98'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '7.98'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
213,What is the most common lead compound?,"SELECT ?compound
WHERE {
  orkgr:R75638 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P35194 ?compound.
}
ORDER BY DESC(COUNT(?compound))
LIMIT 1","SELECT ?compound
WHERE {
  orkgr:R135371 orkgp:compareContribution ?cont.
  ?cont orkgp:P15687 ?compound.
}
ORDER BY DESC(COUNT(?compound))
LIMIT 1",0.4763100914774507,0.8867924528301887,"(0.9643049240112305, 0.9434783458709717, 0.9537779688835144)",,,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
214,What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Enduro dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9834160804748535, 0.9824040532112122, 0.9829098582267761)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
215,Provide a list of papers that have utilized the C51 noop model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""C51 noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""C51 noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9836041927337646, 0.9746204614639282, 0.9790917038917542)","[{'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kochlisGit/autonomous-vehicles-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kchu/DeepRL_CK'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Stable-Baselines-Team/stable-baselines3-contrib'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/dist-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DistRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PierreAlexSW/distributional_rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/parilo/gym_bipedal_walker_v2_solution'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pihey1995/DistributionalRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shuli0808/DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eric-yim/fin_map'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kochlisGit/autonomous-vehicles-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kchu/DeepRL_CK'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Stable-Baselines-Team/stable-baselines3-contrib'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/dist-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DistRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PierreAlexSW/distributional_rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/parilo/gym_bipedal_walker_v2_solution'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pihey1995/DistributionalRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shuli0808/DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eric-yim/fin_map'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
216,Can you provide links to code used in papers that benchmark the FABIR model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FABIR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FABIR"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9834128022193909, 0.9743672609329224, 0.9788690805435181)","[{'code': {'type': 'literal', 'value': 'https://github.com/AlCorreia/FABIR'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/AlCorreia/FABIR'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
217,What is the emergency type of AMBER Alert?,"SELECT DISTINCT ?emergency_type
WHERE {
  orkgr:R153500 orkgp:P31 ?contrib.
  ?contrib orkgp:P43093 ?emergency_type.
}","SELECT DISTINCT ?emergencyType ?emergencyTypeLabel
WHERE {
  orkgr:AMBERAlert orkgp:P1526 ?emergencyType.
  ?emergencyType rdfs:label ?emergencyTypeLabel.
}",7.505697654413981e-155,0.673469387755102,"(0.9215668439865112, 0.9196240305900574, 0.9205944538116455)",[],"[{'emergency_type': {'type': 'literal', 'value': 'Child Abductions'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
218,List the metrics that are used to evaluate models on the CoQA benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CoQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CoQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9622641509433962,"(0.9829612970352173, 0.9768522381782532, 0.9798972010612488)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118414'}, 'metric_lbl': {'type': 'literal', 'value': 'Overall'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118414'}, 'metric_lbl': {'type': 'literal', 'value': 'Overall'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
219,Indicate the model that performed best in terms of F1 metric on the OntoNotes benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""OntoNotes"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""OntoNotes"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9642857142857144,"(0.9819583296775818, 0.9809122085571289, 0.9814350008964539)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122119'}, 'model_lbl': {'type': 'literal', 'value': 'He et al., 2017 + ELMo'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122119'}, 'model_lbl': {'type': 'literal', 'value': 'He et al., 2017 + ELMo'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
220,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Defender dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9636363636363636,"(0.9824599027633667, 0.9750565886497498, 0.9787442684173584)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
221,Where can I find code references in papers that have used the Pointer + Coverage + EntailmentGen + QuestionGen model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Pointer + Coverage + EntailmentGen + QuestionGen"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Pointer + Coverage + EntailmentGen + QuestionGen"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9383861709333506,0.9649122807017544,"(0.983341634273529, 0.9747769236564636, 0.9790405035018921)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
222,Provide a list of papers that have utilized the Switch Transformer model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Switch Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Switch Transformer"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9832863807678223, 0.9742506742477417, 0.9787476658821106)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
223,Can you list the models that have been evaluated on the CommonsenseQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9824537038803101, 0.977260947227478, 0.9798504710197449)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120581'}, 'model_lbl': {'type': 'literal', 'value': 'QA-GNN'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120581'}, 'model_lbl': {'type': 'literal', 'value': 'QA-GNN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
224,What evaluation metrics are commonly used when benchmarking models on the Amazon-2 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9636363636363636,"(0.9826788902282715, 0.9762325286865234, 0.9794450998306274)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
225,List the code links in papers that use the A3C-CTS model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C-CTS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C-CTS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.983500599861145, 0.9743956923484802, 0.9789270162582397)","[{'code': {'type': 'literal', 'value': 'https://github.com/RLAgent/state-marginal-matching'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/RLAgent/state-marginal-matching'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
226,What is the top benchmark score and its metric on the Hutter Prize dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Hutter Prize"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Hutter Prize"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9661016949152542,"(0.9828813672065735, 0.9809030890464783, 0.9818912744522095)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}, 'score': {'type': 'literal', 'value': '88M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}, 'score': {'type': 'literal', 'value': '1.277'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}, 'score': {'type': 'literal', 'value': '88M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}, 'score': {'type': 'literal', 'value': '1.277'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
227,Which model has achieved the highest F1 score on the CoNLL 2003 (English) benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2003 (English)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL 2003 (English)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9069443196104878,0.9661016949152542,"(0.9821799397468567, 0.9808211326599121, 0.9815000891685486)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116584'}, 'model_lbl': {'type': 'literal', 'value': 'LUKE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116584'}, 'model_lbl': {'type': 'literal', 'value': 'LUKE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
228,What is the name of the top performing model in terms of Params score when benchmarked on the VTAB-1k dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""VTAB-1k"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9831575155258179, 0.9822089672088623, 0.982683002948761)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126033'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (50 hypers/task)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
229,Can you list benchmarked problems in the area of Artificial Intelligence?,"SELECT DISTINCT ?problem ?problem_lbl
WHERE {
  ?rf       a            orkgc:ResearchField;
            rdfs:label   ?rf_label.
  FILTER (str(?rf_label) = ""Artificial Intelligence"")
  ?paper    orkgp:P30    ?rf;
            orkgp:P31    ?cont.
  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                orkgp:P32                ?problem.
  ?problem      rdfs:label               ?problem_lbl.
}","SELECT DISTINCT ?problem ?problem_lbl
WHERE {
  ?rf       a            orkgc:ResearchField;
            rdfs:label   ?rf_label.
  FILTER (str(?rf_label) = ""Artificial Intelligence"")
  ?paper    orkgp:P30    ?rf;
            orkgp:P31    ?cont.
  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                orkgp:P32                ?problem.
  ?problem      rdfs:label               ?problem_lbl.
}",0.9343348130467294,0.9629629629629628,"(0.9824908971786499, 0.9742071628570557, 0.9783315062522888)","[{'problem': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116569'}, 'problem_lbl': {'type': 'literal', 'value': 'Relation Extraction'}}]","[{'problem': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116569'}, 'problem_lbl': {'type': 'literal', 'value': 'Relation Extraction'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
230,What are the models that have been benchmarked on the FSNS - Test dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FSNS - Test"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9629629629629628,"(0.9822402000427246, 0.9771521091461182, 0.9796895384788513)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114164'}, 'model_lbl': {'type': 'literal', 'value': 'AttentionOCR_Inception-resnet-v2_Location'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114166'}, 'model_lbl': {'type': 'literal', 'value': 'SEE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114167'}, 'model_lbl': {'type': 'literal', 'value': 'STREET'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114164'}, 'model_lbl': {'type': 'literal', 'value': 'AttentionOCR_Inception-resnet-v2_Location'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114166'}, 'model_lbl': {'type': 'literal', 'value': 'SEE'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114167'}, 'model_lbl': {'type': 'literal', 'value': 'STREET'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
231,What is the best performing model benchmarking the WMT2014 German-English dataset in terms of BLEU metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9672131147540984,"(0.983304500579834, 0.9821993708610535, 0.9827516078948975)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117221'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+4 iterations'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117221'}, 'model_lbl': {'type': 'literal', 'value': 'CMLM+LAT+4 iterations'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
232,Can you provide links to code used in papers that benchmark the BiLSTM-Attention + ELMo model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiLSTM-Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiLSTM-Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9622641509433962,"(0.9838231801986694, 0.9748488068580627, 0.9793154001235962)","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
233,"What is the highest benchmark result achieved on the STS Benchmark dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""STS Benchmark"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""STS Benchmark"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9655172413793104,"(0.9815637469291687, 0.9795452952384949, 0.9805535078048706)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115359'}, 'metric_lbl': {'type': 'literal', 'value': 'Pearson Correlation'}, 'score': {'type': 'literal', 'value': '0.925'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115359'}, 'metric_lbl': {'type': 'literal', 'value': 'Pearson Correlation'}, 'score': {'type': 'literal', 'value': '0.925'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
234,Provide a list of papers that have utilized the Shake-Shake (SAM) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Shake-Shake (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Shake-Shake (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.982559084892273, 0.9737210273742676, 0.9781200885772705)","[{'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/SAM-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jannoshh/simple-sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/moskomule/sam.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/davda54/sam'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/SAM-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jannoshh/simple-sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/moskomule/sam.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/davda54/sam'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
235,What are the most commonly used benchmark datasets for the Joint Entity and Relation Extraction research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Joint Entity and Relation Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Joint Entity and Relation Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9402297675816912,0.9636363636363636,"(0.9832241535186768, 0.9763320684432983, 0.9797659516334534)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116695'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciERC'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116695'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciERC'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
236,What evaluation metrics are commonly used when benchmarking models on the MultiRC dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiRC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MultiRC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9804392457008362, 0.9751139283180237, 0.9777693152427673)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119493'}, 'metric_lbl': {'type': 'literal', 'value': 'F1a'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119493'}, 'metric_lbl': {'type': 'literal', 'value': 'F1a'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
237,Where can I find code references in papers that have used the SRU++ Base model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SRU++ Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""SRU++ Base"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9836143851280212, 0.9747359752655029, 0.9791550040245056)","[{'code': {'type': 'literal', 'value': 'https://github.com/asappresearch/sru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/taolei87/sru'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/asappresearch/sru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/taolei87/sru'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
238,Indicate the model that performed best in terms of Score metric on the Atari 2600 Asteroids benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Asteroids"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Asteroids"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9835422039031982, 0.9825319647789001, 0.9830367565155029)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
239,List the title and ID of research papers that contain a benchmark over the WMT2014 German-English dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9649122807017544,"(0.9814956188201904, 0.9741204977035522, 0.9777941107749939)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129825'}, 'paper_lbl': {'type': 'literal', 'value': 'An Effective Approach to Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129839'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with SMT as Posterior Regularization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129725'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Statistical Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129742'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating a Local Translation Mechanism into Non-autoregressive Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129761'}, 'paper_lbl': {'type': 'literal', 'value': 'Non-Autoregressive Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129773'}, 'paper_lbl': {'type': 'literal', 'value': 'Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129825'}, 'paper_lbl': {'type': 'literal', 'value': 'An Effective Approach to Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129839'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with SMT as Posterior Regularization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129725'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Statistical Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129742'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating a Local Translation Mechanism into Non-autoregressive Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129761'}, 'paper_lbl': {'type': 'literal', 'value': 'Non-Autoregressive Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129773'}, 'paper_lbl': {'type': 'literal', 'value': 'Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
240,What are the models that have been benchmarked on the SearchQA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SearchQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SearchQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9822349548339844, 0.9768155813217163, 0.9795177578926086)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119441'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Attention'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119444'}, 'model_lbl': {'type': 'literal', 'value': 'DrQA'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119441'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Attention'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119438'}, 'model_lbl': {'type': 'literal', 'value': 'Cluster-Former (#C=512)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119444'}, 'model_lbl': {'type': 'literal', 'value': 'DrQA'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
241,What are the metrics of evaluation over the OntoNotes dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""OntoNotes"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""OntoNotes"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9615384615384616,"(0.9829267859458923, 0.9767548441886902, 0.9798310995101929)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
242,What are the metrics of evaluation over the Atari 2600 Defender dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Defender"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9636363636363636,"(0.9831488728523254, 0.9769511222839355, 0.9800401926040649)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
243,"What is the highest benchmark result achieved on the WMT2014 English-German dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9682539682539684,"(0.9812357425689697, 0.9799791574478149, 0.9806070327758789)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '29.52'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}, 'score': {'type': 'literal', 'value': '22.5'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '29.52'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}, 'score': {'type': 'literal', 'value': '22.5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
244,What are the titles and IDs of research papers that include a benchmark for the PWC Leaderboards (restricted) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9615384615384616,"(0.9813270568847656, 0.9732812643051147, 0.9772875905036926)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135186'}, 'paper_lbl': {'type': 'literal', 'value': 'AxCell: Automatic Extraction of Results from Machine Learning Papers'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R135186'}, 'paper_lbl': {'type': 'literal', 'value': 'AxCell: Automatic Extraction of Results from Machine Learning Papers'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
245,List the metrics that are used to evaluate models on the enwik8 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9629629629629628,"(0.9802075624465942, 0.9749351143836975, 0.9775642156600952)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
246,What evaluation metrics are commonly used when benchmarking models on the TempEval-3 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9629629629629628,"(0.9833722710609436, 0.9771915078163147, 0.9802721738815308)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121393'}, 'metric_lbl': {'type': 'literal', 'value': 'Temporal awareness'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121393'}, 'metric_lbl': {'type': 'literal', 'value': 'Temporal awareness'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
247,What is the most common location in the studies?,"SELECT ?locations
WHERE {
  orkgr:R111045 orkgp:compareContribution ?cont.
  ?cont orkgp:P37537 ?locations.
}
ORDER BY DESC(COUNT(?locations))
LIMIT 1","SELECT ?location, ?location_labels
WHERE {
  orkgr:R155621 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P37580 ?location.
  ?location rdfs:label ?location_labels.
}
ORDER BY DESC(COUNT(?location))
LIMIT 1",3.051362047617549e-78,0.8245614035087719,"(0.9507081508636475, 0.9152103662490845, 0.9326215982437134)",,,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
248,Provide a list of papers that have utilized the BCN+ELMo model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BCN+ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BCN+ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9827741384506226, 0.973684549331665, 0.9782082438468933)","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
249,Indicate the model that performed best in terms of Pre-Training Dataset metric on the HMDB51 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Pre-Training Dataset"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""HMDB51"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""PRE-TRAINING DATASET"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""HMDB51"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9036816878108536,0.95,"(0.983911395072937, 0.982207179069519, 0.9830585718154907)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118783'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Kinetics)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118783'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Kinetics)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
250,"Can you list the models that have been evaluated on the Classical music, 5 seconds at 12 kHz dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classical music, 5 seconds at 12 kHz"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}",0.9466178497997028,0.9666666666666668,"(0.9838171005249023, 0.9775617718696594, 0.9806795120239258)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117688'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Transformer 152M (strided)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117688'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Transformer 152M (strided)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
251,Indicate the model that performed best in terms of BLEU score metric on the IWSLT2014 German-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2014 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9840457439422607, 0.9823060035705566, 0.9831750988960266)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117154'}, 'model_lbl': {'type': 'literal', 'value': 'Rfa-Gate-arccos'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117154'}, 'model_lbl': {'type': 'literal', 'value': 'Rfa-Gate-arccos'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
252,Indicate the model that performed best in terms of F1 metric on the BC5CDR-disease benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-disease"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9823430776596069, 0.9809515476226807, 0.9816468358039856)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116679'}, 'model_lbl': {'type': 'literal', 'value': 'PubMedBERT uncased'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
253,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9636363636363636,"(0.9833909273147583, 0.9771872758865356, 0.980279266834259)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
254,List the title and ID of research papers that contain a benchmark over the Atari 2600 Frostbite dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9636363636363636,"(0.9818195104598999, 0.9742221832275391, 0.97800612449646)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134062'}, 'paper_lbl': {'type': 'literal', 'value': 'Playing Atari with Six Neurons'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134084'}, 'paper_lbl': {'type': 'literal', 'value': 'Soft Actor-Critic for Discrete Action Settings'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134238'}, 'paper_lbl': {'type': 'literal', 'value': 'Model-Free Episodic Control with State Aggregation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134302'}, 'paper_lbl': {'type': 'literal', 'value': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134360'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration in Feature Space for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134401'}, 'paper_lbl': {'type': 'literal', 'value': 'Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133383'}, 'paper_lbl': {'type': 'literal', 'value': 'Value Prediction Network'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134062'}, 'paper_lbl': {'type': 'literal', 'value': 'Playing Atari with Six Neurons'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134084'}, 'paper_lbl': {'type': 'literal', 'value': 'Soft Actor-Critic for Discrete Action Settings'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134238'}, 'paper_lbl': {'type': 'literal', 'value': 'Model-Free Episodic Control with State Aggregation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134302'}, 'paper_lbl': {'type': 'literal', 'value': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134360'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration in Feature Space for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134401'}, 'paper_lbl': {'type': 'literal', 'value': 'Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133383'}, 'paper_lbl': {'type': 'literal', 'value': 'Value Prediction Network'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
255,Can you provide links to code used in papers that benchmark the COMET - Direct model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""COMET - Direct"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""COMET - Direct"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9615384615384616,"(0.9833924770355225, 0.9744545221328735, 0.9789031147956848)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
256,Could you provide a list of models that have been tested on the BUCC Russian-to-English benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9642857142857144,"(0.9820220470428467, 0.9767739772796631, 0.9793909788131714)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
257,"What is the highest benchmark result achieved on the Atari 2600 Boxing dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.967741935483871,"(0.9824368357658386, 0.9803938865661621, 0.981414258480072)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '99.6'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '99.6'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
258,Which model has achieved the highest F1 score score on the Penn Treebank benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1 score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Penn Treebank"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9210921090251244,0.9649122807017544,"(0.9804097414016724, 0.9797720313072205, 0.9800907969474792)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116338'}, 'model_lbl': {'type': 'literal', 'value': 'SpanRel'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116338'}, 'model_lbl': {'type': 'literal', 'value': 'SpanRel'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
259,"Can you provide the highest benchmark result, including the metric and score, for the IWSLT2015 German-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2015 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""IWSLT2015 German-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9682539682539684,"(0.9801309108734131, 0.9794345498085022, 0.9797825813293457)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '35.18'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '35.18'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
260,What are the metrics of evaluation over the Atari 2600 Frostbite dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Frostbite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9636363636363636,"(0.9830511808395386, 0.9766565561294556, 0.9798434376716614)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124949'}, 'metric_lbl': {'type': 'literal', 'value': 'Best Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124949'}, 'metric_lbl': {'type': 'literal', 'value': 'Best Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
261,What is the top benchmark score and its metric on the MultiNLI dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MultiNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MultiNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9830392599105835, 0.981082558631897, 0.9820599555969238)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120731'}, 'metric_lbl': {'type': 'literal', 'value': 'Matched'}, 'score': {'type': 'literal', 'value': '90.8'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120731'}, 'metric_lbl': {'type': 'literal', 'value': 'Matched'}, 'score': {'type': 'literal', 'value': '90.8'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
262,Can you list the models that have been evaluated on the ImageNet ReaL dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9622641509433962,"(0.9821377992630005, 0.977008044719696, 0.979566216468811)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126253'}, 'model_lbl': {'type': 'literal', 'value': 'CvT-W24 (384 res, ImageNet-22k pretrain)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126162'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126257'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B-384'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126262'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126263'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-Ti'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126043'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126034'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-H/14'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126037'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126084'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126097'}, 'model_lbl': {'type': 'literal', 'value': 'CAIT-M36-448'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126087'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-T'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126259'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-S (384 finetune res)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126086'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-384'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126088'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-256'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126089'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-192'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126090'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-128'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126091'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-128S'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126253'}, 'model_lbl': {'type': 'literal', 'value': 'CvT-W24 (384 res, ImageNet-22k pretrain)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126162'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126257'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B-384'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126262'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126263'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-Ti'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126043'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126034'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-H/14'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126037'}, 'model_lbl': {'type': 'literal', 'value': 'ViT-L/16'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126084'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-S'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126097'}, 'model_lbl': {'type': 'literal', 'value': 'CAIT-M36-448'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126087'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-T'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126259'}, 'model_lbl': {'type': 'literal', 'value': 'CeiT-S (384 finetune res)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126086'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-384'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126088'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-256'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126089'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-192'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126090'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-128'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126091'}, 'model_lbl': {'type': 'literal', 'value': 'LeViT-128S'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
263,Which model has achieved the highest Accuracy score on the Reuters En-De benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reuters En-De"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reuters En-De"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9655172413793104,"(0.9834256172180176, 0.9825572967529297, 0.9829912185668945)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125980'}, 'model_lbl': {'type': 'literal', 'value': 'BilBOWA'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125980'}, 'model_lbl': {'type': 'literal', 'value': 'BilBOWA'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
264,"Can you provide the highest benchmark result, including the metric and score, for the Kinetics-600 dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kinetics-600"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Kinetics-600"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9672131147540984,"(0.9819111824035645, 0.9798276424407959, 0.9808683395385742)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}, 'score': {'type': 'literal', 'value': '55.5'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}, 'score': {'type': 'literal', 'value': '55.5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
265,List the metrics that are used to evaluate models on the Yelp-5 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp-5"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp-5"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9636363636363636,"(0.9824780225753784, 0.9763045310974121, 0.9793815612792969)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
266,Provide a list of papers that have utilized the BART model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BART"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BART"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9838787317276001, 0.9751061201095581, 0.9794727563858032)","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jiacheng-xu/text-sum-uncertainty'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HHousen/TransformerSum'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fwbrandao/Abstractive_Summarisation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/timrozday/spl-indications-bart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/priyamtejaswin/multistep-retrieve-summarize'}}, {'code': {'type': 'literal', 'value': 'https://github.com/i2r-simmc/i2r-simmc-2020'}}, {'code': {'type': 'literal', 'value': 'https://github.com/awalther/scibart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huangxt39/BART_on_COVID_dialogue'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mcao610/Factual-Error-Correction'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tanyuqian/aspect-based-summarization'}}, {'code': {'type': 'literal', 'value': 'https://github.com/W4ngatang/qags'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Yale-LILY/dart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/GENRE'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jiacheng-xu/text-sum-uncertainty'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HHousen/TransformerSum'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fwbrandao/Abstractive_Summarisation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/timrozday/spl-indications-bart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/priyamtejaswin/multistep-retrieve-summarize'}}, {'code': {'type': 'literal', 'value': 'https://github.com/i2r-simmc/i2r-simmc-2020'}}, {'code': {'type': 'literal', 'value': 'https://github.com/awalther/scibart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huangxt39/BART_on_COVID_dialogue'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mcao610/Factual-Error-Correction'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tanyuqian/aspect-based-summarization'}}, {'code': {'type': 'literal', 'value': 'https://github.com/W4ngatang/qags'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Yale-LILY/dart'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/GENRE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
267,What is the top benchmark score and its metric on the Natural Questions (short) dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (short)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9661016949152542,"(0.9821056127548218, 0.9804835915565491, 0.9812939167022705)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '57.2'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '57.2'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
268,What evaluation metrics are commonly used when benchmarking models on the Sequential CIFAR-10 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9821428571428572,"(0.9825376272201538, 0.9761160612106323, 0.9793162941932678)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127017'}, 'metric_lbl': {'type': 'literal', 'value': 'Unpermuted Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127017'}, 'metric_lbl': {'type': 'literal', 'value': 'Unpermuted Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
269,What is the top benchmark score and its metric on the Automatically labeled Medline abstracts corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9689827775496296,0.9661016949152542,"(0.9815180897712708, 0.9806102514266968, 0.9810639023780823)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
270,Name the datasets that have been used for benchmarking in the citation classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""citation classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Citation Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.8169276475307028,0.9615384615384616,"(0.9821852445602417, 0.9751371145248413, 0.9786484837532043)",[],"[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206159'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206124'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
271,List the code links in papers that use the H-NLI model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""H-NLI"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""H-NLI"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9823636412620544, 0.9728162288665771, 0.9775665998458862)","[{'code': {'type': 'literal', 'value': 'https://github.com/Ishani-Mondal/SciKG'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Ishani-Mondal/SciKG'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
272,What are the titles and IDs of research papers that include a benchmark for the PubMed 20k RCT dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PubMed 20k RCT"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9629629629629628,"(0.9812565445899963, 0.973609209060669, 0.9774179458618164)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
273,"Indicate the model that performed best in terms of Macro Recall metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Recall"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Macro Recall"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9669306597086388,0.967741935483871,"(0.9827834367752075, 0.9817357063293457, 0.9822593331336975)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
274,What is the name of the top performing model in terms of NLL score when benchmarked on the Nottingham dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""NLL"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""NLL"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Nottingham"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0.9196822664155296,0.9642857142857144,"(0.9818657636642456, 0.9807496666908264, 0.9813073873519897)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120964'}, 'model_lbl': {'type': 'literal', 'value': 'R-Transformer'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116147'}, 'model_lbl': {'type': 'literal', 'value': 'RNN'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
275,Where can I find code references in papers that have used the DCN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DCN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9838439226150513, 0.9747118949890137, 0.9792565703392029)","[{'code': {'type': 'literal', 'value': 'https://github.com/andreiilie1/dynamic_coattention_networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wasimusu/MachineRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AdvancedML-Project-Dynamic-Coattention-Networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AML-Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lmn-extracts/dcn_plus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/andreiilie1/dynamic_coattention_networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wasimusu/MachineRC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AdvancedML-Project-Dynamic-Coattention-Networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Lou1sM/AML-Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lmn-extracts/dcn_plus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BAJUKA/SQuAD-NLP'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
276,What is the best performing model benchmarking the iNaturalist 2018 dataset in terms of Top-1 Accuracy metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""iNaturalist 2018"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""iNaturalist 2018"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9838883876800537, 0.9826709628105164, 0.9832792282104492)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126162'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126162'}, 'model_lbl': {'type': 'literal', 'value': 'DeiT-B'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
277,What is the top benchmark score and its metric on the Atari 2600 Ice Hockey dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Ice Hockey"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Ice Hockey"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9684940092844068,0.967741935483871,"(0.9822025299072266, 0.9805777072906494, 0.9813894033432007)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '17.3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '17.3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
278,Provide a list of benchmarked datasets related to the Scientific Results Extraction research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Scientific Results Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Scientific Results Extraction"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9364250605898116,0.9629629629629628,"(0.9833729267120361, 0.9764878749847412, 0.9799183011054993)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128070'}, 'dataset_lbl': {'type': 'literal', 'value': 'PWC Leaderboards (restricted)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128074'}, 'dataset_lbl': {'type': 'literal', 'value': 'NLP-TDMS (Exp, arXiv only)'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128070'}, 'dataset_lbl': {'type': 'literal', 'value': 'PWC Leaderboards (restricted)'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128074'}, 'dataset_lbl': {'type': 'literal', 'value': 'NLP-TDMS (Exp, arXiv only)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
279,"What are the titles and IDs of research papers that include a benchmark for the Walker, walk (DMControl500k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9636363636363636,"(0.9812912940979004, 0.9738512635231018, 0.9775571823120117)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
280,Provide a list of benchmarked datasets related to the Semantic Role Labeling research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Semantic Role Labeling"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Semantic Role Labeling"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9364250605898116,0.9615384615384616,"(0.9831897616386414, 0.9764516353607178, 0.979809045791626)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122117'}, 'dataset_lbl': {'type': 'literal', 'value': 'OntoNotes'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122117'}, 'dataset_lbl': {'type': 'literal', 'value': 'OntoNotes'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
281,Provide a list of research paper titles and IDs that have benchmarked models on the WikiText-2 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WikiText-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WikiText-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9636363636363636,"(0.9816839098930359, 0.97383052110672, 0.9777414798736572)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131069'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Models with a Continuous Cache'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130786'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Neural Sequence Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130803'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models with Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130852'}, 'paper_lbl': {'type': 'literal', 'value': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130871'}, 'paper_lbl': {'type': 'literal', 'value': 'Partially Shuffling the Training Data to Improve Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130890'}, 'paper_lbl': {'type': 'literal', 'value': 'Regularizing and Optimizing LSTM Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130920'}, 'paper_lbl': {'type': 'literal', 'value': 'Fraternal Dropout'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130962'}, 'paper_lbl': {'type': 'literal', 'value': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131048'}, 'paper_lbl': {'type': 'literal', 'value': 'Alleviating Sequence Information Loss with Data Overlapping and Prime Batch Sizes'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129805'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Modeling via Adversarial Training'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131069'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Models with a Continuous Cache'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130786'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Neural Sequence Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130803'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models with Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130817'}, 'paper_lbl': {'type': 'literal', 'value': 'Direct Output Connection for a High-Rank Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130839'}, 'paper_lbl': {'type': 'literal', 'value': 'Improved Language Modeling by Decoding the Past'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130852'}, 'paper_lbl': {'type': 'literal', 'value': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130871'}, 'paper_lbl': {'type': 'literal', 'value': 'Partially Shuffling the Training Data to Improve Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130890'}, 'paper_lbl': {'type': 'literal', 'value': 'Regularizing and Optimizing LSTM Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130920'}, 'paper_lbl': {'type': 'literal', 'value': 'Fraternal Dropout'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130962'}, 'paper_lbl': {'type': 'literal', 'value': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131048'}, 'paper_lbl': {'type': 'literal', 'value': 'Alleviating Sequence Information Loss with Data Overlapping and Prime Batch Sizes'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129805'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Neural Language Modeling via Adversarial Training'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
282,What are the metrics of evaluation over the PWC Leaderboards (restricted) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""PWC Leaderboards (restricted)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9615384615384616,"(0.982158899307251, 0.9756760597229004, 0.9789067506790161)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114479'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro F1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121300'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121301'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro Recall'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114480'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro F1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128072'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128073'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro Recall'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114479'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro F1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121300'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121301'}, 'metric_lbl': {'type': 'literal', 'value': 'Macro Recall'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114480'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro F1'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128072'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128073'}, 'metric_lbl': {'type': 'literal', 'value': 'Micro Recall'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
283,List the code links in papers that use the Duel noop model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Duel noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9836324453353882, 0.9746241569519043, 0.9791075587272644)","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/DeepQNetwork'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nathanin/pad'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kshitij-ingale/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mohit8935/Deep-Q-Learning-Paper'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling_Network_Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling-Network-Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/botforge/simplementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jezzarax/drlnd_p1_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fengsterooni/dql'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shehrum/RL_Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mightypirate1/DRL-Tetris'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZainRaza14/deepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/FaboNo/DRLND'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/Chez'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/chezjulia'}}, {'code': {'type': 'literal', 'value': 'https://github.com/170928/-Review-Dueling-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/opplieam/Pong-Deep-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jsztompka/DuelDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/R-Sweke/DeepQ-Decoding'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gouxiangchen/dueling-DQN-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KDL-umass/saliency_maps'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alessandrositta/Flatland_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Continuous-Control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zynk13/dueling-dqn-Reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abryeemessi/Wednesday'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JBGUIMBAUD/deep-reenforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sirorezka/DeepRL_modules'}}, {'code': {'type': 'literal', 'value': 'https://github.com/manvibharat/Stock-price-pridiction-using-Deep-reienforcement-learning'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/DQN-Atari-Agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/Horizon'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/ReAgent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/DeepQNetwork'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nathanin/pad'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kshitij-ingale/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mohit8935/Deep-Q-Learning-Paper'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling_Network_Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hemilpanchiwala/Dueling-Network-Architectures'}}, {'code': {'type': 'literal', 'value': 'https://github.com/botforge/simplementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jezzarax/drlnd_p1_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fengsterooni/dql'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shehrum/RL_Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mightypirate1/DRL-Tetris'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZainRaza14/deepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/FaboNo/DRLND'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/Chez'}}, {'code': {'type': 'literal', 'value': 'https://github.com/la3lma/chezjulia'}}, {'code': {'type': 'literal', 'value': 'https://github.com/170928/-Review-Dueling-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/opplieam/Pong-Deep-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jsztompka/DuelDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/R-Sweke/DeepQ-Decoding'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gouxiangchen/dueling-DQN-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KDL-umass/saliency_maps'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alessandrositta/Flatland_challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Continuous-Control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prajwalgatti/DRL-Navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zynk13/dueling-dqn-Reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abryeemessi/Wednesday'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JBGUIMBAUD/deep-reenforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sirorezka/DeepRL_modules'}}, {'code': {'type': 'literal', 'value': 'https://github.com/manvibharat/Stock-price-pridiction-using-Deep-reienforcement-learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
284,List the datasets benchmarked under the Fine-Grained Image Classification research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Fine-Grained Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Fine-Grained Image Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9364250605898116,0.9629629629629628,"(0.9826831817626953, 0.9758839011192322, 0.9792717099189758)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119383'}, 'dataset_lbl': {'type': 'literal', 'value': 'CUB-200-2011'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123801'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford-IIIT Pets'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119383'}, 'dataset_lbl': {'type': 'literal', 'value': 'CUB-200-2011'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123801'}, 'dataset_lbl': {'type': 'literal', 'value': 'Oxford-IIIT Pets'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
285,What evaluation metrics are commonly used when benchmarking models on the DRI Corpus dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DRI Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DRI Corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9622641509433962,"(0.9831122159957886, 0.9770050644874573, 0.9800490736961365)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
286,List the metrics that are used to evaluate models on the Oxford-IIIT Pets benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9629629629629628,"(0.9813512563705444, 0.9759734272956848, 0.9786549210548401)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116078'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Error Rate'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116078'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Error Rate'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
287,What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential CIFAR-10 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Unpermuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Unpermuted Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Sequential CIFAR-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9830508474576272,"(0.9840791821479797, 0.9823583364486694, 0.9832179546356201)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120945'}, 'model_lbl': {'type': 'literal', 'value': 'Trellis Network'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120945'}, 'model_lbl': {'type': 'literal', 'value': 'Trellis Network'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
288,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STL-10 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STL-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STL-10"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9826037883758545, 0.9749764800071716, 0.9787752032279968)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134869'}, 'paper_lbl': {'type': 'literal', 'value': 'Training Neural Networks with Local Error Signals'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134898'}, 'paper_lbl': {'type': 'literal', 'value': 'Stacked What-Where Auto-encoders'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134869'}, 'paper_lbl': {'type': 'literal', 'value': 'Training Neural Networks with Local Error Signals'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134898'}, 'paper_lbl': {'type': 'literal', 'value': 'Stacked What-Where Auto-encoders'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131303'}, 'paper_lbl': {'type': 'literal', 'value': 'Neural Architecture Transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
289,Could you provide a list of models that have been tested on the SciCite benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9815264940261841, 0.9761035442352295, 0.9788075089454651)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125989'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226835'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-Attn w/ ELMo + section title and citation worthiness scaffolds'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125989'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226835'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-Attn w/ ELMo + section title and citation worthiness scaffolds'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
290,Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Skiing dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Skiing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9636363636363636,"(0.9809607267379761, 0.9727896451950073, 0.9768581390380859)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134264'}, 'paper_lbl': {'type': 'literal', 'value': 'First return, then explore'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133307'}, 'paper_lbl': {'type': 'literal', 'value': 'Recurrent Rational Networks'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134264'}, 'paper_lbl': {'type': 'literal', 'value': 'First return, then explore'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133307'}, 'paper_lbl': {'type': 'literal', 'value': 'Recurrent Rational Networks'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
291,List the metrics that are used to evaluate models on the VTAB-1k benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""VTAB-1k"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9636363636363636,"(0.9810296297073364, 0.9757242202758789, 0.9783697128295898)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120928'}, 'metric_lbl': {'type': 'literal', 'value': 'Params'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120928'}, 'metric_lbl': {'type': 'literal', 'value': 'Params'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
292,What is the name of the top performing model in terms of Score score when benchmarked on the Cart Pole (OpenAI Gym) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9661016949152542,"(0.9835910201072693, 0.9825113415718079, 0.9830508828163147)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
293,List the code links in papers that use the Rfa-Gate-arccos model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rfa-Gate-arccos"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rfa-Gate-arccos"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9834004044532776, 0.9746271967887878, 0.9789941310882568)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
294,Indicate the model that performed best in terms of F1 metric on the ShARe/CLEF eHealth corpus benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9649122807017544,"(0.9837599992752075, 0.982080340385437, 0.982919454574585)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
295,What are the metrics of evaluation over the BioASQ dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BioASQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BioASQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9629629629629628,"(0.9794039726257324, 0.9740936160087585, 0.9767415523529053)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
296,What is the best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Centipede"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9815250635147095, 0.9802981615066528, 0.9809112548828125)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
297,What are the most commonly used benchmark datasets for the Natural Language Inference research field?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Natural Language Inference"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Natural Language Inference"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9364250605898116,0.9615384615384616,"(0.9839470982551575, 0.9769529700279236, 0.9804375767707825)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120776'}, 'dataset_lbl': {'type': 'literal', 'value': 'SNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120747'}, 'dataset_lbl': {'type': 'literal', 'value': 'ANLI test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120774'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121068'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedSTS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121069'}, 'dataset_lbl': {'type': 'literal', 'value': 'BIOSSES'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123000'}, 'dataset_lbl': {'type': 'literal', 'value': 'ShARe/CLEF eHealth corpus'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120776'}, 'dataset_lbl': {'type': 'literal', 'value': 'SNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120747'}, 'dataset_lbl': {'type': 'literal', 'value': 'ANLI test'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120774'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedNLI'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121068'}, 'dataset_lbl': {'type': 'literal', 'value': 'MedSTS'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121069'}, 'dataset_lbl': {'type': 'literal', 'value': 'BIOSSES'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123000'}, 'dataset_lbl': {'type': 'literal', 'value': 'ShARe/CLEF eHealth corpus'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
298,What models are being evaluated on the Classic dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classic"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Classic"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9807263612747192, 0.9753054976463318, 0.9780084490776062)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125946'}, 'model_lbl': {'type': 'literal', 'value': 'REL-RWMD k-NN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125946'}, 'model_lbl': {'type': 'literal', 'value': 'REL-RWMD k-NN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
299,Where can I find code references in papers that have used the DeiT-Ti model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DeiT-Ti"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DeiT-Ti"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9830130338668823, 0.9738878011703491, 0.9784291386604309)","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tianhai123/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UdbhavPrasad072300/Transformer-Implementations'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TACJu/TransFG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/deit'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tianhai123/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UdbhavPrasad072300/Transformer-Implementations'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TACJu/TransFG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/deit'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
300,For which country of study overall prevalence of epilepsy is the highest?,"SELECT ?country, ?country_label
WHERE {
  orkgr:R75729 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P15512 ?country.
  ?contrib orkgp:P16013 ?overall_prevalence.
  ?country rdfs:label ?country_label.
  ?overall_prevalence rdfs:label ?overall_prevalence_value
}
ORDER BY DESC(?overall_prevalence_value)
LIMIT 1","SELECT DISTINCT ?country ?country_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Overall Prevalence of Epilepsy"")
  {
    SELECT ?country ?country_lbl
    WHERE {
      ?study       a                orkgc:Study;
                  rdfs:label       ?study_lbl.
      ?population   orkgp:HAS_STUDY           ?study;
                    orkgp:HAS_COUNTRY        ?country.
      ?country     rdfs:label               ?country_lbl;
                    orkgp:HAS_METRIC_VALUE ?value. 
      ?value       orkgp:HAS_METRIC         ?metric.

    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",1.7813039848176032e-78,0.71875,"(0.8502700924873352, 0.7912154197692871, 0.8196805119514465)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
301,Can you list the models that have been evaluated on the ShARe/CLEF eHealth corpus dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ShARe/CLEF eHealth corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9636363636363636,"(0.9816795587539673, 0.9766085147857666, 0.9791374802589417)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
302,Could you provide a list of models that have been tested on the HMDB51 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HMDB51"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HMDB51"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.9821110963821411, 0.9767847657203674, 0.9794406294822693)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118777'}, 'model_lbl': {'type': 'literal', 'value': 'MMV TSM-50x2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118769'}, 'model_lbl': {'type': 'literal', 'value': 'XDC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118780'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Audioset)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118782'}, 'model_lbl': {'type': 'literal', 'value': 'AVID (Modified R2+1D-18 on Audioset)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118783'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Kinetics)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118784'}, 'model_lbl': {'type': 'literal', 'value': 'AVID (Modified R2+1D-18 on Kinetics)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118777'}, 'model_lbl': {'type': 'literal', 'value': 'MMV TSM-50x2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118769'}, 'model_lbl': {'type': 'literal', 'value': 'XDC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118780'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Audioset)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118782'}, 'model_lbl': {'type': 'literal', 'value': 'AVID (Modified R2+1D-18 on Audioset)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118783'}, 'model_lbl': {'type': 'literal', 'value': 'AVID+CMA (Modified R2+1D-18 on Kinetics)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118784'}, 'model_lbl': {'type': 'literal', 'value': 'AVID (Modified R2+1D-18 on Kinetics)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
303,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Venture dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Venture"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Venture"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9649122807017544,"(0.9825470447540283, 0.97489333152771, 0.9787052273750305)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134264'}, 'paper_lbl': {'type': 'literal', 'value': 'First return, then explore'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134288'}, 'paper_lbl': {'type': 'literal', 'value': 'Exploration by Random Network Distillation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134302'}, 'paper_lbl': {'type': 'literal', 'value': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134312'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration with Neural Density Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134333'}, 'paper_lbl': {'type': 'literal', 'value': 'Large-Scale Study of Curiosity-Driven Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134345'}, 'paper_lbl': {'type': 'literal', 'value': 'Unifying Count-Based Exploration and Intrinsic Motivation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134360'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration in Feature Space for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134383'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration with the Successor Representation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134401'}, 'paper_lbl': {'type': 'literal', 'value': 'Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134264'}, 'paper_lbl': {'type': 'literal', 'value': 'First return, then explore'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134288'}, 'paper_lbl': {'type': 'literal', 'value': 'Exploration by Random Network Distillation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134302'}, 'paper_lbl': {'type': 'literal', 'value': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134312'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration with Neural Density Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134333'}, 'paper_lbl': {'type': 'literal', 'value': 'Large-Scale Study of Curiosity-Driven Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134345'}, 'paper_lbl': {'type': 'literal', 'value': 'Unifying Count-Based Exploration and Intrinsic Motivation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134360'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration in Feature Space for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134383'}, 'paper_lbl': {'type': 'literal', 'value': 'Count-Based Exploration with the Successor Representation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134401'}, 'paper_lbl': {'type': 'literal', 'value': 'Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
304,List the metrics that are used to evaluate models on the Rotowire (Content Selection) benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9622641509433962,"(0.9822438955307007, 0.9757317304611206, 0.9789769649505615)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116363'}, 'metric_lbl': {'type': 'literal', 'value': 'Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116364'}, 'metric_lbl': {'type': 'literal', 'value': 'Recall'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116363'}, 'metric_lbl': {'type': 'literal', 'value': 'Precision'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116364'}, 'metric_lbl': {'type': 'literal', 'value': 'Recall'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
305,Where can I find code references in papers that have used the Tsetlin Machine model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tsetlin Machine"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tsetlin Machine"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9607843137254902,"(0.9837855100631714, 0.9747990369796753, 0.9792717099189758)","[{'code': {'type': 'literal', 'value': 'https://github.com/adrianphoulady/weighted-tsetlin-machine-cpp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anon767/TsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jcriddle4/tsetlin_rust_mnist'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zdx3578/pyTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/regression-tsetlin-machine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TsetlinMachineC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/fast-tsetlin-machine-in-cuda-with-imdb-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachineMT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachineParallel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/PyTsetlinMachineCUDA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TextUnderstandingTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/fast-tsetlin-machine-with-mnist-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TsetlinMachine'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/adrianphoulady/weighted-tsetlin-machine-cpp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anon767/TsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jcriddle4/tsetlin_rust_mnist'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zdx3578/pyTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/regression-tsetlin-machine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TsetlinMachineC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/fast-tsetlin-machine-in-cuda-with-imdb-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachineMT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/pyTsetlinMachineParallel'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/PyTsetlinMachineCUDA'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TextUnderstandingTsetlinMachine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/fast-tsetlin-machine-with-mnist-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cair/TsetlinMachine'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
306,What is the top benchmark score and its metric on the Atari 2600 Breakout dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Breakout"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Breakout"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9823577404022217, 0.9807329177856445, 0.9815446734428406)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9.5'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9.5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
307,What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Bowling dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bowling"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bowling"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9649122807017544,"(0.9831100702285767, 0.9769064784049988, 0.9799984693527222)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
308,List the code links in papers that use the FQF model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FQF"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FQF"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9832264184951782, 0.9742014408111572, 0.9786931276321411)","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rljax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/FQF-and-Extensions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/microsoft/FQF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/fqf-iqn-qrdqn.pytorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/rljax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/BY571/FQF-and-Extensions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/microsoft/FQF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/fqf-iqn-qrdqn.pytorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
309,Indicate the model that performed best in terms of Sequence error metric on the FSNS - Test benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Sequence error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Sequence error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY ?value
    LIMIT 1
  }
}",0.9237682009314698,0.9824561403508772,"(0.9826384782791138, 0.981749951839447, 0.9821940660476685)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114164'}, 'model_lbl': {'type': 'literal', 'value': 'AttentionOCR_Inception-resnet-v2_Location'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114167'}, 'model_lbl': {'type': 'literal', 'value': 'STREET'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
310,What is the top benchmark result (metric and value) over the dataset ARC (Challenge)?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ARC (Challenge)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ARC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.925039248827207,0.9655172413793104,"(0.9860100150108337, 0.9852546453475952, 0.9856322407722473)",[],"[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '51.5'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
311,What are the titles and IDs of research papers that include a benchmark for the SciREX dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciREX"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciREX"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9826402068138123, 0.9750163555145264, 0.9788133502006531)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
312,Can you list the metrics used to evaluate models on the TSE-NER dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TSE-NER"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TSE-NER"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9809731841087341, 0.9756033420562744, 0.9782809019088745)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
313,Where can I find code references in papers that have used the Concept Mention Extraction model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Concept Mention Extraction"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Concept Mention Extraction"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",1.0,1.0,"(1.0, 1.0, 1.0)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
314,List the code links in papers that use the OTF spelling+lemma (single) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""OTF spelling+lemma (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""OTF spelling+lemma (single)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9615384615384616,"(0.9836232662200928, 0.9745773673057556, 0.9790793657302856)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
315,Provide a list of papers that have utilized the A3C LSTM hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C LSTM hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C LSTM hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9607843137254902,"(0.9831023812294006, 0.974057674407959, 0.9785591959953308)","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
316,Which model has achieved the highest Percentage error score on the SVHN benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SVHN"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SVHN"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9804643988609314, 0.979362964630127, 0.9799133539199829)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126151'}, 'model_lbl': {'type': 'literal', 'value': 'ANODE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126151'}, 'model_lbl': {'type': 'literal', 'value': 'ANODE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
317,Where can I find code references in papers that have used the LayerNorm HM-LSTM model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LayerNorm HM-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LayerNorm HM-LSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9837759733200073, 0.9750314950942993, 0.979384183883667)","[{'code': {'type': 'literal', 'value': 'https://github.com/kaiu85/hm-rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bolducp/hierarchical-rnn'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/kaiu85/hm-rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bolducp/hierarchical-rnn'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
318,List the datasets benchmarked under the SPARQL query optimization research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""SPARQL query optimization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""SPARQL query optimization"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9364250605898116,0.9821428571428572,"(0.9824992418289185, 0.9767379760742188, 0.9796101450920105)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
319,"What is the highest benchmark result achieved on the Amazon-2 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon-2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9672131147540984,"(0.9829825758934021, 0.9809608459472656, 0.9819706678390503)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}, 'score': {'type': 'literal', 'value': '2.11'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}, 'score': {'type': 'literal', 'value': '2.11'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
320,Can you provide links to code used in papers that benchmark the Temporal Convolutional Network model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Temporal Convolutional Network"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Temporal Convolutional Network"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9629629629629628,"(0.9840230941772461, 0.9749621152877808, 0.9794716238975525)","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
321,Provide a list of papers that have utilized the BiT-S (ResNet) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-S (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiT-S (ResNet)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9827637076377869, 0.9744138717651367, 0.9785709381103516)","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SoojungYang/supervised_pretraining_GN_WS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/big_transfer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
322,"What is the highest benchmark result achieved on the WNLI dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WNLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9821001291275024, 0.9805915951728821, 0.9813452959060669)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '92.5%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '92.5%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
323,"Can you provide the highest benchmark result, including the metric and score, for the AAPD dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AAPD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AAPD"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.982195258140564, 0.9806830883026123, 0.9814385771751404)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '72.9'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '72.9'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
324,What models are being evaluated on the FTD dataset dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FTD dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""FTD"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.8169276475307028,0.9622641509433962,"(0.978885293006897, 0.9741835594177246, 0.9765287637710571)",[],"[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R221862'}, 'model_lbl': {'type': 'literal', 'value': 'Baseline tf-idf NPs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R221894'}, 'model_lbl': {'type': 'literal', 'value': 'Pattern Matching and Learning'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
325,What is the best performing model benchmarking the CIFAR-10 Image Classification dataset in terms of Percentage error metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-10 Image Classification"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Percentage error"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CIFAR-10"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY ASC(?value)
    LIMIT 1
  }
}",0.876484548290347,0.9661016949152542,"(0.9803886413574219, 0.9793376922607422, 0.9798628687858582)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123733'}, 'model_lbl': {'type': 'literal', 'value': 'NAT-M4'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123733'}, 'model_lbl': {'type': 'literal', 'value': 'NAT-M4'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
326,"What is the highest benchmark result achieved on the Walker, walk (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.967741935483871,"(0.9806522130966187, 0.9807561635971069, 0.9807041883468628)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '902'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '902'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
327,What evaluation metrics are commonly used when benchmarking models on the SciGEN dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciGEN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciGEN"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9622641509433962,"(0.9825178384780884, 0.9762762188911438, 0.9793870449066162)",[{}],[{}],"{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
328,List the code links in papers that use the POP3D model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""POP3D"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""POP3D"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9838200807571411, 0.974824070930481, 0.979301393032074)","[{'code': {'type': 'literal', 'value': 'https://github.com/cxxgtxy/POP3D'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/cxxgtxy/POP3D'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
329,Indicate the model that performed best in terms of Score metric on the Atari 2600 Tennis benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Tennis"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9661016949152542,"(0.9820948839187622, 0.9811293482780457, 0.9816119074821472)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
330,What evaluation metrics are commonly used when benchmarking models on the UCF101 (finetuned) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9636363636363636,"(0.9797394275665283, 0.9744901657104492, 0.9771077632904053)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118614'}, 'metric_lbl': {'type': 'literal', 'value': '3-fold Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118614'}, 'metric_lbl': {'type': 'literal', 'value': '3-fold Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
331,Provide a list of research paper titles and IDs that have benchmarked models on the MPQA dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MPQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MPQA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9815913438796997, 0.9739547371864319, 0.9777581095695496)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
332,"What is the highest benchmark result achieved on the BC5CDR-chemical dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-chemical"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BC5CDR-chemical"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9666666666666668,"(0.9816590547561646, 0.9803436994552612, 0.9810009002685547)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}, 'score': {'type': 'literal', 'value': '94.06'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '93.5'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}, 'score': {'type': 'literal', 'value': '94.06'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '93.5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
333,Which model has achieved the highest SUCCESS score on the Habitat 2020 Object Nav test-std benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SUCCESS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""SUCCESS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9669306597086388,0.9666666666666668,"(0.9831362962722778, 0.9810532331466675, 0.9820936918258667)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123478'}, 'model_lbl': {'type': 'literal', 'value': 'RGBD+DD-PPO'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123478'}, 'model_lbl': {'type': 'literal', 'value': 'RGBD+DD-PPO'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
334,"Can you provide the highest benchmark result, including the metric and score, for the Paper Field dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Paper Field"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Paper Field"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9655172413793104,"(0.9820058345794678, 0.9805036783218384, 0.9812542200088501)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '65.71'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '65.71'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
335,Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9666666666666668,"(0.9830129146575928, 0.9809831380844116, 0.981997013092041)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124055'}, 'model_lbl': {'type': 'literal', 'value': 'XLMft UDA'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124055'}, 'model_lbl': {'type': 'literal', 'value': 'XLMft UDA'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
336,"What is the highest benchmark result achieved on the Atari 2600 Double Dunk dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Double Dunk"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9684940092844068,0.9672131147540984,"(0.9825931787490845, 0.9809114336967468, 0.9817516207695007)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
337,Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (ensemble) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9383861709333506,0.9615384615384616,"(0.9834654927253723, 0.9749501943588257, 0.9791893362998962)","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
338,"What is the top benchmark score and its metric on the Cheetah, run (DMControl500k) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cheetah, run (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9819802045822144, 0.9814498424530029, 0.9817149639129639)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '518'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '518'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
339,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STS Benchmark dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""STS Benchmark"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9607843137254902,"(0.9825769662857056, 0.9749515056610107, 0.9787493944168091)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
340,What is the top benchmark score and its metric on the Atari 2600 Alien dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Alien"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Alien"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9819150567054749, 0.9798270463943481, 0.9808699488639832)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '994.0'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '994.0'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
341,"What is the highest benchmark result achieved on the Birdsnap dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Birdsnap"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Birdsnap"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9819363355636597, 0.979857325553894, 0.9808956980705261)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90.07%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '90.07%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
342,What models are being evaluated on the Atari 2600 Chopper Command dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Chopper Command"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Chopper Command"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9649122807017544,"(0.9819058179855347, 0.9766513109207153, 0.9792715311050415)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
343,Indicate the model that performed best in terms of Accuracy metric on the Stanford Cars benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Cars"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Stanford Cars"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9818879961967468, 0.9810241460800171, 0.98145592212677)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126364'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-TDN(ResNet-101)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126364'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-TDN(ResNet-101)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
344,Indicate the model that performed best in terms of Precision metric on the RotoWire (Relation Generation) benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Precision"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9655172413793104,"(0.9826183319091797, 0.9813185334205627, 0.9819680452346802)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120299'}, 'model_lbl': {'type': 'literal', 'value': 'Hierarchical Transformer Encoder +  conditional copy'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120299'}, 'model_lbl': {'type': 'literal', 'value': 'Hierarchical Transformer Encoder +  conditional copy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
345,List the metrics that are used to evaluate models on the SQuAD1.1 benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD1.1"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SQuAD1.1"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",1.0,1.0,"(1.0, 1.0, 1.0)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
346,Provide a list of papers that have utilized the Large mLSTM model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Large mLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Large mLSTM"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.96,"(0.9837662577629089, 0.9747855067253113, 0.9792552590370178)","[{'code': {'type': 'literal', 'value': 'https://github.com/astakara48/python_project'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/astakara48/python_project'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
347,What models are being evaluated on the ACL Anthology dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACL Anthology"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ACL Anthology"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9629629629629628,"(0.9821681976318359, 0.9769595265388489, 0.9795569777488708)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R224967'}, 'model_lbl': {'type': 'literal', 'value': 'CL-Titles-Parser'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R224967'}, 'model_lbl': {'type': 'literal', 'value': 'CL-Titles-Parser'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
348,Which model has achieved the highest Score score on the Atari 2600 Yars Revenge benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Yars Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Yars Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9661016949152542,"(0.9817331433296204, 0.9805158376693726, 0.9811240434646606)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124997'}, 'model_lbl': {'type': 'literal', 'value': 'RUDDER'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124997'}, 'model_lbl': {'type': 'literal', 'value': 'RUDDER'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
349,What models are being evaluated on the NCBI-disease dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI-disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.9817857146263123, 0.9765112400054932, 0.979141354560852)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
350,"Can you provide the highest benchmark result, including the metric and score, for the Softcite dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Softcite"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Softcite"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9829069972038269, 0.980932354927063, 0.9819186925888062)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
351,What are the metrics of evaluation over the Fashion-MNIST dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Fashion-MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Fashion-MNIST"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9811564683914185, 0.9757398366928101, 0.9784407019615173)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116138'}, 'metric_lbl': {'type': 'literal', 'value': 'Percentage error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116138'}, 'metric_lbl': {'type': 'literal', 'value': 'Percentage error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
352,What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-2 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""X-Sum"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""X-Sum"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9666666666666668,"(0.982867419719696, 0.9815711975097656, 0.982218861579895)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124731'}, 'model_lbl': {'type': 'literal', 'value': 'PtGen'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124731'}, 'model_lbl': {'type': 'literal', 'value': 'PtGen'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
353,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RotoWire (Relation Generation) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Relation Generation)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9622641509433962,"(0.9818704128265381, 0.9744992852210999, 0.9781709909439087)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130466'}, 'paper_lbl': {'type': 'literal', 'value': 'Data-to-Text Generation with Content Selection and Planning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130479'}, 'paper_lbl': {'type': 'literal', 'value': 'Challenges in Data-to-Document Generation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130451'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Model for Data-to-Text Generation'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130466'}, 'paper_lbl': {'type': 'literal', 'value': 'Data-to-Text Generation with Content Selection and Planning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130479'}, 'paper_lbl': {'type': 'literal', 'value': 'Challenges in Data-to-Document Generation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130451'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Model for Data-to-Text Generation'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
354,Can you provide links to code used in papers that benchmark the Fine-Grained Gating model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Fine-Grained Gating"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Fine-Grained Gating"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9622641509433962,"(0.9835895299911499, 0.97495037317276, 0.9792509078979492)","[{'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/fg-gating'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/fg-gating'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
355,What is the best performing model benchmarking the Atari 2600 Montezuma's Revenge dataset in terms of Average Return (NoOp) metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Average Return (NoOp)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Average Return (NoOp)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9674687404175402,0.9672131147540984,"(0.9825935363769531, 0.9811116456985474, 0.9818520545959473)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
356,Provide a list of papers that have utilized the Prior noop model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Prior noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Prior noop"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9615384615384616,"(0.9833017587661743, 0.9742851257324219, 0.9787726998329163)","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Yuheon/Reinforcement-Learning-Study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KatyNTsachi/Hierarchical-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yzheng51/rl-dino-run'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Damcy/prioritized-experience-replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/soft-actor-critic.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dtak/hip-mdp-public'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kayuksel/pytorch-ars'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Suryavf/SelfDrivingCar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MathPhysSim/PER-NAF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Guillaume-Cr/lunar_lander_per'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Arrabonae/openai_DDDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KAIST-AILab/deeprl_practice_colab'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Tennis-With-Multi-Agent-Reinforcement'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Continuous-Control-with-Deep-Deterministic-Policy-Gradient'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-VREP'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CSCI4850/S20-team3-project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-Research'}}, {'code': {'type': 'literal', 'value': 'https://github.com/7starsea/Prioritized-Experience-Replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ameet-1997/Prioritized_Experience_Replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/VictorZuanazzi/Project_RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/V0LsTeR/dopamine_prioritized_buffer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ACampero/dopamine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tphanson/xupr-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anhtu293/NeurIPS-2019-Challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/V0LsTeR/DQN_heap'}}, {'code': {'type': 'literal', 'value': 'https://github.com/backgom2357/Recommender_system_via_deep_RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-VREP-Version-2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MrDaubinet/collaboration-and-competition'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yusme/DDPG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p3_collab-compet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/VasaKiDD/TD3-deep-rl-research'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p2-continuous-control-SNH'}}, {'code': {'type': 'literal', 'value': 'https://github.com/GoingMyWay/dopamine_reward_decomposition'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p1_navigation_SNH'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google/dopamine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SimonRamstedt/ddpg'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/ku2482/sac-discrete.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/eddynelson/dqn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Yuheon/Reinforcement-Learning-Study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JuliaPOMDP/DeepQLearning.jl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SayhoKim/tetrisRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kmdanielduan/DQN_Family_PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KatyNTsachi/Hierarchical-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/atavakol/action-branching-agents'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utarumo/RL_implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cocolico14/N-step-Dueling-DDQN-PER-Pacman'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yzheng51/rl-dino-run'}}, {'code': {'type': 'literal', 'value': 'https://github.com/OMS1996/Carla_The_RL_Self-Driving-Car'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/deep-rl-trex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rybread1/DeepRlTrex'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Adrelf/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MEOWMEOW114/nd893-p1-navigation-banana'}}, {'code': {'type': 'literal', 'value': 'https://github.com/austinsilveria/Banana-Collection-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/1jsingh/rl_navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HussonnoisMaxence/RL_Algorithms'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shashwatsaxena571/DRL-navigation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nbopardi/smb'}}, {'code': {'type': 'literal', 'value': 'https://github.com/guillaumeboniface/bananaland'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Damcy/prioritized-experience-replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ku2482/soft-actor-critic.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dtak/hip-mdp-public'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kayuksel/pytorch-ars'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Suryavf/SelfDrivingCar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MathPhysSim/PER-NAF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Guillaume-Cr/lunar_lander_per'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Arrabonae/openai_DDDQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/KAIST-AILab/deeprl_practice_colab'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Tennis-With-Multi-Agent-Reinforcement'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Continuous-Control-with-Deep-Deterministic-Policy-Gradient'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iDataist/Navigation-with-Deep-Q-Network'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-VREP'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CSCI4850/S20-team3-project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-Research'}}, {'code': {'type': 'literal', 'value': 'https://github.com/7starsea/Prioritized-Experience-Replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ameet-1997/Prioritized_Experience_Replay'}}, {'code': {'type': 'literal', 'value': 'https://github.com/VictorZuanazzi/Project_RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/V0LsTeR/dopamine_prioritized_buffer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ACampero/dopamine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tphanson/xupr-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anhtu293/NeurIPS-2019-Challenge'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Brandon-Rozek/DeepRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/V0LsTeR/DQN_heap'}}, {'code': {'type': 'literal', 'value': 'https://github.com/backgom2357/Recommender_system_via_deep_RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/CharlotteMorrison/Baxter-VREP-Version-2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MrDaubinet/collaboration-and-competition'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yusme/DDPG'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p3_collab-compet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/VasaKiDD/TD3-deep-rl-research'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p2-continuous-control-SNH'}}, {'code': {'type': 'literal', 'value': 'https://github.com/GoingMyWay/dopamine_reward_decomposition'}}, {'code': {'type': 'literal', 'value': 'https://github.com/snhwang/p1_navigation_SNH'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google/dopamine'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SimonRamstedt/ddpg'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
357,What is the best performing model benchmarking the WMT2016 English-Russian dataset in terms of BLEU score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-Russian"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9210921090251244,0.9666666666666668,"(0.9826803207397461, 0.9817066192626953, 0.9821932315826416)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117124'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + Transformer'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117124'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised NMT + Transformer'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
358,What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford-IIIT Pets dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Error Rate"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Top-1 Error Rate"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY ?value
    LIMIT 1
  }
}",0.9237682009314698,0.9661016949152542,"(0.9831429719924927, 0.981940746307373, 0.9825414419174194)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123738'}, 'model_lbl': {'type': 'literal', 'value': 'NAT-M1'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126364'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-TDN(ResNet-101)'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'jaccard': 0.0}"
359,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters-21578 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9649122807017544,"(0.9822765588760376, 0.974619448184967, 0.9784330129623413)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134423'}, 'paper_lbl': {'type': 'literal', 'value': 'DocBERT: BERT for Document Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134434'}, 'paper_lbl': {'type': 'literal', 'value': 'Text classification with word embedding regularization and soft similarity measure'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134448'}, 'paper_lbl': {'type': 'literal', 'value': 'Rep the Set: Neural Networks for Learning Set Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134476'}, 'paper_lbl': {'type': 'literal', 'value': ""Speeding up Word Mover's Distance and its variants via properties of distances between embeddings""}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134423'}, 'paper_lbl': {'type': 'literal', 'value': 'DocBERT: BERT for Document Classification'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134434'}, 'paper_lbl': {'type': 'literal', 'value': 'Text classification with word embedding regularization and soft similarity measure'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134448'}, 'paper_lbl': {'type': 'literal', 'value': 'Rep the Set: Neural Networks for Learning Set Representations'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134476'}, 'paper_lbl': {'type': 'literal', 'value': ""Speeding up Word Mover's Distance and its variants via properties of distances between embeddings""}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131153'}, 'paper_lbl': {'type': 'literal', 'value': 'Message Passing Attention Networks for Document Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
360,What models are being evaluated on the Penn Treebank (Character Level) dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank (Character Level)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9622641509433962,"(0.9819966554641724, 0.9768547415733337, 0.9794189929962158)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121040'}, 'model_lbl': {'type': 'literal', 'value': 'Bipartite Flow'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120936'}, 'model_lbl': {'type': 'literal', 'value': 'Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120945'}, 'model_lbl': {'type': 'literal', 'value': 'Trellis Network'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121036'}, 'model_lbl': {'type': 'literal', 'value': 'NASCell'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121039'}, 'model_lbl': {'type': 'literal', 'value': 'Temporal Convolutional Network'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120964'}, 'model_lbl': {'type': 'literal', 'value': 'R-Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120876'}, 'model_lbl': {'type': 'literal', 'value': 'Feedback Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120921'}, 'model_lbl': {'type': 'literal', 'value': '3-layer AWD-LSTM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121033'}, 'model_lbl': {'type': 'literal', 'value': '6-layer QRNN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120924'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-4'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121035'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121037'}, 'model_lbl': {'type': 'literal', 'value': '2-layer Norm HyperLSTM'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121040'}, 'model_lbl': {'type': 'literal', 'value': 'Bipartite Flow'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120936'}, 'model_lbl': {'type': 'literal', 'value': 'Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120945'}, 'model_lbl': {'type': 'literal', 'value': 'Trellis Network'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121036'}, 'model_lbl': {'type': 'literal', 'value': 'NASCell'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121039'}, 'model_lbl': {'type': 'literal', 'value': 'Temporal Convolutional Network'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120964'}, 'model_lbl': {'type': 'literal', 'value': 'R-Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120876'}, 'model_lbl': {'type': 'literal', 'value': 'Feedback Transformer'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120921'}, 'model_lbl': {'type': 'literal', 'value': '3-layer AWD-LSTM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121033'}, 'model_lbl': {'type': 'literal', 'value': '6-layer QRNN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120924'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-4'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121035'}, 'model_lbl': {'type': 'literal', 'value': 'FS-LSTM-2'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121037'}, 'model_lbl': {'type': 'literal', 'value': '2-layer Norm HyperLSTM'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
361,Provide a list of papers that have utilized the ANODE model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ANODE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ANODE"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.983932614326477, 0.9747858643531799, 0.9793378710746765)","[{'code': {'type': 'literal', 'value': 'https://github.com/kfallah/NODE-Denoiser'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mandubian/pytorch-neural-ode'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/monotone_op_net'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mitmath/18S096SciML'}}, {'code': {'type': 'literal', 'value': 'https://github.com/EmilienDupont/augmented-neural-odes'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/kfallah/NODE-Denoiser'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mandubian/pytorch-neural-ode'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/monotone_op_net'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mitmath/18S096SciML'}}, {'code': {'type': 'literal', 'value': 'https://github.com/EmilienDupont/augmented-neural-odes'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
362,Provide a list of papers that have utilized the DY-MobileNetV3-Small model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DY-MobileNetV3-Small"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""DY-MobileNetV3-Small"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9636363636363636,"(0.9838564395904541, 0.9748368263244629, 0.9793258309364319)","[{'code': {'type': 'literal', 'value': 'https://github.com/TArdelean/DynamicConvolution'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prstrive/CondConv-tensorflow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaijieshi7/Dynamic-convolution-Pytorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/TArdelean/DynamicConvolution'}}, {'code': {'type': 'literal', 'value': 'https://github.com/prstrive/CondConv-tensorflow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaijieshi7/Dynamic-convolution-Pytorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
363,"What is the highest benchmark result achieved on the FSNS - Test dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FSNS - Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9661016949152542,"(0.9819411039352417, 0.9799501895904541, 0.9809446334838867)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114165'}, 'metric_lbl': {'type': 'literal', 'value': 'Sequence error'}, 'score': {'type': 'literal', 'value': '27.54'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114165'}, 'metric_lbl': {'type': 'literal', 'value': 'Sequence error'}, 'score': {'type': 'literal', 'value': '27.54'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
364,Where can I find code references in papers that have used the MPAD-path model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MPAD-path"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MPAD-path"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9837200045585632, 0.974911093711853, 0.9792957901954651)","[{'code': {'type': 'literal', 'value': 'https://github.com/Tixierae/gow_tools'}}, {'code': {'type': 'literal', 'value': 'https://github.com/giannisnik/mpad'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Tixierae/gow_tools'}}, {'code': {'type': 'literal', 'value': 'https://github.com/giannisnik/mpad'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
365,What are the models that have been benchmarked on the BoolQ dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BoolQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BoolQ"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9822508096694946, 0.9768878221511841, 0.9795619249343872)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117327'}, 'model_lbl': {'type': 'literal', 'value': 'GPT-3 175B (Few-Shot)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
366,"Can you provide the highest benchmark result, including the metric and score, for the BUCC German-to-English dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""BUCC German-to-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9661016949152542,"(0.9819580316543579, 0.9808436036109924, 0.9814004898071289)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}, 'score': {'type': 'literal', 'value': '96.19'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}, 'score': {'type': 'literal', 'value': '96.19'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
367,"Which model has achieved the highest Score score on the Ball in cup, catch (DMControl100k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Ball in cup, catch (DMControl100k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9669306597086388,0.9655172413793104,"(0.9829140901565552, 0.9808387756347656, 0.9818753600120544)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
368,List the code links in papers that use the Multi-Perspective Matching (ensemble) model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Multi-Perspective Matching (ensemble)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9636363636363636,"(0.9839973449707031, 0.9752358198165894, 0.9795970320701599)","[{'code': {'type': 'literal', 'value': 'https://github.com/bloomsburyai/question-generation'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/bloomsburyai/question-generation'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
369,What is the best performing model benchmarking the ImageNet 64x64 dataset in terms of Bits per dim metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Bits per dim"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Bits per dim"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet 64x64"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9661016949152542,"(0.9836158156394958, 0.9821692705154419, 0.9828920364379883)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117688'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Transformer 152M (strided)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117688'}, 'model_lbl': {'type': 'literal', 'value': 'Sparse Transformer 152M (strided)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
370,What is the top benchmark result (metric and value) over the dataset CommonsenseQA?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CommonsenseQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9819120168685913, 0.9798651337623596, 0.9808874726295471)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '76.1'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '76.1'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
371,Are children examined in the studies?,"ASK {
  orkgr:R44979 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P23161 ?population.
  FILTER(REGEX(?population, ""ildren""))
}","SELECT SUM(?number_of_children) AS ?total
WHERE {
  orkgr:R33008 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P15586 ?number_of_children.
  BIND(xsd:integer(?number_of_children) AS ?number_of_children)
}",2.8526683815540716e-78,0.5967741935483871,"(0.9197139739990234, 0.8856732845306396, 0.9023726582527161)",,,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
372,"What is the highest benchmark result achieved on the CoQA dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoQA"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9828678965568542, 0.9808632135391235, 0.9818645119667053)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118414'}, 'metric_lbl': {'type': 'literal', 'value': 'Overall'}, 'score': {'type': 'literal', 'value': '85'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118414'}, 'metric_lbl': {'type': 'literal', 'value': 'Overall'}, 'score': {'type': 'literal', 'value': '85'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
373,What is the top benchmark score and its metric on the ImageNet V2 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet V2"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9661016949152542,"(0.9822452068328857, 0.9801799654960632, 0.9812114834785461)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115534'}, 'metric_lbl': {'type': 'literal', 'value': 'Top 1 Accuracy'}, 'score': {'type': 'literal', 'value': '76.7'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115534'}, 'metric_lbl': {'type': 'literal', 'value': 'Top 1 Accuracy'}, 'score': {'type': 'literal', 'value': '76.7'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
374,"Which model has achieved the highest Score score on the Reacher, easy (DMControl500k) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9666666666666668,"(0.9832655787467957, 0.9814709424972534, 0.9823674559593201)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
375,List the metrics that are used to evaluate models on the Quasart-T benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Quasart-T"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Quasart-T"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9636363636363636,"(0.982747495174408, 0.976417601108551, 0.9795723557472229)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119439'}, 'metric_lbl': {'type': 'literal', 'value': 'EM'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
376,Can you list the models that have been evaluated on the Multimodal PISA dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Multimodal PISA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Multimodal PISA"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9636363636363636,"(0.9817318916320801, 0.9764469265937805, 0.9790823459625244)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118533'}, 'model_lbl': {'type': 'literal', 'value': 'Video'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122331'}, 'model_lbl': {'type': 'literal', 'value': 'Audio'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129308'}, 'model_lbl': {'type': 'literal', 'value': 'MMDL'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118533'}, 'model_lbl': {'type': 'literal', 'value': 'Video'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122331'}, 'model_lbl': {'type': 'literal', 'value': 'Audio'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129308'}, 'model_lbl': {'type': 'literal', 'value': 'MMDL'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
377,Can you list the metrics used to evaluate models on the Barabasi-Albert dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Barabasi-Albert"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Barabasi-Albert"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9629629629629628,"(0.9812854528427124, 0.9759355783462524, 0.9786032438278198)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124627'}, 'metric_lbl': {'type': 'literal', 'value': 'Entropy Difference'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124627'}, 'metric_lbl': {'type': 'literal', 'value': 'Entropy Difference'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
378,Can you list the metrics used to evaluate models on the Atari 2600 Zaxxon dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Zaxxon"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Zaxxon"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8981503502402635,0.9649122807017544,"(0.981346607208252, 0.9759951829910278, 0.9786635637283325)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
379,What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-Spanish?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Spanish"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Spanish"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9666666666666668,"(0.9805391430854797, 0.9803669452667236, 0.9804530739784241)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '96.8'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '96.8'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
380,Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9824391603469849, 0.9809879064559937, 0.9817129969596863)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117253'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised S2S with attention'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117253'}, 'model_lbl': {'type': 'literal', 'value': 'Unsupervised S2S with attention'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
381,Provide a list of benchmarked datasets related to the Sentence Classification research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Sentence Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Sentence Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9615384615384616,"(0.9835969805717468, 0.9766730070114136, 0.9801228046417236)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125988'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125991'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206124'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125988'}, 'dataset_lbl': {'type': 'literal', 'value': 'SciCite'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125991'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R206124'}, 'dataset_lbl': {'type': 'literal', 'value': 'ACL-ARC'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
382,List the metrics that are used to evaluate models on the RotoWire (Content Ordering) benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9615384615384616,"(0.9818066358566284, 0.9754706025123596, 0.9786283373832703)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120302'}, 'metric_lbl': {'type': 'literal', 'value': 'DLD'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120302'}, 'metric_lbl': {'type': 'literal', 'value': 'DLD'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
383,What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Italian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MLDoc Zero-Shot English-to-Italian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9629629629629628,"(0.9820613861083984, 0.975521445274353, 0.9787805080413818)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
384,Provide a list of papers that have utilized the Tokenlearner model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tokenlearner"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Tokenlearner"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9830617308616638, 0.974047839641571, 0.9785340428352356)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
385,What models are being evaluated on the MedSTS dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MedSTS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MedSTS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9622641509433962,"(0.9823171496391296, 0.9768385887145996, 0.9795701503753662)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124559'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (PubMed)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124560'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (PubMed + MIMIC-III)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124561'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (MIMIC-III)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124562'}, 'model_lbl': {'type': 'literal', 'value': 'Universal Sentence Encoder'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124559'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (PubMed)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124560'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (PubMed + MIMIC-III)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124561'}, 'model_lbl': {'type': 'literal', 'value': 'BioSentVec (MIMIC-III)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124562'}, 'model_lbl': {'type': 'literal', 'value': 'Universal Sentence Encoder'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120775'}, 'model_lbl': {'type': 'literal', 'value': 'NCBI_BERT(base) (P+M)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
386,What is the best performing model benchmarking the CoNLL++ dataset in terms of F1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""CoNLL++"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9649122807017544,"(0.9836339950561523, 0.9826078414916992, 0.9831206202507019)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122917'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-CRF+ELMo'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122917'}, 'model_lbl': {'type': 'literal', 'value': 'BiLSTM-CRF+ELMo'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
387,Provide a list of research paper titles and IDs that have benchmarked models on the UCF101 (finetuned) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""UCF101 (finetuned)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9636363636363636,"(0.9817078113555908, 0.9742558598518372, 0.9779676795005798)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129958'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised MultiModal Versatile Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129977'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised Learning by Cross-Modal Audio-Video Clustering'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130082'}, 'paper_lbl': {'type': 'literal', 'value': 'Audio-Visual Instance Discrimination with Cross-Modal Agreement'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130118'}, 'paper_lbl': {'type': 'literal', 'value': 'Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129958'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised MultiModal Versatile Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129977'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised Learning by Cross-Modal Audio-Video Clustering'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130082'}, 'paper_lbl': {'type': 'literal', 'value': 'Audio-Visual Instance Discrimination with Cross-Modal Agreement'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130118'}, 'paper_lbl': {'type': 'literal', 'value': 'Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
388,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciCite dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SciCite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9827604293823242, 0.9751172065734863, 0.9789239168167114)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129411'}, 'paper_lbl': {'type': 'literal', 'value': 'SciBERT: A Pretrained Language Model for Scientific Text'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
389,Can you provide links to code used in papers that benchmark the ImageNet + iNat on WS-DAN model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ImageNet + iNat on WS-DAN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ImageNet + iNat on WS-DAN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9343348130467294,0.9622641509433962,"(0.9838847517967224, 0.9749406576156616, 0.9793922901153564)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
390,Can you list the metrics used to evaluate models on the BUCC Russian-to-English dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC Russian-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9636363636363636,"(0.9802781343460083, 0.9748690128326416, 0.9775660634040833)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
391,What is the best performing model benchmarking the AESLC dataset in terms of ROUGE-1 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""ROUGE-1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""AESLC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9827004671096802, 0.9813353419303894, 0.982017457485199)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124688'}, 'model_lbl': {'type': 'literal', 'value': 'PEGASUS'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124688'}, 'model_lbl': {'type': 'literal', 'value': 'PEGASUS'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
392,What is the top benchmark score and its metric on the ModelNet40 dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ModelNet40"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ModelNet40"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9666666666666668,"(0.9829556941986084, 0.9809424877166748, 0.9819480776786804)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114881'}, 'metric_lbl': {'type': 'literal', 'value': 'Mean Accuracy'}, 'score': {'type': 'literal', 'value': '14.3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114881'}, 'metric_lbl': {'type': 'literal', 'value': 'Mean Accuracy'}, 'score': {'type': 'literal', 'value': '14.3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
393,List the metrics that are used to evaluate models on the Penn Treebank benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Penn Treebank"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9615384615384616,"(0.9801837205886841, 0.9747986793518066, 0.9774837493896484)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115445'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
394,Could you provide a list of models that have been tested on the Reuters-21578 benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reuters-21578"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9666666666666668,"(0.982445240020752, 0.9772392511367798, 0.9798352718353271)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125942'}, 'model_lbl': {'type': 'literal', 'value': 'KD-LSTMreg'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125944'}, 'model_lbl': {'type': 'literal', 'value': 'Orthogonalized Soft VSM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125946'}, 'model_lbl': {'type': 'literal', 'value': 'REL-RWMD k-NN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122632'}, 'model_lbl': {'type': 'literal', 'value': 'MPAD-path'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125942'}, 'model_lbl': {'type': 'literal', 'value': 'KD-LSTMreg'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125944'}, 'model_lbl': {'type': 'literal', 'value': 'Orthogonalized Soft VSM'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125946'}, 'model_lbl': {'type': 'literal', 'value': 'REL-RWMD k-NN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122632'}, 'model_lbl': {'type': 'literal', 'value': 'MPAD-path'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
395,What is the best performing model benchmarking the Atari 2600 Seaquest dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9830508474576272,"(0.9832713007926941, 0.982277512550354, 0.9827741980552673)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
396,What are the metrics of evaluation over the seel.cse.lsu.edu/data/re17.zip  dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.7965020533851944,0.9649122807017544,"(0.9791791439056396, 0.9747100472450256, 0.9769394993782043)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
397,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ObjectNet dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9822272658348083, 0.9745903015136719, 0.9783938527107239)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134508'}, 'paper_lbl': {'type': 'literal', 'value': 'Big Transfer (BiT): General Visual Representation Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
398,List the metrics that are used to evaluate models on the Atari 2600 HERO benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 HERO"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 HERO"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8981503502402635,0.9636363636363636,"(0.9800337553024292, 0.9745028614997864, 0.9772604703903198)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124949'}, 'metric_lbl': {'type': 'literal', 'value': 'Best Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124949'}, 'metric_lbl': {'type': 'literal', 'value': 'Best Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
399,What are the titles and IDs of research papers that include a benchmark for the Amazon-2 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Amazon-2"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9809136986732483, 0.9729722738265991, 0.976926863193512)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
400,Provide a list of papers that have utilized the Rainbow+SEER model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rainbow+SEER"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""Rainbow+SEER"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9622641509433962,"(0.9829423427581787, 0.9739004373550415, 0.978400468826294)","[{'code': {'type': 'literal', 'value': 'https://github.com/lili-chen/SEER'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/lili-chen/SEER'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
401,What is the name of the top performing model in terms of Accuracy (High) score when benchmarked on the RACE dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy (High)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RACE"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy (High)"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RACE"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9793438911437988, 0.9781670570373535, 0.9787551164627075)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
402,Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Romanian dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-Romanian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 English-Romanian"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9642857142857144,"(0.9820480942726135, 0.9744604825973511, 0.9782395362854004)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129654'}, 'paper_lbl': {'type': 'literal', 'value': 'Edinburgh Neural Machine Translation Systems for WMT 16'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129673'}, 'paper_lbl': {'type': 'literal', 'value': 'Phrase-Based & Neural Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129742'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating a Local Translation Mechanism into Non-autoregressive Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129761'}, 'paper_lbl': {'type': 'literal', 'value': 'Non-Autoregressive Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129773'}, 'paper_lbl': {'type': 'literal', 'value': 'Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129654'}, 'paper_lbl': {'type': 'literal', 'value': 'Edinburgh Neural Machine Translation Systems for WMT 16'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129673'}, 'paper_lbl': {'type': 'literal', 'value': 'Phrase-Based & Neural Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129742'}, 'paper_lbl': {'type': 'literal', 'value': 'Incorporating a Local Translation Mechanism into Non-autoregressive Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129761'}, 'paper_lbl': {'type': 'literal', 'value': 'Non-Autoregressive Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129773'}, 'paper_lbl': {'type': 'literal', 'value': 'Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
403,Can you list the metrics used to evaluate models on the MUTAG dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MUTAG"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""MUTAG"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9802730679512024, 0.9749091267585754, 0.9775837063789368)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
404,What evaluation metrics are commonly used when benchmarking models on the ESC-50 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ESC-50"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ESC-50"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9636363636363636,"(0.9829388856887817, 0.9767649173736572, 0.9798421859741211)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122339'}, 'metric_lbl': {'type': 'literal', 'value': 'PRE-TRAINING DATASET'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122339'}, 'metric_lbl': {'type': 'literal', 'value': 'PRE-TRAINING DATASET'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
405,Which model has achieved the highest F1 score on the SQuAD1.1 dev benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD1.1 dev"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SQuAD1.1 dev"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9829221963882446, 0.98148512840271, 0.9822031259536743)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
406,What models are being evaluated on the TempEval-3 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""TempEval-3"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9636363636363636,"(0.9820586442947388, 0.9768936634063721, 0.979469358921051)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121392'}, 'model_lbl': {'type': 'literal', 'value': 'Ning et al.'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121392'}, 'model_lbl': {'type': 'literal', 'value': 'Ning et al.'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
407,What is the best performing model benchmarking the RotoWire (Content Ordering) dataset in terms of BLEU metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""RotoWire (Content Ordering)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9642857142857144,"(0.9825356602668762, 0.9811789989471436, 0.9818569421768188)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120289'}, 'model_lbl': {'type': 'literal', 'value': 'Encoder-decoder + conditional copy'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120289'}, 'model_lbl': {'type': 'literal', 'value': 'Encoder-decoder + conditional copy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
408,What is the top benchmark score and its metric on the Atari 2600 Seaquest dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Seaquest"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9836065573770492,"(0.9823870658874512, 0.9807683229446411, 0.9815770387649536)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '931.6'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '931.6'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
409,Could you provide a list of models that have been tested on the GENIA - LAS benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GENIA - LAS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""GENIA - LAS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9636363636363636,"(0.9813717603683472, 0.9760178923606873, 0.9786875247955322)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116685'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (Base Vocab)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
410,Provide a list of research paper titles and IDs that have benchmarked models on the Yelp Binary classification dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Yelp Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9629629629629628,"(0.981665849685669, 0.9741623401641846, 0.9778997302055359)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130126'}, 'paper_lbl': {'type': 'literal', 'value': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
411,Indicate the model that performed best in terms of Accuracy metric on the Amazon benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Accuracy"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Amazon"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9655172413793104,"(0.9844226837158203, 0.9828619360923767, 0.9836416840553284)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
412,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Bank Heist dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bank Heist"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Bank Heist"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9343348130467294,0.9636363636363636,"(0.9811820983886719, 0.973628044128418, 0.977390468120575)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134029'}, 'paper_lbl': {'type': 'literal', 'value': 'Smaller World Models for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134043'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134029'}, 'paper_lbl': {'type': 'literal', 'value': 'Smaller World Models for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134043'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
413,What is the name of the top performing model in terms of A2 score when benchmarked on the ANLI test dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A2"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9196822664155296,0.9649122807017544,"(0.9828569889068604, 0.9816311001777649, 0.9822436571121216)",[],"[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120755'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (Large)'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
414,Could you provide a list of models that have been tested on the QNLI benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9820877313613892, 0.9766885638237, 0.9793807864189148)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
415,What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Asterix dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Asterix"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Asterix"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9642857142857144,"(0.9816739559173584, 0.9741843938827515, 0.9779148101806641)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134084'}, 'paper_lbl': {'type': 'literal', 'value': 'Soft Actor-Critic for Discrete Action Settings'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133307'}, 'paper_lbl': {'type': 'literal', 'value': 'Recurrent Rational Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133937'}, 'paper_lbl': {'type': 'literal', 'value': 'Evolution Strategies as a Scalable Alternative to Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134084'}, 'paper_lbl': {'type': 'literal', 'value': 'Soft Actor-Critic for Discrete Action Settings'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134126'}, 'paper_lbl': {'type': 'literal', 'value': 'The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134171'}, 'paper_lbl': {'type': 'literal', 'value': 'Fully Parameterized Quantile Function for Distributional Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133503'}, 'paper_lbl': {'type': 'literal', 'value': 'Asynchronous Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133821'}, 'paper_lbl': {'type': 'literal', 'value': 'Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132604'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Reinforcement Learning with Double Q-learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133007'}, 'paper_lbl': {'type': 'literal', 'value': 'Learning values across many orders of magnitude'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133107'}, 'paper_lbl': {'type': 'literal', 'value': 'Massively Parallel Methods for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133307'}, 'paper_lbl': {'type': 'literal', 'value': 'Recurrent Rational Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133207'}, 'paper_lbl': {'type': 'literal', 'value': 'Deep Exploration via Bootstrapped DQN'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R133403'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Imitation Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R132399'}, 'paper_lbl': {'type': 'literal', 'value': 'Prioritized Experience Replay'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131980'}, 'paper_lbl': {'type': 'literal', 'value': 'Dueling Network Architectures for Deep Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131877'}, 'paper_lbl': {'type': 'literal', 'value': 'A Distributional Perspective on Reinforcement Learning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
416,Can you provide links to code used in papers that benchmark the MFEC model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MFEC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""MFEC"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.96,"(0.9831374883651733, 0.9737690687179565, 0.9784308671951294)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
417,Can you provide links to code used in papers that benchmark the CAIT-XS-36 model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CAIT-XS-36"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CAIT-XS-36"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9629629629629628,"(0.9829409718513489, 0.9736995697021484, 0.9782984852790833)","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/deit'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/deit'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
418,What models are being evaluated on the seel.cse.lsu.edu/data/re17.zip  dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.8169276475307028,0.9661016949152542,"(0.9811773300170898, 0.9770009517669678, 0.9790846705436707)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
419,Indicate the model that performed best in terms of Score metric on the Atari 2600 Montezuma's Revenge benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Montezuma's Revenge"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.966374472731516,0.9672131147540984,"(0.9832741022109985, 0.9818288087844849, 0.9825509190559387)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
420,What is the best performing model benchmarking the ImageNet ReaL dataset in terms of Params metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Params"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet ReaL"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9809200167655945, 0.9799747467041016, 0.9804471135139465)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126036'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
421,Can you provide links to code used in papers that benchmark the ResNet-152 (SAM) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ResNet-152 (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""ResNet-152 (SAM)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9629629629629628,"(0.9838392734527588, 0.9750910997390747, 0.9794456958770752)","[{'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/SAM-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jannoshh/simple-sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/moskomule/sam.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/davda54/sam'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Janus-Shiau/SAM-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jannoshh/simple-sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow'}}, {'code': {'type': 'literal', 'value': 'https://github.com/moskomule/sam.pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/sam'}}, {'code': {'type': 'literal', 'value': 'https://github.com/davda54/sam'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
422,"Can you provide the highest benchmark result, including the metric and score, for the Pubmed dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Pubmed"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Pubmed"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.982002854347229, 0.9805017709732056, 0.9812517166137695)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120314'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-1'}, 'score': {'type': 'literal', 'value': '45.09'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120314'}, 'metric_lbl': {'type': 'literal', 'value': 'ROUGE-1'}, 'score': {'type': 'literal', 'value': '45.09'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
423,"Provide a list of research paper titles and IDs that have benchmarked models on the Walker, walk (DMControl100k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Walker, walk (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9629629629629628,"(0.9812511205673218, 0.9737985134124756, 0.9775106310844421)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
424,"What is the highest benchmark result achieved on the REDDIT-B dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""REDDIT-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""REDDIT-B"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9661016949152542,"(0.9819621443748474, 0.9798755645751953, 0.9809176921844482)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '80.3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '80.3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
425,What models are being evaluated on the Softcite dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Softcite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Softcite"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}",0.9364250605898116,0.9629629629629628,"(0.983464777469635, 0.9770746827125549, 0.9802592992782593)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226473'}, 'model_lbl': {'type': 'literal', 'value': 'linear-chain CRFs'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226473'}, 'model_lbl': {'type': 'literal', 'value': 'linear-chain CRFs'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
426,Could you provide a list of models that have been tested on the SST-2 Binary classification benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-2 Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-2 Binary classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9649122807017544,"(0.9818413853645325, 0.9765724539756775, 0.9791998267173767)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122632'}, 'model_lbl': {'type': 'literal', 'value': 'MPAD-path'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122153'}, 'model_lbl': {'type': 'literal', 'value': 'PAR BERT Base'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122154'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet-Large (ensemble)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122632'}, 'model_lbl': {'type': 'literal', 'value': 'MPAD-path'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122153'}, 'model_lbl': {'type': 'literal', 'value': 'PAR BERT Base'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119567'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (single model)'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122154'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet-Large (ensemble)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
427,What is the top benchmark score and its metric on the Hendrycks Test dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Hendrycks Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = "" Hendrycks Test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9114434865990404,0.9661016949152542,"(0.9803323745727539, 0.9789513945579529, 0.979641318321228)",[],"[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '43.9'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
428,Can you provide links to code used in papers that benchmark the KD-LSTMreg model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""KD-LSTMreg"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""KD-LSTMreg"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9607843137254902,"(0.9838622808456421, 0.9750456809997559, 0.9794341325759888)","[{'code': {'type': 'literal', 'value': 'https://github.com/helenabalabin/covid-19-document-classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dki-lab/covid19-classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/castorini/hedwig'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/helenabalabin/covid-19-document-classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dki-lab/covid19-classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/castorini/hedwig'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
429,What are the titles and IDs of research papers that include a benchmark for the NLP-TDMS dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9615384615384616,"(0.9805845022201538, 0.9728806614875793, 0.9767173528671265)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
430,Can you list the models that have been evaluated on the ClueWeb09-B dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ClueWeb09-B"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ClueWeb09-B"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9649122807017544,"(0.9816120266914368, 0.9763661623001099, 0.9789820313453674)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119139'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
431,Can you list the metrics used to evaluate models on the DocRED (Human-annotated) dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DocRED (Human-annotated)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DocRED"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.7965020533851944,0.925925925925926,"(0.9806383848190308, 0.9795073866844177, 0.9800726175308228)",[],[{}],"{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
432,Provide a list of papers that have utilized the CvT-21 (384 res) model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CvT-21 (384 res)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CvT-21 (384 res)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9649122807017544,"(0.983919084072113, 0.9748512506484985, 0.9793642163276672)","[{'code': {'type': 'literal', 'value': 'https://github.com/rishikksh20/convolution-vision-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/rishikksh20/convolution-vision-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lucidrains/vit-pytorch'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
433,Can you provide links to code used in papers that benchmark the FG fine-grained gate model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FG fine-grained gate"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""FG fine-grained gate"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9622641509433962,"(0.9829586744308472, 0.9747878313064575, 0.9788562059402466)","[{'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/fg-gating'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/fg-gating'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
434,"What is the highest benchmark result achieved on the NYT29 dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT29"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""NYT29"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9666666666666668,"(0.9829000234603882, 0.9808876514434814, 0.9818928241729736)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '71.6'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '71.6'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
435,Can you list the metrics used to evaluate models on the QNLI dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""QNLI"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9622641509433962,"(0.9828381538391113, 0.9767738580703735, 0.9797965884208679)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
436,Which model has achieved the highest Entity F1 score on the SciERC benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Entity F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SciERC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Entity F1"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""SciERC"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9649122807017544,"(0.9837048053741455, 0.9827216267585754, 0.9832130074501038)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116612'}, 'model_lbl': {'type': 'literal', 'value': 'SciBERT (SciVocab)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
437,What evaluation metrics are commonly used when benchmarking models on the SST-5 Fine-grained classification dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""SST-5 Fine-grained classification"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9343348130467294,0.9629629629629628,"(0.9816816449165344, 0.9753541946411133, 0.9785076975822449)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
438,"Can you provide the highest benchmark result, including the metric and score, for the Natural Questions (long) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Natural Questions (long)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9661016949152542,"(0.9821032285690308, 0.9804906845092773, 0.9812963008880615)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '76.5'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R114483'}, 'metric_lbl': {'type': 'literal', 'value': 'F1'}, 'score': {'type': 'literal', 'value': '76.5'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
439,What is the top benchmark result (metric and value) over the dataset WMT2016 Czech-English?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Czech-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2016 Czech-English"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.96875,"(0.9813634157180786, 0.980087399482727, 0.9807249903678894)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '31.4'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}, 'score': {'type': 'literal', 'value': '31.4'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
440,Which sectors are modeled as energy sectors and how often?,"SELECT ?label COUNT(?label)
WHERE {
  ?sector rdfs:label ?label;
          a ?class.
  ?class owl:equivalentClass <http://openenergy-platform.org/ontology/oeo/OEO_00000367>.
  [
    orkgp:P37668 ?sector
  ].
}","SELECT DISTINCT ?sector
WHERE {
  ?_ orkgp:compareContribution [
    orkgp:P32 [
      rdfs:label ?label
    ];
    orkgp:P5049 ?sector
  ]
  FILTER(REGEX(STR(?label), ""energy""))
}",5.70716620683989e-155,0.6376811594202898,"(0.8695181608200073, 0.8721003532409668, 0.8708073496818542)",[],,"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
441,Provide a list of research paper titles and IDs that have benchmarked models on the Kinetics-600 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Kinetics-600"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Kinetics-600"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9636363636363636,"(0.9826410412788391, 0.9750199317932129, 0.9788156747817993)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129958'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised MultiModal Versatile Networks'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129958'}, 'paper_lbl': {'type': 'literal', 'value': 'Self-Supervised MultiModal Versatile Networks'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
442,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Rotowire (Content Selection) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Rotowire (Content Selection)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9622641509433962,"(0.9819141626358032, 0.9744734168052673, 0.9781796932220459)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130466'}, 'paper_lbl': {'type': 'literal', 'value': 'Data-to-Text Generation with Content Selection and Planning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130479'}, 'paper_lbl': {'type': 'literal', 'value': 'Challenges in Data-to-Document Generation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130451'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Model for Data-to-Text Generation'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130466'}, 'paper_lbl': {'type': 'literal', 'value': 'Data-to-Text Generation with Content Selection and Planning'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130479'}, 'paper_lbl': {'type': 'literal', 'value': 'Challenges in Data-to-Document Generation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130451'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Model for Data-to-Text Generation'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
443,"What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? ","SELECT ?precision ?recall ?f1
WHERE {
  orkgr:R112387 orkgp:compareContribution ?contrib.
  ?contrib orkgp:P15006 ?algorithms.
  ?algorithms rdfs:label ?alg_names.
  FILTER(REGEX(?alg_names, ""Naive bayes""))
  ?algorithms orkgp:P36075 ?features.
  ?features rdfs:label ?fea_names.
  FILTER(REGEX(?fea_names, ""Bag of words""))
  ?features orkgp:P37029 ?categories.
  ?categories rdfs:label ?cat_names.
  FILTER(REGEX(?cat_names, ""Feature request""))
  ?categories orkgp:P3004 ?precision;
              orkgp:P5015 ?recall;
              orkgp:P18037 ?f1.
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?study a orkgc:Study.
  ?study orkgp:HAS_ALGORITHM ?algo.
  ?algo rdfs:label ""Naive Bayes"".
  ?study orkgp:HAS_FEATURE ?feature.
  ?feature rdfs:label ""Bag of Words"".
  ?study orkgp:HAS_TASK ?task.
  ?task rdfs:label ""Classify User Feedback as Feature Request"".
  ?study orkgp:HAS_EVALUATION ?eval.
  OPTIONAL {?eval orkgp:HAS_METRIC ?metric.
            ?metric rdfs:label ?metric_lbl.}
}",4.577147846387938e-155,0.6231884057971014,"(0.8654100894927979, 0.8674638271331787, 0.8664357662200928)",[],"[{'precision': {'type': 'literal', 'value': '0.77'}, 'recall': {'type': 'literal', 'value': '0.58'}, 'f1': {'type': 'literal', 'value': '0.66'}}, {'precision': {'type': 'literal', 'value': '0.72'}, 'recall': {'type': 'literal', 'value': '0.90'}, 'f1': {'type': 'literal', 'value': '0.80'}}, {'precision': {'type': 'literal', 'value': '0.28'}, 'recall': {'type': 'literal', 'value': '0.62'}, 'f1': {'type': 'literal', 'value': '0.39'}}, {'precision': {'type': 'literal', 'value': '0.67'}, 'recall': {'type': 'literal', 'value': '0.58'}, 'f1': {'type': 'literal', 'value': '0.62'}}, {'precision': {'type': 'literal', 'value': '0.67'}, 'recall': {'type': 'literal', 'value': '0.64'}, 'f1': {'type': 'literal', 'value': '0.65'}}, {'precision': {'type': 'literal', 'value': '0.71'}, 'recall': {'type': 'literal', 'value': '0.79'}, 'f1': {'type': 'literal', 'value': '0.75'}}, {'precision': {'type': 'literal', 'value': '0.20'}, 'recall': {'type': 'literal', 'value': '1.00'}, 'f1': {'type': 'literal', 'value': '0.33'}}, {'precision': {'type': 'literal', 'value': '0.89'}, 'recall': {'type': 'literal', 'value': '0.81'}, 'f1': {'type': 'literal', 'value': '0.85'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
444,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Dmlab-30 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Dmlab-30"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Dmlab-30"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9622641509433962,"(0.9816668033599854, 0.9742184281349182, 0.9779284596443176)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131297'}, 'paper_lbl': {'type': 'literal', 'value': 'Multi-task Deep Reinforcement Learning with PopArt'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131297'}, 'paper_lbl': {'type': 'literal', 'value': 'Multi-task Deep Reinforcement Learning with PopArt'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
445,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 German-English dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2016 German-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9297121915433836,0.9649122807017544,"(0.981514573097229, 0.9738689661026001, 0.9776768088340759)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129825'}, 'paper_lbl': {'type': 'literal', 'value': 'An Effective Approach to Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129839'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with SMT as Posterior Regularization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129654'}, 'paper_lbl': {'type': 'literal', 'value': 'Edinburgh Neural Machine Translation Systems for WMT 16'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129673'}, 'paper_lbl': {'type': 'literal', 'value': 'Phrase-Based & Neural Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129725'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Statistical Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129787'}, 'paper_lbl': {'type': 'literal', 'value': 'Linguistic Input Features Improve Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129793'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with Weight Sharing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129799'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Machine Translation Using Monolingual Corpora Only'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129825'}, 'paper_lbl': {'type': 'literal', 'value': 'An Effective Approach to Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129839'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with SMT as Posterior Regularization'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129853'}, 'paper_lbl': {'type': 'literal', 'value': 'Language Models are Few-Shot Learners'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129654'}, 'paper_lbl': {'type': 'literal', 'value': 'Edinburgh Neural Machine Translation Systems for WMT 16'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129673'}, 'paper_lbl': {'type': 'literal', 'value': 'Phrase-Based & Neural Unsupervised Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129725'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Statistical Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129787'}, 'paper_lbl': {'type': 'literal', 'value': 'Linguistic Input Features Improve Neural Machine Translation'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129793'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Neural Machine Translation with Weight Sharing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129799'}, 'paper_lbl': {'type': 'literal', 'value': 'Unsupervised Machine Translation Using Monolingual Corpora Only'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
446,"What is the highest benchmark result achieved on the Cartpole, swingup (DMControl500k) dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cartpole, swingup (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cartpole, swingup (DMControl500k)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.967741935483871,"(0.9821782112121582, 0.9817042350769043, 0.9819411635398865)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '841'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '841'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
447,What are the models that have been benchmarked on the Automatically labeled Medline abstracts corpus dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Automatically labeled Medline abstracts corpus"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9129476313504002,0.9642857142857144,"(0.9823339581489563, 0.9771748781204224, 0.9797475934028625)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226473'}, 'model_lbl': {'type': 'literal', 'value': 'linear-chain CRFs'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R226473'}, 'model_lbl': {'type': 'literal', 'value': 'linear-chain CRFs'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
448,"List the code links in papers that use the LSTM (Bai et al., 2018) model in any benchmark?","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LSTM (Bai et al., 2018)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""LSTM (Bai et al., 2018)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9343348130467294,0.9642857142857144,"(0.9837276339530945, 0.9747533798217773, 0.979219913482666)","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/sucheta19/Text-Classification-Using-CNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khappiya/rnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nic5472K/FriendsOOGroup_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zll1996/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/anandharaju/Basic_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/TensorFlow_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/linxi159/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/patHutchings/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ZTianle/keras-tcn-solar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/MChen9/TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShotDownDiane/tcn-master'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DevonFulcher/CryptoPricePredictor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/abduallahmohamed/MCRM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jxz542189/TCN_classification'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhong110020/pytorch_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jakeret/tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ashishpatel26/tcn-keras-Examples'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YuanTingHsieh/TF_TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Baichenjia/Tensorflow-TCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/csteinmetz1/ronn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Songweiping/TCN-TF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mhjabreel/CharCnn_Keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/IndicoDataSolutions/finetune'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philipperemy/keras-tcn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/locuslab/TCN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
449,What is the top benchmark result (metric and value) over the dataset Oxford-IIIT Pets?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Oxford-IIIT Pets"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9666666666666668,"(0.9817191958427429, 0.9805453419685364, 0.981131911277771)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '99.91'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '94.3'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '86.4M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '744M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116078'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Error Rate'}, 'score': {'type': 'literal', 'value': '6.2%'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R111697'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy'}, 'score': {'type': 'literal', 'value': '99.91'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115579'}, 'metric_lbl': {'type': 'literal', 'value': 'Accuracy (%)'}, 'score': {'type': 'literal', 'value': '94.3'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123735'}, 'metric_lbl': {'type': 'literal', 'value': 'PARAMS'}, 'score': {'type': 'literal', 'value': '86.4M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123734'}, 'metric_lbl': {'type': 'literal', 'value': 'FLOPS'}, 'score': {'type': 'literal', 'value': '744M'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116078'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Error Rate'}, 'score': {'type': 'literal', 'value': '6.2%'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
450,Can you provide links to code used in papers that benchmark the XLNet-Large model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet-Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""XLNet-Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9836224913597107, 0.9747023582458496, 0.9791420698165894)","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/anli'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zaradana/Fast_BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pauldevos/python-notes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tomgoter/nlp_finalproject'}}, {'code': {'type': 'literal', 'value': 'https://github.com/2miatran/Natural-Language-Processing'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fanchenyou/transformer-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cuhksz-nlp/SAPar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/studio-ousia/luke'}}, {'code': {'type': 'literal', 'value': 'https://github.com/graykode/xlnet-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utterworks/fast-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaushaltrivedi/fast-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zihangdai/xlnet'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/anli'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zaradana/Fast_BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/pauldevos/python-notes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tomgoter/nlp_finalproject'}}, {'code': {'type': 'literal', 'value': 'https://github.com/2miatran/Natural-Language-Processing'}}, {'code': {'type': 'literal', 'value': 'https://github.com/fanchenyou/transformer-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cuhksz-nlp/SAPar'}}, {'code': {'type': 'literal', 'value': 'https://github.com/studio-ousia/luke'}}, {'code': {'type': 'literal', 'value': 'https://github.com/graykode/xlnet-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/utterworks/fast-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaushaltrivedi/fast-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zihangdai/xlnet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
451,Where can I find code references in papers that have used the EfficientNetV2-L model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""EfficientNetV2-L"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""EfficientNetV2-L"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9629629629629628,"(0.9838333129882812, 0.9750425815582275, 0.9794182181358337)","[{'code': {'type': 'literal', 'value': 'https://github.com/jahongir7174/EffcientNetV2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google/automl/tree/master/efficientnetv2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lukemelas/EfficientNet-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rwightman/pytorch-image-models'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/jahongir7174/EffcientNetV2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google/automl/tree/master/efficientnetv2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lukemelas/EfficientNet-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rwightman/pytorch-image-models'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
452,"Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-46985 dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-46985"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-46985"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9655172413793104,"(0.9817678928375244, 0.9741848111152649, 0.9779616594314575)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134494'}, 'paper_lbl': {'type': 'literal', 'value': 'HDLTex: Hierarchical Deep Learning for Text Classification'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R134494'}, 'paper_lbl': {'type': 'literal', 'value': 'HDLTex: Hierarchical Deep Learning for Text Classification'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
453,"What is the highest benchmark result achieved on the Supervised: dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Supervised:"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9669306597086388,0.9655172413793104,"(0.9827108979225159, 0.9807031750679016, 0.9817059636116028)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120654'}, 'metric_lbl': {'type': 'literal', 'value': 'Senseval 2'}, 'score': {'type': 'literal', 'value': '71.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120653'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2015'}, 'score': {'type': 'literal', 'value': '71.3'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120655'}, 'metric_lbl': {'type': 'literal', 'value': 'Senseval 3'}, 'score': {'type': 'literal', 'value': '69.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120652'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2013'}, 'score': {'type': 'literal', 'value': '66.2'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120651'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2007'}, 'score': {'type': 'literal', 'value': '62.2'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120654'}, 'metric_lbl': {'type': 'literal', 'value': 'Senseval 2'}, 'score': {'type': 'literal', 'value': '71.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120653'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2015'}, 'score': {'type': 'literal', 'value': '71.3'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120655'}, 'metric_lbl': {'type': 'literal', 'value': 'Senseval 3'}, 'score': {'type': 'literal', 'value': '69.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120652'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2013'}, 'score': {'type': 'literal', 'value': '66.2'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120651'}, 'metric_lbl': {'type': 'literal', 'value': 'SemEval 2007'}, 'score': {'type': 'literal', 'value': '62.2'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
454,What is the best performing model benchmarking the ANLI test dataset in terms of A3 metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A3"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI test"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""A3"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ANLI"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9196822664155296,0.9649122807017544,"(0.9828413724899292, 0.9816400408744812, 0.9822403192520142)",[],"[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R120755'}, 'model_lbl': {'type': 'literal', 'value': 'XLNet (Large)'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
455,What are the metrics of evaluation over the iNaturalist 2019 dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""iNaturalist 2019"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""iNaturalist 2019"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9649122807017544,"(0.9830663800239563, 0.976896345615387, 0.9799716472625732)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
456,What are the models that have been benchmarked on the Atari 2600 Space Invaders dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Space Invaders"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Space Invaders"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9649122807017544,"(0.9813653230667114, 0.9760065674781799, 0.9786785840988159)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124927'}, 'model_lbl': {'type': 'literal', 'value': 'IDVQ + DRSC + XNES'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124950'}, 'model_lbl': {'type': 'literal', 'value': 'Rainbow'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124948'}, 'model_lbl': {'type': 'literal', 'value': 'MFEC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124915'}, 'model_lbl': {'type': 'literal', 'value': 'DDRL A3C'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124918'}, 'model_lbl': {'type': 'literal', 'value': 'DQN Best'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124906'}, 'model_lbl': {'type': 'literal', 'value': 'DARQN soft'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124927'}, 'model_lbl': {'type': 'literal', 'value': 'IDVQ + DRSC + XNES'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124932'}, 'model_lbl': {'type': 'literal', 'value': 'FQF'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124950'}, 'model_lbl': {'type': 'literal', 'value': 'Rainbow'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124948'}, 'model_lbl': {'type': 'literal', 'value': 'MFEC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124915'}, 'model_lbl': {'type': 'literal', 'value': 'DDRL A3C'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124918'}, 'model_lbl': {'type': 'literal', 'value': 'DQN Best'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124905'}, 'model_lbl': {'type': 'literal', 'value': 'Recurrent Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124907'}, 'model_lbl': {'type': 'literal', 'value': 'Rational DQN Average'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124906'}, 'model_lbl': {'type': 'literal', 'value': 'DARQN soft'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119888'}, 'model_lbl': {'type': 'literal', 'value': 'MAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
457,Which model has achieved the highest BLEU score score on the WMT2014 English-German benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""BLEU score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""WMT2014 English-German"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9657992495762466,0.9672131147540984,"(0.9823900461196899, 0.9809402227401733, 0.9816645979881287)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117264'}, 'model_lbl': {'type': 'literal', 'value': 'Transformer Big + adversarial MLE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117264'}, 'model_lbl': {'type': 'literal', 'value': 'Transformer Big + adversarial MLE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
458,Provide a list of research paper titles and IDs that have benchmarked models on the Cart Pole (OpenAI Gym) dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9343348130467294,0.9629629629629628,"(0.9819411635398865, 0.9744622111320496, 0.9781873822212219)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131248'}, 'paper_lbl': {'type': 'literal', 'value': 'Mean Actor Critic'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131248'}, 'paper_lbl': {'type': 'literal', 'value': 'Mean Actor Critic'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
459,Provide a list of papers that have utilized the A3C FF hs model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""A3C FF hs"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9607843137254902,"(0.9835385084152222, 0.9743348360061646, 0.9789150357246399)","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/liuyuezhang/pyrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/chainer/chainerrl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/aabbeell/reinforcementLearning.a2c.gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/alexmlamb/blocks_rl_gru_setup'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JulT1/RL_SS19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ofekluis/sonic_project_ss19'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/demo-advantage-actor-critic'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AI-RG/rl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/natsumeS/analysis'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PaulCharnay/Projet_AIF'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Remtasya/DDPG-Actor-Critic-Reinforcement-Learning-Reacher-Environment'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jzar/Space-Invaders-DQN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jventajas/Reinforcement-Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sharan-dce/A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hill-a/stable-baselines'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NervanaSystems/coach'}}, {'code': {'type': 'literal', 'value': 'https://github.com/DLR-RM/stable-baselines3'}}, {'code': {'type': 'literal', 'value': 'https://github.com/openai/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-a3c'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Khrylx/PyTorch-RL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/miyosuda/async_deep_reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yukezhu/tensorflow-reinforce'}}, {'code': {'type': 'literal', 'value': 'https://github.com/muupan/async-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/DeepRL-TensorFlow2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/marload/deep-rl-tf2'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dickreuter/neuron_poker'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/ACER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Kaixhin/NoisyNet-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bentrevett/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Nasdin/ReinforcementLearning-AtariGame'}}, {'code': {'type': 'literal', 'value': 'https://github.com/khanhptnk/bandit-nmt'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lcswillems/torch-ac'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arnomoonens/yarll'}}, {'code': {'type': 'literal', 'value': 'https://github.com/traai/async-deep-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/deepsense-ai/Distributed-BA3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ikostrikov/pytorch-rl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ShibiHe/Q-Optimality-Tightening'}}, {'code': {'type': 'literal', 'value': 'https://github.com/qihongl/dlstm-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/roop-pal/Meta-Learning-for-StarCraft-II-Minigames'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Sheepsody/Batched-Impala-PyTorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/grananqvist/reinforcement-learning-super-mario-A3C'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vladfi1/universe-starter-agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/braemt/attentive-multi-task-deep-reinforcement-learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/4rChon/NL-FuN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mavischer/DRRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/avillemin/Minecraft-AI'}}, {'code': {'type': 'literal', 'value': 'https://github.com/dsinghnegi/atari_RL_agent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/InSpaceAI/RL-Zoo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Zartris/TD3_continuous_control'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cdesilv1/sc2_ai_cdes'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wtingda/DeepRLBreakout'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sainijagjit/A3C-Pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/hack-flappy-bird-drl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/haroldmei/pysc2-study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amanda-lambda/drl-experiments'}}, {'code': {'type': 'literal', 'value': 'https://github.com/gungui98/deeprl-a3c-ai2thor'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxj77/TransferReinforcementLearning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amaudruz/RL_openaigym'}}, {'code': {'type': 'literal', 'value': 'https://github.com/hulanwin/A3C-DRL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/joshiatul/game_playing'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
460,Where can I find code references in papers that have used the BiDAF + Self Attention + ELMo model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9364250605898116,0.9615384615384616,"(0.9835708737373352, 0.9745848178863525, 0.979057252407074)","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
461,List the metrics that are used to evaluate models on the NCBI Disease benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI Disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NCBI Disease"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8945648481322716,0.9622641509433962,"(0.9801157712936401, 0.9746954441070557, 0.9773980975151062)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122892'}, 'metric_lbl': {'type': 'literal', 'value': 'F1 entity level'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
462,Where can I find code references in papers that have used the 6-layer QRNN model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""6-layer QRNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""6-layer QRNN"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9629629629629628,"(0.9821540117263794, 0.9725959897041321, 0.9773516058921814)","[{'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/lookahead-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/awd-lstm-test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/soyoung97/awd-lstm-gru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arvieFrydenlund/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/llppff/ptb-lstmorqrnn-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ari-holtzman/genlm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/treelangrnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SachinIchake/KALM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/salesforce/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Han-JD/GRU-D'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/AtheMathmo/lookahead-lstm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/awd-lstm-test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/soyoung97/awd-lstm-gru'}}, {'code': {'type': 'literal', 'value': 'https://github.com/arvieFrydenlund/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/llppff/ptb-lstmorqrnn-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ari-holtzman/genlm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/philippwirth/treelangrnn'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SachinIchake/KALM'}}, {'code': {'type': 'literal', 'value': 'https://github.com/salesforce/awd-lstm-lm'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Han-JD/GRU-D'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
463,What models are being evaluated on the WOS-11967 dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-11967"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WOS-11967"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9655172413793104,"(0.982245922088623, 0.9770655632019043, 0.9796488881111145)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125975'}, 'model_lbl': {'type': 'literal', 'value': 'HDLTex'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125975'}, 'model_lbl': {'type': 'literal', 'value': 'HDLTex'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
464,List the title and ID of research papers that contain a benchmark over the NYT24 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT24"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NYT24"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9815306067466736, 0.9741231203079224, 0.9778128266334534)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129390'}, 'paper_lbl': {'type': 'literal', 'value': 'Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129399'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Framework for Relation Extraction with Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129390'}, 'paper_lbl': {'type': 'literal', 'value': 'Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129399'}, 'paper_lbl': {'type': 'literal', 'value': 'A Hierarchical Framework for Relation Extraction with Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
465,Name the datasets that have been used for benchmarking in the Robot Navigation research problem?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Robot Navigation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Robot Navigation"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9622641509433962,"(0.9836664795875549, 0.9767000675201416, 0.9801709055900574)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123467'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Point Nav test-std'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123476'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Object Nav test-std'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123467'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Point Nav test-std'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123476'}, 'dataset_lbl': {'type': 'literal', 'value': 'Habitat 2020 Object Nav test-std'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
466,Could you provide a list of models that have been tested on the seel.cse.lsu.edu/data/refsq17.zip benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/refsq17.zip"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/refsq17.zip"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9830508474576272,"(0.983007550239563, 0.9781476259231567, 0.9805715680122375)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
467,Could you provide a list of models that have been tested on the IMDb-M benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""IMDb-M"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""IMDb-M"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9629629629629628,"(0.9824752807617188, 0.9773755669593811, 0.9799188375473022)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R125945'}, 'model_lbl': {'type': 'literal', 'value': 'ApproxRepSet'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
468,Where can I find code references in papers that have used the PEGASUS model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PEGASUS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PEGASUS"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9615384615384616,"(0.9837785363197327, 0.9749815464019775, 0.9793603420257568)","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ibrahim-elsawy/test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vdavid033/Pegasus-Google-'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rsin46/pegasus-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amiyamandal-dev/pegasus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ManuMahadevaswamy/PEGASUS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jiacheng-xu/text-sum-uncertainty'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/pegasus'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ibrahim-elsawy/test'}}, {'code': {'type': 'literal', 'value': 'https://github.com/vdavid033/Pegasus-Google-'}}, {'code': {'type': 'literal', 'value': 'https://github.com/rsin46/pegasus-demo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/amiyamandal-dev/pegasus'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ManuMahadevaswamy/PEGASUS'}}, {'code': {'type': 'literal', 'value': 'https://github.com/jiacheng-xu/text-sum-uncertainty'}}, {'code': {'type': 'literal', 'value': 'https://github.com/google-research/pegasus'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
469,Provide a list of benchmarked datasets related to the Audio Classification research area?,"SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Audio Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}","SELECT DISTINCT ?dataset ?dataset_lbl
WHERE {
  ?problem       a                orkgc:Problem;
                 rdfs:label       ?problem_lbl.  
  FILTER (str(?problem_lbl) = ""Audio Classification"")
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;
                  orkgp:P32                ?problem.
}",0.9343348130467294,0.9622641509433962,"(0.9822960495948792, 0.9754508137702942, 0.9788615107536316)","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122332'}, 'dataset_lbl': {'type': 'literal', 'value': 'AudioSet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121347'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127290'}, 'dataset_lbl': {'type': 'literal', 'value': 'ModelNet40'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122340'}, 'dataset_lbl': {'type': 'literal', 'value': 'ESC-50'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118532'}, 'dataset_lbl': {'type': 'literal', 'value': 'Multimodal PISA'}}]","[{'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122332'}, 'dataset_lbl': {'type': 'literal', 'value': 'AudioSet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121347'}, 'dataset_lbl': {'type': 'literal', 'value': 'ImageNet'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R127290'}, 'dataset_lbl': {'type': 'literal', 'value': 'ModelNet40'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R122340'}, 'dataset_lbl': {'type': 'literal', 'value': 'ESC-50'}}, {'dataset': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118532'}, 'dataset_lbl': {'type': 'literal', 'value': 'Multimodal PISA'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
470,"Can you provide the highest benchmark result, including the metric and score, for the Cart Pole (OpenAI Gym) dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Cart Pole (OpenAI Gym)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?eval           orkgp:HAS_VALUE         ?value.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}
GROUP BY ?metric ?metric_lbl
ORDER BY DESC(?value)",0.6069483815824188,0.9491525423728814,"(0.9394906163215637, 0.947074830532074, 0.9432675242424011)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '178.3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '178.3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
471,"What are the titles and IDs of research papers that include a benchmark for the Reacher, easy (DMControl100k) dataset?","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Reacher, easy (DMControl100k)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9321022168949714,0.9629629629629628,"(0.9816072583198547, 0.9742113351821899, 0.9778953194618225)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R131170'}, 'paper_lbl': {'type': 'literal', 'value': 'CURL: Contrastive Unsupervised Representations for Reinforcement Learning'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
472,Which model has achieved the highest MACs score on the ImageNet benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""MACs"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""MACs"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ImageNet"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9645876452711916,0.9642857142857144,"(0.9839190244674683, 0.9827760457992554, 0.9833472371101379)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126160'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (ResNet)'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126160'}, 'model_lbl': {'type': 'literal', 'value': 'BiT-L (ResNet)'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
473,"Can you provide the highest benchmark result, including the metric and score, for the ACE 2005 dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2005"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""ACE 2005"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9674687404175402,0.9672131147540984,"(0.9820543527603149, 0.9805359840393066, 0.981294572353363)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116637'}, 'metric_lbl': {'type': 'literal', 'value': 'Sentence Encoder'}, 'score': {'type': 'literal', 'value': 'biLSTM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116617'}, 'metric_lbl': {'type': 'literal', 'value': 'NER Micro F1'}, 'score': {'type': 'literal', 'value': '89.5'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116646'}, 'metric_lbl': {'type': 'literal', 'value': 'Relation F1'}, 'score': {'type': 'literal', 'value': '67.8'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116628'}, 'metric_lbl': {'type': 'literal', 'value': 'RE Micro F1'}, 'score': {'type': 'literal', 'value': '67.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116619'}, 'metric_lbl': {'type': 'literal', 'value': 'RE+ Micro F1'}, 'score': {'type': 'literal', 'value': '64.3'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116637'}, 'metric_lbl': {'type': 'literal', 'value': 'Sentence Encoder'}, 'score': {'type': 'literal', 'value': 'biLSTM'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116617'}, 'metric_lbl': {'type': 'literal', 'value': 'NER Micro F1'}, 'score': {'type': 'literal', 'value': '89.5'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116646'}, 'metric_lbl': {'type': 'literal', 'value': 'Relation F1'}, 'score': {'type': 'literal', 'value': '67.8'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116628'}, 'metric_lbl': {'type': 'literal', 'value': 'RE Micro F1'}, 'score': {'type': 'literal', 'value': '67.6'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116619'}, 'metric_lbl': {'type': 'literal', 'value': 'RE+ Micro F1'}, 'score': {'type': 'literal', 'value': '64.3'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
474,List the metrics that are used to evaluate models on the DBpedia benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DBpedia"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""DBpedia"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.8907171682201394,0.9622641509433962,"(0.9805430769920349, 0.975388765335083, 0.9779590964317322)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119433'}, 'metric_lbl': {'type': 'literal', 'value': 'Error'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
475,What is the top benchmark result (metric and value) over the dataset Atari 2600 Enduro?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Enduro"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9672131147540984,"(0.9822758436203003, 0.9805240035057068, 0.9813991189002991)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '957'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '957'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
476,What are the metrics of evaluation over the Hutter Prize dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Hutter Prize"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Hutter Prize"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9629629629629628,"(0.9829684495925903, 0.976773202419281, 0.9798610806465149)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116794'}, 'metric_lbl': {'type': 'literal', 'value': 'Bit per Character (BPC)'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115739'}, 'metric_lbl': {'type': 'literal', 'value': 'Number of params'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
477,"Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/re17.zip  dataset?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip "")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""seel.cse.lsu.edu/data/re17.zip"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.925039248827207,0.967741935483871,"(0.9800602793693542, 0.9785491228103638, 0.9793041348457336)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
478,What is the top benchmark score and its metric on the Atari 2600 Wizard of Wor dataset?,"SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Wizard of Wor"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Wizard of Wor"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9689827775496296,0.967741935483871,"(0.9816513061523438, 0.9804186224937439, 0.9810345768928528)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9300.0'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '9300.0'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
479,List the code links in papers that use the 12-layer Transformer-XL model in any benchmark?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""12-layer Transformer-XL"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""12-layer Transformer-XL"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9271474438253492,0.9636363636363636,"(0.9840513467788696, 0.9752829670906067, 0.9796475172042847)","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/benkrause/dynamiceval-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cmunnis/BERT_vs_Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cedrickchee/pytorch-pretrained-BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/threelittlemonkeys/transformer-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/inzva/fake-academic-paper-generation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/nlp-attentions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sh951011/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TimDettmers/transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/okkteam/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/code-prediction-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxt1997/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/conformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn/tree/master/labml_nn/transformers/xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/transformer-xl'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/huggingface/transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/benkrause/dynamiceval-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Machine-Learning-Tokyo/Poetry-GAN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/listenviolet/XLNet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/samwisegamjeee/pytorch-transformers'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cmunnis/BERT_vs_Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zhdbwe/Paper-DailyReading'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cedrickchee/pytorch-pretrained-BERT'}}, {'code': {'type': 'literal', 'value': 'https://github.com/threelittlemonkeys/transformer-pytorch'}}, {'code': {'type': 'literal', 'value': 'https://github.com/huggingface/xlnet'}}, {'code': {'type': 'literal', 'value': 'https://github.com/inzva/fake-academic-paper-generation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/nlp-attentions'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sh951011/Attention-Implementation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TimDettmers/transformer-xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/okkteam/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/facebookresearch/code-prediction-transformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/wxt1997/Transformer-Transducer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sooftware/conformer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/lab-ml/nn/tree/master/labml_nn/transformers/xl'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kimiyoung/transformer-xl'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
480,What is the best performing model benchmarking the Atari 2600 Up and Down dataset in terms of Score metric?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""Score"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Up and Down"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.9669306597086388,0.9666666666666668,"(0.9813941717147827, 0.9801748394966125, 0.9807841181755066)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
481,"Could you provide a list of models that have been tested on the NLP-TDMS (Exp, arXiv only) benchmark dataset?","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""NLP-TDMS (Exp, arXiv only)"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9661016949152542,"(0.9825182557106018, 0.9777607321739197, 0.9801337122917175)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128071'}, 'model_lbl': {'type': 'literal', 'value': 'AxCell'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128071'}, 'model_lbl': {'type': 'literal', 'value': 'AxCell'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R128075'}, 'model_lbl': {'type': 'literal', 'value': 'TDMS-IE'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
482,What are the models that have been benchmarked on the  Jacquard dataset dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = "" Jacquard dataset"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Jacquard"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.7917934261493339,0.9818181818181818,"(0.9784108400344849, 0.9728213548660278, 0.9756080508232117)",[],"[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R121352'}, 'model_lbl': {'type': 'literal', 'value': 'GR-ConvNet'}}]","{'exact_match': False, 'precision': 0.0, 'recall': 0, 'f1_score': 0, 'jaccard': 0.0}"
483,What are the metrics of evaluation over the ObjectNet dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""ObjectNet"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9297121915433836,0.9622641509433962,"(0.9831738471984863, 0.9769400358200073, 0.9800470471382141)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115539'}, 'metric_lbl': {'type': 'literal', 'value': 'Top 5 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R115539'}, 'metric_lbl': {'type': 'literal', 'value': 'Top 5 Accuracy'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R118364'}, 'metric_lbl': {'type': 'literal', 'value': 'Top-1 Accuracy'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
484,Provide a list of research paper titles and IDs that have benchmarked models on the enwik8 dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""enwik8"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9629629629629628,"(0.9819162487983704, 0.9742516279220581, 0.9780688881874084)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130498'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Transformer Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130521'}, 'paper_lbl': {'type': 'literal', 'value': 'When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130545'}, 'paper_lbl': {'type': 'literal', 'value': 'Addressing Some Limitations of Transformers with Feedback Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130563'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Transformer Models by Reordering their Sublayers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130572'}, 'paper_lbl': {'type': 'literal', 'value': 'Compressive Transformers for Long-Range Sequence Modelling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130584'}, 'paper_lbl': {'type': 'literal', 'value': 'Adaptive Attention Span in Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130601'}, 'paper_lbl': {'type': 'literal', 'value': 'Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130652'}, 'paper_lbl': {'type': 'literal', 'value': 'Longformer: The Long-Document Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130669'}, 'paper_lbl': {'type': 'literal', 'value': 'Augmenting Self-attention with Persistent Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130689'}, 'paper_lbl': {'type': 'literal', 'value': 'Character-Level Language Modeling with Deeper Self-Attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130712'}, 'paper_lbl': {'type': 'literal', 'value': 'An Analysis of Neural Language Modeling at Multiple Scales'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130733'}, 'paper_lbl': {'type': 'literal', 'value': 'Multiplicative LSTM for sequence modelling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130749'}, 'paper_lbl': {'type': 'literal', 'value': 'Fast-Slow Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130768'}, 'paper_lbl': {'type': 'literal', 'value': 'Hierarchical Multiscale Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130777'}, 'paper_lbl': {'type': 'literal', 'value': 'HyperNetworks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129926'}, 'paper_lbl': {'type': 'literal', 'value': 'Generating Long Sequences with Sparse Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130209'}, 'paper_lbl': {'type': 'literal', 'value': 'Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130498'}, 'paper_lbl': {'type': 'literal', 'value': 'Dynamic Evaluation of Transformer Language Models'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130521'}, 'paper_lbl': {'type': 'literal', 'value': 'When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130545'}, 'paper_lbl': {'type': 'literal', 'value': 'Addressing Some Limitations of Transformers with Feedback Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130563'}, 'paper_lbl': {'type': 'literal', 'value': 'Improving Transformer Models by Reordering their Sublayers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130572'}, 'paper_lbl': {'type': 'literal', 'value': 'Compressive Transformers for Long-Range Sequence Modelling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130584'}, 'paper_lbl': {'type': 'literal', 'value': 'Adaptive Attention Span in Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130601'}, 'paper_lbl': {'type': 'literal', 'value': 'Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130652'}, 'paper_lbl': {'type': 'literal', 'value': 'Longformer: The Long-Document Transformer'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130669'}, 'paper_lbl': {'type': 'literal', 'value': 'Augmenting Self-attention with Persistent Memory'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130689'}, 'paper_lbl': {'type': 'literal', 'value': 'Character-Level Language Modeling with Deeper Self-Attention'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130712'}, 'paper_lbl': {'type': 'literal', 'value': 'An Analysis of Neural Language Modeling at Multiple Scales'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130733'}, 'paper_lbl': {'type': 'literal', 'value': 'Multiplicative LSTM for sequence modelling'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130749'}, 'paper_lbl': {'type': 'literal', 'value': 'Fast-Slow Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130768'}, 'paper_lbl': {'type': 'literal', 'value': 'Hierarchical Multiscale Recurrent Neural Networks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130777'}, 'paper_lbl': {'type': 'literal', 'value': 'HyperNetworks'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129926'}, 'paper_lbl': {'type': 'literal', 'value': 'Generating Long Sequences with Sparse Transformers'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R130209'}, 'paper_lbl': {'type': 'literal', 'value': 'Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
485,Indicate the model that performed best in terms of PARAMS metric on the FGVC Aircraft benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""PARAMS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FGVC Aircraft"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?metric     a       orkgc:Metric;
              rdfs:label  ?metric_lbl.
  FILTER (str(?metric_lbl) = ""PARAMS"")
  {
    SELECT ?model ?model_lbl
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""FGVC Aircraft"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value;
                      orkgp:HAS_METRIC         ?metric.
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;
                    orkgp:HAS_MODEL          ?model.
      ?model      rdfs:label               ?model_lbl.
    }
    ORDER BY DESC(?value)
    LIMIT 1
  }
}",0.965203995518736,0.9655172413793104,"(0.9821394085884094, 0.9813907146453857, 0.9817649126052856)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126666'}, 'model_lbl': {'type': 'literal', 'value': 'ImageNet + iNat on WS-DAN'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R126666'}, 'model_lbl': {'type': 'literal', 'value': 'ImageNet + iNat on WS-DAN'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
486,List the metrics that are used to evaluate models on the Atari 2600 Battle Zone benchmark dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Battle Zone"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}}",0.9014996327760888,0.9649122807017544,"(0.9808177947998047, 0.9754834175109863, 0.9781433343887329)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
487,What are the models that have been benchmarked on the Atari 2600 Road Runner dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Road Runner"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Road Runner"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9103429040065264,0.9655172413793104,"(0.9822406768798828, 0.976991593837738, 0.9796090722084045)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124926'}, 'model_lbl': {'type': 'literal', 'value': 'Rainbow+SEER'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123322'}, 'model_lbl': {'type': 'literal', 'value': 'SAC'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124926'}, 'model_lbl': {'type': 'literal', 'value': 'Rainbow+SEER'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
488,Can you list the models that have been evaluated on the Atari 2600 Boxing dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Boxing"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9075772733559514,0.9655172413793104,"(0.9825948476791382, 0.9773893356323242, 0.9799851775169373)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124915'}, 'model_lbl': {'type': 'literal', 'value': 'DDRL A3C'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124931'}, 'model_lbl': {'type': 'literal', 'value': 'Reactor 500M'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124915'}, 'model_lbl': {'type': 'literal', 'value': 'DDRL A3C'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123293'}, 'model_lbl': {'type': 'literal', 'value': 'CURL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
489,What evaluation metrics are commonly used when benchmarking models on the WMT2014 French-English dataset?,"SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}","SELECT DISTINCT ?metric ?metric_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""WMT2014 French-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
           ?metric          rdfs:label               ?metric_lbl.}
}",0.9321022168949714,0.9649122807017544,"(0.9829304218292236, 0.9765206575393677, 0.9797150492668152)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R116443'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU'}}, {'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R117121'}, 'metric_lbl': {'type': 'literal', 'value': 'BLEU score'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
490,Can you list the models that have been evaluated on the BUCC French-to-English dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""BUCC French-to-English"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.90463533101174,0.9636363636363636,"(0.981959879398346, 0.9767647981643677, 0.9793553948402405)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124053'}, 'model_lbl': {'type': 'literal', 'value': 'Massively Multilingual Sentence Embeddings'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
491,Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (single model) model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo (single model)"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BiDAF + Self Attention + ELMo"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.8547305998833805,0.9615384615384616,"(0.9826991558074951, 0.9762600660324097, 0.9794690608978271)","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/dmlc/gluon-nlp'}}, {'code': {'type': 'literal', 'value': 'https://github.com/LamLauChiu/Tensorflow_Learning'}}, {'code': {'type': 'literal', 'value': 'https://github.com/nlp-research/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangzonglin1994/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/weixsong/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yangrui123/Hidden'}}, {'code': {'type': 'literal', 'value': 'https://github.com/young-zonglin/bilm-tf-extended'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kunde122/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/seunghwan1228/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kafura-kafiri/tf2-elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shaneding/bilm-tf-experimentation'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ankurbanga/Language-Models'}}, {'code': {'type': 'literal', 'value': 'https://github.com/richinkabra/CoVe-BCN'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kinimod23/NMT_Project'}}, {'code': {'type': 'literal', 'value': 'https://github.com/ajovanov95/probabilistic-spiking-neural-networks'}}, {'code': {'type': 'literal', 'value': 'https://github.com/cheng18/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/sarveshsparab/DeepElmoEmbedNer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/shelleyHLX/bilm_EMLo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/mingdachen/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/menajosep/AleatoricSent'}}, {'code': {'type': 'literal', 'value': 'https://github.com/TEAMLAB-Lecture/deep_nlp_101'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanjing-zhu/elmo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/bestend/tf2-bi-lstm-crf-nni'}}, {'code': {'type': 'literal', 'value': 'https://github.com/AshwinDeshpande96/Hierarchical-Softmax'}}, {'code': {'type': 'literal', 'value': 'https://github.com/SeonbeomKim/TensorFlow-ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/griff4692/LMC'}}, {'code': {'type': 'literal', 'value': 'https://github.com/RundongChou/elmo-chinese-oversimplified'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zenanz/ChemPatentEmbeddings'}}, {'code': {'type': 'literal', 'value': 'https://github.com/horizonheart/ELMO'}}, {'code': {'type': 'literal', 'value': 'https://github.com/kaist-dmlab/BioNER'}}, {'code': {'type': 'literal', 'value': 'https://github.com/yuanxiaosc/ELMo'}}, {'code': {'type': 'literal', 'value': 'https://github.com/JHart96/keras_elmo_embedding_layer'}}, {'code': {'type': 'literal', 'value': 'https://github.com/YC-wind/embedding_study'}}, {'code': {'type': 'literal', 'value': 'https://github.com/helboukkouri/character-bert'}}, {'code': {'type': 'literal', 'value': 'https://github.com/iliaschalkidis/ELMo-keras'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/Elmo-Tutorial'}}, {'code': {'type': 'literal', 'value': 'https://github.com/PrashantRanjan09/WordEmbeddings-Elmo-Fasttext-Word2Vec'}}, {'code': {'type': 'literal', 'value': 'https://github.com/UKPLab/elmo-bilstm-cnn-crf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/HIT-SCIR/ELMoForManyLangs'}}, {'code': {'type': 'literal', 'value': 'https://github.com/Hironsan/anago'}}, {'code': {'type': 'literal', 'value': 'https://github.com/allenai/bilm-tf'}}, {'code': {'type': 'literal', 'value': 'https://github.com/zalandoresearch/flair'}}, {'code': {'type': 'literal', 'value': 'https://github.com/flairNLP/flair'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
492,What models are being evaluated on the AESLC dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AESLC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""AESLC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9014996327760888,0.9622641509433962,"(0.982234001159668, 0.9767946004867554, 0.97950679063797)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124688'}, 'model_lbl': {'type': 'literal', 'value': 'PEGASUS'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124688'}, 'model_lbl': {'type': 'literal', 'value': 'PEGASUS'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
493,What are the titles and IDs of research papers that include a benchmark for the HoC dataset?,"SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HoC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}","SELECT DISTINCT ?paper ?paper_lbl
WHERE {
  ?dataset        a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""HoC"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset.
  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.
  ?paper         orkgp:P31                ?cont;
                 rdfs:label               ?paper_lbl.
}",0.9271474438253492,0.9607843137254902,"(0.9821164608001709, 0.9744173288345337, 0.9782517552375793)","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","[{'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129608'}, 'paper_lbl': {'type': 'literal', 'value': 'Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing'}}, {'paper': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R129632'}, 'paper_lbl': {'type': 'literal', 'value': 'Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
494,Where can I find code references in papers that have used the PAR Transformer Large model for benchmarking purposes?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PAR Transformer Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""PAR Transformer Large"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9297121915433836,0.9607843137254902,"(0.9835805296897888, 0.9749769568443298, 0.9792598485946655)","[{'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/Jmkernes/PAR-Transformer-XL'}}, {'code': {'type': 'literal', 'value': 'https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
495,Can you provide links to code used in papers that benchmark the BERTwwm + SQuAD 2 model?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERTwwm + SQuAD 2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""BERTwwm + SQuAD 2"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9321022168949714,0.9636363636363636,"(0.9836679697036743, 0.9746648073196411, 0.9791457056999207)",[],[],"{'exact_match': True, 'precision': 0, 'recall': 0, 'f1_score': 0, 'jaccard': 1.0}"
496,Provide a list of papers that have utilized the CL-Titles-Parser model and include the links to their code?,"SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CL-Titles-Parser"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}","SELECT DISTINCT ?code
WHERE {
  ?model    a            orkgc:Model;
            rdfs:label    ?model_lbl.
  FILTER (str(?model_lbl) = ""CL-Titles-Parser"")
  ?benchmark      orkgp:HAS_DATASET        ?dataset.
  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.
  ?cont           orkgp:HAS_MODEL          ?model;
                  orkgp:HAS_SOURCE_CODE    ?code.
}",0.9243880458347608,0.9622641509433962,"(0.9840714335441589, 0.9752213954925537, 0.9796264171600342)","[{'code': {'type': 'literal', 'value': 'https://github.com/jd-coderepos/cl-titles-parser'}}]","[{'code': {'type': 'literal', 'value': 'https://github.com/jd-coderepos/cl-titles-parser'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
497,Could you provide a list of models that have been tested on the Habitat 2020 Object Nav test-std benchmark dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Habitat 2020 Object Nav test-std"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9129476313504002,0.9655172413793104,"(0.9819689989089966, 0.9770004153251648, 0.9794784784317017)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123477'}, 'model_lbl': {'type': 'literal', 'value': 'SemExp'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123478'}, 'model_lbl': {'type': 'literal', 'value': 'RGBD+DD-PPO'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123477'}, 'model_lbl': {'type': 'literal', 'value': 'SemExp'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R123478'}, 'model_lbl': {'type': 'literal', 'value': 'RGBD+DD-PPO'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
498,What models are being evaluated on the Atari 2600 Name This Game dataset?,"SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Name This Game"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}
}","SELECT DISTINCT ?model ?model_lbl
WHERE {
  ?dataset       a                orkgc:Dataset;
                  rdfs:label       ?dataset_lbl.
  FILTER (str(?dataset_lbl) = ""Atari 2600 Name This Game"")
  ?benchmark      orkgp:HAS_DATASET       ?dataset;
                  orkgp:HAS_EVALUATION    ?eval.
  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.
  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.
            ?model      rdfs:label               ?model_lbl.}}",0.9129476313504002,0.9655172413793104,"(0.9817957878112793, 0.9765143394470215, 0.9791479706764221)","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124927'}, 'model_lbl': {'type': 'literal', 'value': 'IDVQ + DRSC + XNES'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}]","[{'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124913'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124914'}, 'model_lbl': {'type': 'literal', 'value': 'A3C FF (1 day) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124921'}, 'model_lbl': {'type': 'literal', 'value': 'A3C LSTM hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124916'}, 'model_lbl': {'type': 'literal', 'value': 'POP3D'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124927'}, 'model_lbl': {'type': 'literal', 'value': 'IDVQ + DRSC + XNES'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124920'}, 'model_lbl': {'type': 'literal', 'value': 'ES FF (1 hour) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124919'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124900'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN+Pop-Art noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124901'}, 'model_lbl': {'type': 'literal', 'value': 'Gorila'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124902'}, 'model_lbl': {'type': 'literal', 'value': 'Bootstrapped DQN'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124912'}, 'model_lbl': {'type': 'literal', 'value': 'A2C + SIL'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124895'}, 'model_lbl': {'type': 'literal', 'value': 'Prior hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124898'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124908'}, 'model_lbl': {'type': 'literal', 'value': 'DQN noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124911'}, 'model_lbl': {'type': 'literal', 'value': 'DQN hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124892'}, 'model_lbl': {'type': 'literal', 'value': 'Duel hs'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124897'}, 'model_lbl': {'type': 'literal', 'value': 'DDQN (tuned) noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124922'}, 'model_lbl': {'type': 'literal', 'value': 'Prior+Duel noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124894'}, 'model_lbl': {'type': 'literal', 'value': 'Prior noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124890'}, 'model_lbl': {'type': 'literal', 'value': 'C51 noop'}}, {'model': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R124891'}, 'model_lbl': {'type': 'literal', 'value': 'Duel noop'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
499,"What is the highest benchmark result achieved on the Atari 2600 Freeway dataset, including the metric and its value?","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl","SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)
WHERE {
  {
    SELECT ?metric ?metric_lbl ?value
    WHERE {
      ?dataset       a                orkgc:Dataset;
                      rdfs:label       ?dataset_lbl.
      FILTER (str(?dataset_lbl) = ""Atari 2600 Freeway"")
      ?benchmark      orkgp:HAS_DATASET       ?dataset;
                      orkgp:HAS_EVALUATION    ?eval.
      ?eval           orkgp:HAS_VALUE         ?value.
      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.
               ?metric          rdfs:label               ?metric_lbl.}
      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.
      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.
                ?model      rdfs:label               ?model_lbl.}
    }
    ORDER BY DESC(?value)
  }
}
GROUP BY ?metric ?metric_lbl",0.9679895851501508,0.9682539682539684,"(0.9822793006896973, 0.9806264638900757, 0.9814521670341492)","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '4.4'}}]","[{'metric': {'type': 'uri', 'value': 'http://orkg.org/orkg/resource/R119875'}, 'metric_lbl': {'type': 'literal', 'value': 'Score'}, 'score': {'type': 'literal', 'value': '4.4'}}]","{'exact_match': True, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'jaccard': 1.0}"
