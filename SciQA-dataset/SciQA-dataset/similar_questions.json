{
  "AQ1475": {
    "question": "Which model has achieved the highest Accuracy score on the Story Cloze Test benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the WSC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WSC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Accuracy score on the MUTAG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MUTAG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0495": {
    "question": "List the title and ID of research papers that contain a benchmark over the Penn Treebank (Word Level) dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the LAMBADA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"LAMBADA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0176": {
    "question": "What models are being evaluated on the UrbanSound8k dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0392": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ADE Corpus dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1059": {
    "question": "What is the top benchmark score and its metric on the MAZEA dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the SoMeSci dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SoMeSci\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the nuScenes dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"nuScenes\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0021": {
    "question": "What models are being evaluated on the TDMSci dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "HQ0038": {
    "question": "What is the mean capacity of a carbon-based fuel?",
    "similar_questions": [
      {
        "text": "What is the average installed capacity of all energy sources considered?",
        "sparql": "SELECT (AVG(?installed_cap_value) AS ?average_installed_cap_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43133 ?installed_capacity.\n  FILTER(REGEX(?energy_sources_labels, \"all sources\"))\n  ?installed_capacity orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?installed_cap_value)\n}"
      },
      {
        "text": "What is the average energy generation of all energy sources considered?",
        "sparql": "SELECT (AVG(?elec_gen_value) AS ?average_elec_gen_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43134 ?electricity_generation.\n  FILTER(REGEX(?energy_sources_labels, \"all sources\"))\n  ?electricity_generation orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?elec_gen_value)\n}"
      }
    ]
  },
  "AQ0566": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Russian dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-French dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-German dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1807": {
    "question": "Indicate the model that performed best in terms of Accuracy metric on the Kuzushiji-MNIST benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Error metric on the Kuzushiji-MNIST benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the Oxford-IIIT Pets benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1437": {
    "question": "Which model has achieved the highest BLEU score score on the WMT2016 Romanian-English benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest BLEU score score on the WMT2016 Russian-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest BLEU score score on the IWSLT2015 English-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1221": {
    "question": "What is the highest benchmark result achieved on the Ball in cup, catch (DMControl500k) dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Finger, spin (DMControl500k) dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the SemEval-2010 Task 8 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1803": {
    "question": "What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the VTAB-1k dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the Kinetics-600 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kinetics-600\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the WOS-5736 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-5736\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0573": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the arXiv dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the SciGEN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the GAD dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0698": {
    "question": "Can you list the metrics used to evaluate models on the TDM Tagged Corpus dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the TDMSci dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDMSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0530": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the BC5CDR-disease dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ORKG-TDM dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ESC-50 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1634": {
    "question": "What is the name of the top performing model in terms of Score score when benchmarked on the Lunar Lander (OpenAI Gym) dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the ChemProt dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the ARC (Easy) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0727": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the FSNS - Test dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the GENIA - LAS dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0435": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the ImageNet 64x64 dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the ImageNet dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the FTD dataset dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FTD dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0999": {
    "question": "What are the metrics of evaluation over the Classical music, 5 seconds at 12 kHz dataset?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Classical music, 5 seconds at 12 kHz dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Classical music, 5 seconds at 12 kHz\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What are the metrics of evaluation over the Ball in cup, catch (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1967": {
    "question": "Provide a list of papers that have utilized the Flair-TDM model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the DEQ-TrellisNet model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-TrellisNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Linear SVM model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear SVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2193": {
    "question": "Can you provide links to code used in papers that benchmark the Transformer-XL Base model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the PAR Transformer Base model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PAR Transformer Base\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the Transformer-XL (18 layers) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (18 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1743": {
    "question": "What is the best performing model benchmarking the BUCC German-to-English dataset in terms of F1 score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the IWSLT2015 German-English dataset in terms of BLEU score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the WMT2014 French-English dataset in terms of BLEU metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2064": {
    "question": "Provide a list of papers that have utilized the SAN (single) model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the LUKE (single model) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LUKE (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the BART Base (with text infilling) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BART Base (with text infilling)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0059": {
    "question": "What are the models that have been benchmarked on the ACE 2005 dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the CIFAR-100 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the WikiText-103 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-103\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1993": {
    "question": "Where can I find code references in papers that have used the PNDec model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the GRU model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GRU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the AVTS model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1956": {
    "question": "Where can I find code references in papers that have used the CATTS-XSUM model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the ST-MoE model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ST-MoE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the XLMft UDA model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLMft UDA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1369": {
    "question": "What is the top benchmark result (metric and value) over the dataset IMDb-B?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset EBM-NLP?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset CS-NER?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CS-NER\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1250": {
    "question": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot German-to-French?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-French?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Reuters RCV1/RCV2 German-to-English?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2249": {
    "question": "Where can I find code references in papers that have used the SemExp model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the XDC model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XDC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the AVTS model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0952": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Up and Down dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Gopher dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1537": {
    "question": "What is the name of the top performing model in terms of Number of params score when benchmarked on the Penn Treebank (Character Level) dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Number of params score when benchmarked on the Text8 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Validation perplexity score when benchmarked on the Penn Treebank (Word Level) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0500": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Penn Treebank (Character Level) dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Barabasi-Albert dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoNLL04 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0924": {
    "question": "What are the metrics of evaluation over the Atari 2600 Double Dunk dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Road Runner dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1806": {
    "question": "Which model has achieved the highest Top 1 Accuracy score on the ImageNet V2 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Top 5 Accuracy score on the ObjectNet benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Macro Precision score on the PWC Leaderboards (restricted) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "HQ0003": {
    "question": "What is the most common Knowledge representation method?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SciFACT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "HQ0057": {
    "question": "Where can all the data sets used in the compared studies be found?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Natural Questions dataset in terms of F1 (Long) metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 (Long)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the ChemProt dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1891": {
    "question": "What are the most commonly used benchmark datasets for the Entity Disambiguation research field?",
    "similar_questions": [
      {
        "text": "What are the most commonly used benchmark datasets for the Named entity recognition research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Named entity recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "What are the most commonly used benchmark datasets for the Phrase Extraction research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Phrase Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0503": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the BIOSSES dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Softcite dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Softcite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1745": {
    "question": "Which model has achieved the highest F1 score score on the BUCC Chinese-to-English benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest F1 score score on the BUCC French-to-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest F1 score on the AAPD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AAPD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0661": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the ImageNet ReaL dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CommonsenseQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0550": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Gibson PointGoal Navigation dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the AI-KG dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AI-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the FTD dataset dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FTD dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1214": {
    "question": "What is the top benchmark result (metric and value) over the dataset CoNLL++?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset BoolQ?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BoolQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Text8?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1498": {
    "question": "What is the best performing model benchmarking the PIQA dataset in terms of Accuracy metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the STL-10 dataset in terms of Percentage correct metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of Parameters metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Parameters\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1692": {
    "question": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Crazy Climber benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Phoenix benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Gopher benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1997": {
    "question": "Provide a list of papers that have utilized the Table-Sequence model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Depth DDPPO model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Depth DDPPO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PtGen model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PtGen\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1920": {
    "question": "Provide a list of papers that have utilized the Funnel Transformer model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Linear SVM model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear SVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Transformer-XL model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0991": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Reuters De-En dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Reuters En-De dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters En-De\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ORKG-TDM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1587": {
    "question": "Indicate the model that performed best in terms of F1 metric on the PubMed 20k RCT benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the PubMedQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMedQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of RE+ Macro F1  metric on the CoNLL04 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Macro F1 \")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2008": {
    "question": "List the code links in papers that use the DocRED-BiLSTM model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GGCNN model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GGCNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the LibSVM model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LibSVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1656": {
    "question": "What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of FLOPS metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of PARAMS metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of FLOPS metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1262": {
    "question": "What is the top benchmark result (metric and value) over the dataset AESLC?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset GAD?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GAD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset TDMSci?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TDMSci\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0554": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Oxford-IIIT Pets dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the TSE-NER dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1333": {
    "question": "What is the top benchmark score and its metric on the WOS-46985 dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the NYT24 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2273": {
    "question": "Provide a list of papers that have utilized the AcrE model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the LASER model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LASER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1503": {
    "question": "What is the best performing model benchmarking the Supervised: dataset in terms of SemEval 2013 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the ChemProt dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the SciCite dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0361": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciERC dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MultiNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "HQ0081": {
    "question": "What quantity of iron oxide was discovered on Elorza crater?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Barabasi-Albert dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "For what product minimum conversion was obtained?",
        "sparql": "SELECT ?product, ?product_label\nWHERE {\n  orkgr:R155272 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43149 ?product;\n           orkgp:P43148 ?conversion.\n  ?product rdfs:label ?product_label.\n  ?conversion rdfs:label ?conversion_label.\n}\nORDER BY ASC(xsd:float(?conversion_label))\nLIMIT 1"
      }
    ]
  },
  "AQ0314": {
    "question": "Can you list the models that have been evaluated on the VTAB-1k dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the WikiText-2 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2336": {
    "question": "Provide a list of papers that have utilized the DQN-PixelCNN model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the DQN-CTS model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN-CTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the DQN hs model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0942": {
    "question": "Can you list the metrics used to evaluate models on the Atari 2600 Freeway dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the Atari 2600 Phoenix dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the Atari 2600 Centipede dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2092": {
    "question": "List the code links in papers that use the Dynamic Coattention Networks (single model) model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the Transformer (12 layers) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (12 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the FusionNet (single model) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FusionNet (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1826": {
    "question": "Indicate the model that performed best in terms of Macro Precision metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Macro F1 metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of RE+ Macro F1  metric on the CoNLL04 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Macro F1 \")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1302": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Tennis dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Bowling dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0742": {
    "question": "What are the metrics of evaluation over the DuIE dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the SoMeSci dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SoMeSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0888": {
    "question": "List the metrics that are used to evaluate models on the Cheetah, run (DMControl500k) benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Finger, spin (DMControl500k) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Cartpole, swingup (DMControl500k) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0217": {
    "question": "Could you provide a list of models that have been tested on the Reuters RCV1/RCV2 English-to-German benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the WMT2014 German-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MLDoc Zero-Shot English-to-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "HQ0097": {
    "question": "What types of nanocarriers do have therapeutic effect?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the BC5CDR-chemical dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "How many studies do use Chloride as major anion?",
        "sparql": "SELECT COUNT(?anions_labels) AS ?chloride_count\nWHERE {\n  orkgr:R110597 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37458 ?anions.\n  ?anions rdfs:label ?anions_labels.\n  FILTER(REGEX(?anions_labels, \"Chloride\"^^xsd:string))\n}"
      }
    ]
  },
  "AQ1685": {
    "question": "What is the name of the top performing model in terms of ROUGE-2 score when benchmarked on the CL-SciSumm dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the ChemProt dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1a score when benchmarked on the MultiRC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1a\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2033": {
    "question": "List the code links in papers that use the Unsupervised NMT + weight-sharing model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GR-ConvNet model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GR-ConvNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the Transformer-XL Large model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1740": {
    "question": "Which model has achieved the highest Permuted Accuracy score on the Sequential MNIST benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Percentage error score on the MNIST benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Matched score on the MultiNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Matched\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0026": {
    "question": "Can you list the models that have been evaluated on the SciTLDR dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the SciERC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0699": {
    "question": "List the metrics that are used to evaluate models on the CommonsenseQA benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the GAD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1327": {
    "question": "What is the highest benchmark result achieved on the IMDb-M dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the HMDB51 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1037": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Scholarly entity usage detection dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the DRI Corpus dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the ACL Anthology dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACL Anthology\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0142": {
    "question": "Can you list the models that have been evaluated on the MultiNLI dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the SciERC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0759": {
    "question": "List the metrics that are used to evaluate models on the 200k Short Texts for Humor Detection benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the BIOSSES benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BIOSSES\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the ARC (Easy) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1355": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Sequential MNIST dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the MNIST dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WLPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1971": {
    "question": "Provide a list of papers that have utilized the CRF with sentence expansion model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Ours: cross-sentence ALB model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Ours: cross-sentence ALB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the BART Base (with text infilling) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BART Base (with text infilling)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1092": {
    "question": "What is the top benchmark result (metric and value) over the dataset NYT-single?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset SVHN?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SVHN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset QuAC?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QuAC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0712": {
    "question": "List the metrics that are used to evaluate models on the SciTLDR benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the SciERC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0085": {
    "question": "Can you list the models that have been evaluated on the WMT2016 English-German dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the WMT2016 German-English dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the IWSLT2014 German-English dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1603": {
    "question": "Indicate the model that performed best in terms of FLOPS metric on the CIFAR-100 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of bits/dimension metric on the CIFAR-10 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"bits/dimension\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of ROUGE-L metric on the AESLC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-L\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AESLC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1160": {
    "question": "What is the top benchmark result (metric and value) over the dataset RotoWire (Relation Generation)?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset UCF101 (finetuned)?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Kuzushiji-MNIST?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1631": {
    "question": "What is the best performing model benchmarking the Reacher, easy (DMControl100k) dataset in terms of Score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Cartpole, swingup (DMControl100k) dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Walker, walk (DMControl500k) dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0248": {
    "question": "Can you list the models that have been evaluated on the Atari 2600 Assault dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Asterix dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2342": {
    "question": "Where can I find code references in papers that have used the DQNMMCe+SR model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the DQN+SR model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN+SR\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the A2C + SIL model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C + SIL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1230": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Ball in cup, catch (DMControl100k) dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Ball in cup, catch (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the Cheetah, run (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1402": {
    "question": "What is the name of the top performing model in terms of F1 score when benchmarked on the NYT-single dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of F1 score when benchmarked on the NYT29 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT29\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1 score when benchmarked on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2083": {
    "question": "Can you provide links to code used in papers that benchmark the MEMEN (single model) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the SpERT (with overlap) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpERT (with overlap)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the SciBert (Finetune) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBert (Finetune)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2050": {
    "question": "Provide a list of papers that have utilized the MMV TSM-50x2 model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the ViT-L/16 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ViT-L/16\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Large FS-LSTM-4 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Large FS-LSTM-4\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1583": {
    "question": "Which model has achieved the highest Accuracy score on the Yelp-5 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the Yelp-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Accuracy score on the IMDb-B benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1428": {
    "question": "What is the best performing model benchmarking the WMT2016 German-English dataset in terms of BLEU score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the IWSLT2015 German-English dataset in terms of BLEU score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the WMT2014 French-English dataset in terms of BLEU metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2246": {
    "question": "Provide a list of papers that have utilized the SAC model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the LASER model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LASER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2077": {
    "question": "Provide a list of papers that have utilized the MEMEN model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the SciBERT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2152": {
    "question": "Where can I find code references in papers that have used the Past Decode Reg. + AWD-LSTM-MoS + dyn. eval. model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the VGG8B(2x) + LocalLearning + CO model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG8B(2x) + LocalLearning + CO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Cluster-Former (#C=512) model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Cluster-Former (#C=512)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1702": {
    "question": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Assault dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Venture dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1415": {
    "question": "What is the best performing model benchmarking the 200k Short Texts for Humor Detection dataset in terms of F1-score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the ChemProt dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the WebNLG dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebNLG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1977": {
    "question": "Where can I find code references in papers that have used the STREET model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the DYGIE model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DYGIE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the BiGRU model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiGRU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0156": {
    "question": "Can you list the models that have been evaluated on the enwiki8 dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the GigaWord dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GigaWord\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0407": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the SciERC dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the SciTLDR dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciTLDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1465": {
    "question": "Indicate the model that performed best in terms of Accuracy metric on the CommonsenseQA benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the WNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the MNIST benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0813": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the SQuAD2.0 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the GENIA - LAS dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0769": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the WMT2014 English-German dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the WMT2014 German-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-German dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1860": {
    "question": "Provide a list of benchmarked datasets related to the Reading Comprehension research area?",
    "similar_questions": [
      {
        "text": "Provide a list of benchmarked datasets related to the stochastic classification research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"stochastic classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Provide a list of benchmarked datasets related to the Atari Games research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Atari Games\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1388": {
    "question": "Which model has achieved the highest RE+ Micro F1 score on the CoNLL04 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest NER Micro F1 score on the ACE 2005 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest F1 score on the EBM-NLP benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2455": {
    "question": "Provide a list of papers that have utilized the XLNet (base) model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the EffNet-L2 (SAM) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EffNet-L2 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the DEQ-TrellisNet model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-TrellisNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0639": {
    "question": "List the title and ID of research papers that contain a benchmark over the Ohsumed dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0053": {
    "question": "Could you provide a list of models that have been tested on the NYT29 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the UCF101 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MPQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MPQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "HQ0043": {
    "question": "Which are 3 the most common variables for the atmosphere models?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the WSC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WSC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Which are five the most common research fields for papers?",
        "sparql": "SELECT ?research_field, ?research_field_labels\nWHERE {\n  ?papers orkgp:P30 ?research_field.\n  ?research_field rdfs:label ?research_field_labels.\n}\nORDER BY DESC(COUNT(?research_field_labels))\nLIMIT 5"
      }
    ]
  },
  "AQ2345": {
    "question": "List the code links in papers that use the DDQN-PC model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GPT-3 model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the DDRL A3C model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDRL A3C\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0638": {
    "question": "List the title and ID of research papers that contain a benchmark over the TREC-6 dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the FB15k dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FB15k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2304": {
    "question": "Can you provide links to code used in papers that benchmark the Rational DQN Average model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the Recurrent Rational DQN Average model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Recurrent Rational DQN Average\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the Multi-turn QA model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-turn QA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1678": {
    "question": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-French dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-Spanish dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of BLEU score score when benchmarked on the WMT2014 English-French dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1593": {
    "question": "Indicate the model that performed best in terms of 1-of-100 Accuracy metric on the PolyAI Reddit benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of 3-fold Accuracy metric on the UCF101 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the Oxford-IIIT Pets benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1923": {
    "question": "List the code links in papers that use the Long Short Transformer model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the Linear Transformer model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the DEQ-Transformer (small) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-Transformer (small)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1472": {
    "question": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the TriviaQA dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of EM score when benchmarked on the TriviaQA dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TriviaQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the BoolQ dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BoolQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "HQ0091": {
    "question": "What is Raman spectroscopy?",
    "similar_questions": [
      {
        "text": "What are economics subfields?",
        "sparql": "SELECT DISTINCT ?subfields, ?subfields_labels\nWHERE {\n  ?papers orkgp:P30 ?research_fields.\n  ?research_fields rdfs:label \"Economics\"^^xsd:string.\n  ?research_fields orkgp:P36 ?subfields.\n  ?subfields rdfs:label ?subfields_labels. \n}"
      },
      {
        "text": "What kind of graph does ADANA use?",
        "sparql": "SELECT ?graph ?graph_label\nWHERE {\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  FILTER(REGEX(?title, \"ADANA\"))\n  ?cont orkgp:P5008 ?graph. \n  ?graph rdfs:label ?graph_label.\n}"
      }
    ]
  },
  "AQ1244": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the DTD dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the SNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the X-Sum dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1241": {
    "question": "What is the top benchmark score and its metric on the CINIC-10 dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the NYT24 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0344": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the SemEval-2018 Task 7 dataset dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the CoNLL 2012 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the DDI extraction 2013 corpus dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0756": {
    "question": "List the metrics that are used to evaluate models on the AG News benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the GAD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1571": {
    "question": "What is the name of the top performing model in terms of F1 entity level score when benchmarked on the NCBI Disease dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of F1 score when benchmarked on the NCBI-disease dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI-disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1a score when benchmarked on the MultiRC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1a\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0525": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the NCBI-disease dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ESC-50 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2290": {
    "question": "Can you provide links to code used in papers that benchmark the GCN Hybrid model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the CeiT-T model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the SMT model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "HQ0085": {
    "question": "What data format does CHEMDNER corpus have?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CL-SciSumm dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CL-SciSumm\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Text8 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0447": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the CUB-200-2011 dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the ARC (Challenge) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the CoNLL 2012 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1976": {
    "question": "Can you provide links to code used in papers that benchmark the SEE model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the SpanRel model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpanRel\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the CATTS model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CATTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2294": {
    "question": "Provide a list of papers that have utilized the Duel hs model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the GShard model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GShard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Prior hs model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1372": {
    "question": "What is the top benchmark result (metric and value) over the dataset DocRED (Human-annotated)?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset UCF101 (finetuned)?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset HMDB51 (finetuned)?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2194": {
    "question": "Provide a list of papers that have utilized the Adaptive Input Large model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Adaptive Input Very Large model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Adaptive Input Very Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Transformer (Adaptive inputs) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (Adaptive inputs)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0259": {
    "question": "What models are being evaluated on the Atari 2600 Solaris dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Atari 2600 Gopher dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Atari 2600 Enduro dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Enduro\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0489": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SNLI dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the QNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"QNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MultiNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2046": {
    "question": "Where can I find code references in papers that have used the MMV model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the RND model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RND\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Linformer model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1273": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Centipede dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0042": {
    "question": "What are the models that have been benchmarked on the MNIST dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the NYT dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "HQ0078": {
    "question": "Where did the study with maximal geographic scale take place?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the RotoWire dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Paper Field dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Paper Field\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0409": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the WLPC dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the SciTLDR dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciTLDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0507": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the TempEval-3 dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the TSE-NER dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0064": {
    "question": "Could you provide a list of models that have been tested on the SciERC benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the MedNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the WNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1545": {
    "question": "Indicate the model that performed best in terms of F1 metric on the CoNLL 2012 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of RE Micro F1 metric on the ACE 2004 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2004\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Micro F1 metric on the HoC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0083": {
    "question": "What are the models that have been benchmarked on the WMT2014 English-German dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the IWSLT2015 English-German dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the BUCC German-to-English dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1335": {
    "question": "What is the highest benchmark result achieved on the Yelp-14 dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Yelp-2 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the HMDB51 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2309": {
    "question": "List the code links in papers that use the A3C FF (1 day) hs model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the DDQN (tuned) hs model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDQN (tuned) hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the SAN (single model) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SAN (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0141": {
    "question": "Could you provide a list of models that have been tested on the RTE benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the MPQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MPQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MRPC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MRPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1332": {
    "question": "What is the highest benchmark result achieved on the WOS-5736 dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the VTAB-1k dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"VTAB-1k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the BC5CDR dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0460": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the WebQuestions dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ADE Corpus dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0717": {
    "question": "List the metrics that are used to evaluate models on the ART/CoreSC benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the SNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0107": {
    "question": "What are the models that have been benchmarked on the Natural Questions (short) dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Natural Questions (long) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (long)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the ANLI test dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ANLI test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1105": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the WMT2014 French-English dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the BUCC Russian-to-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Italian dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1535": {
    "question": "Which model has achieved the highest Test perplexity score on the WikiText-2 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the Yelp-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest MRPC score on the SentEval benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"MRPC\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2214": {
    "question": "Where can I find code references in papers that have used the All-attention network - 18 layers model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the ResNet50 multi-grasp predictor model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ResNet50 multi-grasp predictor\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Feedback Transformer (8 layers) model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Feedback Transformer (8 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "HQ0022": {
    "question": "Does paper \"Disambiguating authors in citations on the web and authorship correlations\" employe Cosine similarity?",
    "similar_questions": [
      {
        "text": "what are the evidence and limitations of paper \"Evaluating the Use of Social Networks in Author Name Disambiguation in Digital Libraries\"?",
        "sparql": "SELECT ?evidence ?evidence_title ?limitation\nWHERE {\n  orkgr:R6751 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?paper_title.\n  ?cont orkgp:P5004 ?evidence;\n        orkgp:P5006 ?limitation.\n  ?evidence rdfs:label ?evidence_title.\n  FILTER(REGEX(STR(?paper_title), \"Evaluating the Use of Social Networks in Author Name Disambiguation in Digital Libraries\", \"i\"))\n}"
      },
      {
        "text": "What is the best performing model benchmarking the WikiText-2 dataset in terms of Validation perplexity metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0168": {
    "question": "Can you list the models that have been evaluated on the STS Benchmark dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the SciERC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the SciREX dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1710": {
    "question": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Freeway benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Gopher benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Phoenix benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0517": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the DCASE dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the GAD dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0864": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Yelp Fine-grained classification dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the AAPD dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAPD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1704": {
    "question": "Which model has achieved the highest Score score on the Atari 2600 River Raid benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Score score on the Atari 2600 Krull benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Score score on the Atari 2600 Gravitar benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1949": {
    "question": "Provide a list of papers that have utilized the BERT + BiLSTM + CRF Decoding model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the BiLSTM-CRF+ELMo model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-CRF+ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the LNN-EL/ens model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LNN-EL/ens\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1541": {
    "question": "Indicate the model that performed best in terms of Pearson Correlation metric on the MedSTS benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Pearson Correlation metric on the BIOSSES benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Pearson Correlation\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BIOSSES\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of % Test Accuracy metric on the SNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"% Test Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0570": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the WSC dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the SciGEN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the FTD dataset dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FTD dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1964": {
    "question": "List the code links in papers that use the linear-chain CRFs model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GR-ConvNet model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GR-ConvNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the Hierarchical clustering model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hierarchical clustering\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2059": {
    "question": "List the code links in papers that use the DrQA model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the KNN model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"KNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the CitClus model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CitClus\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1559": {
    "question": "Which model has achieved the highest Accuracy score on the SST-5 Fine-grained classification benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the Yelp-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Accuracy score on the IMDb-B benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0692": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the ARC-PDN dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ACL-ARC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ACL-ARC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "HQ0026": {
    "question": "Which QA benchmarks incorporating more than 10000 questions?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the QNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Matched score on the MultiNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Matched\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0932": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Berzerk dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Gopher dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0434": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Stanford Cars dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MNIST dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DRI Corpus dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0671": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the BUCC German-to-English dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the BUCC Chinese-to-English dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the MLDoc Zero-Shot English-to-Italian dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0777": {
    "question": "What are the metrics of evaluation over the Stanford Cars dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the UrbanSound8k dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UrbanSound8k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0533": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the ShARe/CLEF eHealth corpus dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the TDM Tagged Corpus dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDM Tagged Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the NYT-single dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT-single\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "HQ0099": {
    "question": "For what piezoresistive material the least response time was obtained?",
    "similar_questions": [
      {
        "text": "For what product minimum conversion was obtained?",
        "sparql": "SELECT ?product, ?product_label\nWHERE {\n  orkgr:R155272 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43149 ?product;\n           orkgp:P43148 ?conversion.\n  ?product rdfs:label ?product_label.\n  ?conversion rdfs:label ?conversion_label.\n}\nORDER BY ASC(xsd:float(?conversion_label))\nLIMIT 1"
      },
      {
        "text": "In what country was conducted research with the largest number of participants?",
        "sparql": "SELECT ?country\nWHERE {\n  orkgr:R44980 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15249 ?country;\n           orkgp:P23169 ?number_of_participants.\n}\nORDER BY DESC(?number_of_participants)\nLIMIT 1"
      }
    ]
  },
  "AQ2454": {
    "question": "List the code links in papers that use the GPT-2 (small) model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GPT-3 (Zero-Shot) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3 (Zero-Shot)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the WRN28-10 (SAM) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"WRN28-10 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0946": {
    "question": "List the metrics that are used to evaluate models on the Atari 2600 Fishing Derby benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Ice Hockey benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ice Hockey\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Private Eye benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1776": {
    "question": "What is the best performing model benchmarking the ImageNet dataset in terms of Number of params metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the enwik8 dataset in terms of Number of params metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwik8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the DTD dataset in terms of PARAMS metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DTD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0278": {
    "question": "Can you list the models that have been evaluated on the Atari 2600 Battle Zone dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Asterix dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Seaquest dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Seaquest\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2361": {
    "question": "List the code links in papers that use the BiT-M model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the KNN model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"KNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the EneRex model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EneRex\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1317": {
    "question": "What is the highest benchmark result achieved on the Atari 2600 Star Gunner dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Road Runner dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Phoenix dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2205": {
    "question": "Can you provide links to code used in papers that benchmark the NASCell model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the SpanRel model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpanRel\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the LSTM model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1980": {
    "question": "Where can I find code references in papers that have used the TCN model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the VPN model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VPN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the AVTS model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1358": {
    "question": "What is the top benchmark result (metric and value) over the dataset BUCC French-to-English?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-French?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset WMT2014 German-English?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1156": {
    "question": "What is the top benchmark result (metric and value) over the dataset SQuAD2.0?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset enwiki8?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwiki8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Text8?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1213": {
    "question": "What is the top benchmark result (metric and value) over the dataset BC2GM?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset TSE-NER?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TSE-NER\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset SVHN?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SVHN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0807": {
    "question": "List the metrics that are used to evaluate models on the Story Cloze Test benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the DROP Test benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DROP Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the BIOSSES benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BIOSSES\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "HQ0037": {
    "question": "Who has contributed to the largest number of articles about coronavirus?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the BC5CDR-disease dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What is the top benchmark score and its metric on the NCBI Disease dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI Disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0056": {
    "question": "What are the models that have been benchmarked on the DuIE dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the NYT dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the SNLI dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "HQ0031": {
    "question": "What coolant does ASTRID reactor use?",
    "similar_questions": [
      {
        "text": "What kind of graph does ADANA use?",
        "sparql": "SELECT ?graph ?graph_label\nWHERE {\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  FILTER(REGEX(?title, \"ADANA\"))\n  ?cont orkgp:P5008 ?graph. \n  ?graph rdfs:label ?graph_label.\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SQuAD1.1 dev dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1275": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Berzerk dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Gravitar dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Yars Revenge dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Yars Revenge\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0262": {
    "question": "Can you list the models that have been evaluated on the Atari 2600 Skiing dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Fishing Derby dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Crazy Climber dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Crazy Climber\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1884": {
    "question": "What are the most commonly used benchmark datasets for the Text Summarization research field?",
    "similar_questions": [
      {
        "text": "What are the most commonly used benchmark datasets for the Text Generation research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Generation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "What are the most commonly used benchmark datasets for the Document Summarization research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Document Summarization\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0958": {
    "question": "What are the metrics of evaluation over the Atari 2600 Tutankham dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Solaris dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1722": {
    "question": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Tutankham dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Venture dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0339": {
    "question": "Can you list the models that have been evaluated on the PROTEINS dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the BioASQ dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BioASQ\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the DCASE dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DCASE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1484": {
    "question": "What is the name of the top performing model in terms of F1 score when benchmarked on the Natural Questions (long) dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of RE+ Macro F1 score when benchmarked on the ADE Corpus dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1 entity level score when benchmarked on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 entity level\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC2GM\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0829": {
    "question": "What are the metrics of evaluation over the CommitmentBank dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the DCASE dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DCASE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SciFACT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2387": {
    "question": "Can you provide links to code used in papers that benchmark the BiT-M (ResNet) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the BiT-S (ResNet-152x4) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-S (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the BiT-S model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1391": {
    "question": "What is the best performing model benchmarking the ACE 2004 dataset in terms of RE+ Micro F1 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the ACE 2005 dataset in terms of RE Micro F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the CoNLL04 dataset in terms of NER Micro F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1370": {
    "question": "What is the top benchmark score and its metric on the Nottingham dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the MPQA dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MPQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the CoNLL 2012 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0689": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the STEM-ECR v1.0 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the NLP-TDMS dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2091": {
    "question": "Can you provide links to code used in papers that benchmark the Multi-Perspective Matching (single model) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the Multi-turn QA model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-turn QA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the D-NLI model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"D-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0060": {
    "question": "What models are being evaluated on the GAD dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0995": {
    "question": "What are the metrics of evaluation over the PubMed 20k RCT dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0893": {
    "question": "List the metrics that are used to evaluate models on the Gibson PointGoal Navigation benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WOS-5736 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the ACE 2005 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2005\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0559": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AAPD dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MNIST dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2452": {
    "question": "Where can I find code references in papers that have used the AxCell model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the XDC model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XDC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Linformer model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2164": {
    "question": "Can you provide links to code used in papers that benchmark the AWD-LSTM model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the AWD-LSTM-MoS model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the DocTAET-TDM model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DocTAET-TDM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0452": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the PubMedQA dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1839": {
    "question": "Name the datasets that have been used for benchmarking in the Image Classification research problem?",
    "similar_questions": [
      {
        "text": "Name the datasets that have been used for benchmarking in the Text Classification research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Name the datasets that have been used for benchmarking in the Graph Embedding research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Graph Embedding\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1236": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Gibson PointGoal Navigation dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the WOS-11967 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-11967\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the RotoWire dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1639": {
    "question": "Which model has achieved the highest Score score on the Cheetah, run (DMControl500k) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest 3-fold Accuracy score on the UCF101 (finetuned) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Macro Precision score on the PWC Leaderboards (restricted) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1119": {
    "question": "What is the top benchmark score and its metric on the Stanford Dogs dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the ChemProt dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Stanford Cars dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1505": {
    "question": "Indicate the model that performed best in terms of Senseval 2 metric on the Supervised: benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Senseval 3 metric on the Supervised: benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Senseval 3\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Supervised:\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of F1 (Short) metric on the Natural Questions benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 (Short)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1531": {
    "question": "Indicate the model that performed best in terms of Test perplexity metric on the WikiText-103 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of 3-fold Accuracy metric on the UCF101 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the WOS-11967 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-11967\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1103": {
    "question": "What is the highest benchmark result achieved on the WMT2016 English-Russian dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the WMT2014 English-French dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the BUCC Chinese-to-English dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "HQ0032": {
    "question": "What is the most common lead compound?",
    "similar_questions": [
      {
        "text": "What is the maximum sample size?",
        "sparql": "SELECT ?sample_size\nWHERE {\n  orkgr:R135371 orkgp:compareContribution ?cont.\n  ?cont orkgp:P15687 ?sample_size\n}\nORDER BY DESC(?sample_size)\nLIMIT 1"
      },
      {
        "text": "What is the most common substrate for catalysts?",
        "sparql": "SELECT ?substrate\nWHERE {\n  orkgr:R25900 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15090 ?substrate.\n}\nORDER BY DESC(COUNT(?substrate))\nLIMIT 1"
      }
    ]
  },
  "AQ1712": {
    "question": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Enduro dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Venture dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2292": {
    "question": "Provide a list of papers that have utilized the C51 noop model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the C51 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"C51\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2069": {
    "question": "Can you provide links to code used in papers that benchmark the FABIR model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the CATTS model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CATTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the SpanRel model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpanRel\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "HQ0084": {
    "question": "What is the emergency type of AMBER Alert?",
    "similar_questions": [
      {
        "text": "What kind of graph does ADANA use?",
        "sparql": "SELECT ?graph ?graph_label\nWHERE {\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  FILTER(REGEX(?title, \"ADANA\"))\n  ?cont orkgp:P5008 ?graph. \n  ?graph rdfs:label ?graph_label.\n}"
      },
      {
        "text": "What are areas of study?",
        "sparql": "SELECT DISTINCT ?areas, ?areas_labels\nWHERE {\n  orkgr:R155445 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37041 ?areas.\n  ?areas rdfs:label ?areas_labels.\n}"
      }
    ]
  },
  "AQ0799": {
    "question": "List the metrics that are used to evaluate models on the CoQA benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the PIQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the GAD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1544": {
    "question": "Indicate the model that performed best in terms of F1 metric on the OntoNotes benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of F1 metric on the QuAC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QuAC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Micro F1 metric on the HoC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0612": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Defender dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Solaris dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Gravitar dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2287": {
    "question": "Where can I find code references in papers that have used the Pointer + Coverage + EntailmentGen + QuestionGen model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the VGG8B(2x) + LocalLearning + CO model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG8B(2x) + LocalLearning + CO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Cluster-Former (#C=512) model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Cluster-Former (#C=512)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1931": {
    "question": "Provide a list of papers that have utilized the Switch Transformer model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Transformer-XL model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Linear SVM model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear SVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0013": {
    "question": "Can you list the models that have been evaluated on the CommonsenseQA dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the CommonsenseQA dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the JNLPBA dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"JNLPBA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0977": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Amazon-2 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the WikiText-103 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-103\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2337": {
    "question": "List the code links in papers that use the A3C-CTS model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the DDRL A3C model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDRL A3C\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the MMDL model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MMDL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1180": {
    "question": "What is the top benchmark score and its metric on the Hutter Prize dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Barabasi-Albert dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the MPQA dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MPQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1568": {
    "question": "Which model has achieved the highest F1 score on the CoNLL 2003 (English) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Relation F1 score on the ACE 2005 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Relation F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest BLEU score score on the IWSLT2015 English-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1804": {
    "question": "What is the name of the top performing model in terms of Params score when benchmarked on the VTAB-1k dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Number of params score when benchmarked on the Text8 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1a score when benchmarked on the MultiRC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1a\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2462": {
    "question": "Can you list benchmarked problems in the area of Artificial Intelligence?",
    "similar_questions": [
      {
        "text": "Can you list benchmarked problems in the area of Computer Sciences?",
        "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Computer Sciences\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
      },
      {
        "text": "Can you list benchmarked problems in the area of Information Science?",
        "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Information Science\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
      }
    ]
  },
  "AQ0041": {
    "question": "What are the models that have been benchmarked on the FSNS - Test dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the ANLI test dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ANLI test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the DDI dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1425": {
    "question": "What is the best performing model benchmarking the WMT2014 German-English dataset in terms of BLEU metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the WMT2014 French-English dataset in terms of BLEU metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the IWSLT2015 German-English dataset in terms of BLEU score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2355": {
    "question": "Can you provide links to code used in papers that benchmark the BiLSTM-Attention + ELMo model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the ESIM + ELMo Ensemble model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ESIM + ELMo Ensemble\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the ApproxRepSet model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ApproxRepSet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1197": {
    "question": "What is the highest benchmark result achieved on the STS Benchmark dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the SciGEN dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciGEN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the CORLL dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CORLL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2446": {
    "question": "Provide a list of papers that have utilized the Shake-Shake (SAM) model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the LUKE (single model) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LUKE (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the MEMEN  (single model) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MEMEN  (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1854": {
    "question": "What are the most commonly used benchmark datasets for the Joint Entity and Relation Extraction research field?",
    "similar_questions": [
      {
        "text": "What are the most commonly used benchmark datasets for the Named entity recognition research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Named entity recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "What are the most commonly used benchmark datasets for the Semantic Textual Similarity research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Semantic Textual Similarity\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0798": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the MultiRC dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the MultiNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2117": {
    "question": "Where can I find code references in papers that have used the SRU++ Base model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the SRU++ model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SRU++\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the A2C + SIL model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C + SIL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1706": {
    "question": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Asteroids benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Phoenix benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Alien benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Alien\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0424": {
    "question": "List the title and ID of research papers that contain a benchmark over the WMT2014 German-English dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the WMT2016 Russian-English dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the BUCC Russian-to-English dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0128": {
    "question": "What are the models that have been benchmarked on the SearchQA dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the DRI Corpus dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0852": {
    "question": "What are the metrics of evaluation over the OntoNotes dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the SentEval dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SentEval\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the WNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0955": {
    "question": "What are the metrics of evaluation over the Atari 2600 Defender dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Space Invaders dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1112": {
    "question": "What is the highest benchmark result achieved on the WMT2014 English-German dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the WMT2014 English-French dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the BUCC Chinese-to-English dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0678": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the PWC Leaderboards (restricted) dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the ARC (Challenge) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 (finetuned) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0835": {
    "question": "List the metrics that are used to evaluate models on the enwik8 benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Text8 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0850": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the TempEval-3 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the GENIA - LAS dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "HQ0017": {
    "question": "What is the most common location in the studies?",
    "similar_questions": [
      {
        "text": "What is the most common drug in the studies?",
        "sparql": "SELECT ?drug, ?drug_labels\nWHERE {\n  orkgr:R155621 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37578 ?drug.\n  ?drug rdfs:label ?drug_labels.\n}\nORDER BY DESC(COUNT(?drug))\nLIMIT 1"
      },
      {
        "text": "What is the average efficency for experiments?",
        "sparql": "SELECT AVG(?efficency_values)\nWHERE {\n  orkgr:R155266 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43156 ?efficency.\n  ?efficency rdfs:label ?efficency_labels.\n  BIND(xsd:float(?efficency_labels) AS ?efficency_values)\n}"
      }
    ]
  },
  "AQ2237": {
    "question": "Provide a list of papers that have utilized the BCN+ELMo model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the BiLSTM-CRF+ELMo model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-CRF+ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1447": {
    "question": "Indicate the model that performed best in terms of Pre-Training Dataset metric on the HMDB51 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of PRE-TRAINING DATASET metric on the DCASE benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PRE-TRAINING DATASET\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DCASE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the PubMedQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMedQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0313": {
    "question": "Can you list the models that have been evaluated on the Classical music, 5 seconds at 12 kHz dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Ball in cup, catch (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the Finger, spin (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1422": {
    "question": "Indicate the model that performed best in terms of BLEU score metric on the IWSLT2014 German-English benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of BLEU score metric on the WMT2014 German-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of BLEU metric on the WMT2016 English-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1569": {
    "question": "Indicate the model that performed best in terms of F1 metric on the BC5CDR-disease benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of 3-fold Accuracy metric on the UCF101 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the Oxford-IIIT Pets benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0948": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Skiing dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Tennis dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Enduro dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Enduro\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0618": {
    "question": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Frostbite dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Zaxxon dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Gopher dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2457": {
    "question": "Can you provide links to code used in papers that benchmark the COMET - Direct model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the ApproxRepSet model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ApproxRepSet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the LibLinear model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LibLinear\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0331": {
    "question": "Could you provide a list of models that have been tested on the BUCC Russian-to-English benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the MLDoc Zero-Shot English-to-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the WMT2014 German-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1310": {
    "question": "What is the highest benchmark result achieved on the Atari 2600 Boxing dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Phoenix dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Asterix dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1376": {
    "question": "Which model has achieved the highest F1 score score on the Penn Treebank benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest F1 score on the NYT benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest F1 score on the AAPD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AAPD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1113": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the IWSLT2015 German-English dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the BUCC Russian-to-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Chinese dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0961": {
    "question": "What are the metrics of evaluation over the Atari 2600 Frostbite dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the Atari 2600 Solaris dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1171": {
    "question": "What is the top benchmark score and its metric on the MultiNLI dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the SoMeSci dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SoMeSci\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the MRPC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MRPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0318": {
    "question": "Can you list the models that have been evaluated on the ImageNet ReaL dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the SentEval dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SentEval\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the SciREX dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1802": {
    "question": "Which model has achieved the highest Accuracy score on the Reuters En-De benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the Reuters De-En benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters De-En\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Error score on the Amazon-5 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Amazon-5\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1125": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Kinetics-600 dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the WOS-11967 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-11967\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the RotoWire dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0980": {
    "question": "List the metrics that are used to evaluate models on the Yelp-5 benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the SciERC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1985": {
    "question": "Provide a list of papers that have utilized the BART model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the GShard model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GShard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1136": {
    "question": "What is the top benchmark score and its metric on the Natural Questions (short) dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the ARC (Easy) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the DROP Test dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DROP Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1013": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Sequential CIFAR-10 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the GENIA - LAS dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1062": {
    "question": "What is the top benchmark score and its metric on the Automatically labeled Medline abstracts corpus dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the PubMedQA dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMedQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the NYT24 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1844": {
    "question": "Name the datasets that have been used for benchmarking in the citation classification research problem?",
    "similar_questions": [
      {
        "text": "Name the datasets that have been used for benchmarking in the Citation Intent Classification research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Citation Intent Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Name the datasets that have been used for benchmarking in the Text Classification research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1945": {
    "question": "List the code links in papers that use the H-NLI model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the GR-ConvNet model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GR-ConvNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the QA-GNN model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"QA-GNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0652": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the PubMed 20k RCT dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1827": {
    "question": "Indicate the model that performed best in terms of Macro Recall metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Macro F1 metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Macro Recall metric on the PWC Leaderboards (restricted) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Recall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1748": {
    "question": "What is the name of the top performing model in terms of NLL score when benchmarked on the Nottingham dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of F1a score when benchmarked on the MultiRC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1a\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Oxford 102 Flowers dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2068": {
    "question": "Where can I find code references in papers that have used the DCN model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the GRU model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GRU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the RND model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RND\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1813": {
    "question": "What is the best performing model benchmarking the iNaturalist 2018 dataset in terms of Top-1 Accuracy metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the HMDB51 (finetuned) dataset in terms of Top-1 Accuracy metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the SemEval-2010 Task 8 dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1300": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Ice Hockey dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Bowling dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1904": {
    "question": "Provide a list of benchmarked datasets related to the Scientific Results Extraction research area?",
    "similar_questions": [
      {
        "text": "Provide a list of benchmarked datasets related to the Information Extraction research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Information Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Provide a list of benchmarked datasets related to the Scientific Claim Verification research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Scientific Claim Verification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0547": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Walker, walk (DMControl500k) dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 (finetuned) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Lunar Lander (OpenAI Gym) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Lunar Lander (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1870": {
    "question": "Provide a list of benchmarked datasets related to the Semantic Role Labeling research area?",
    "similar_questions": [
      {
        "text": "Provide a list of benchmarked datasets related to the co-authorship prediction research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"co-authorship prediction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Provide a list of benchmarked datasets related to the Information Extraction research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Information Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0498": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the WikiText-2 dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoNLL04 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Yelp-2 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1021": {
    "question": "What are the metrics of evaluation over the PWC Leaderboards (restricted) dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2293": {
    "question": "List the code links in papers that use the Duel noop model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the SWWAE model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SWWAE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the PEGASUSLARGE model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PEGASUSLARGE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1903": {
    "question": "List the datasets benchmarked under the Fine-Grained Image Classification research problem?",
    "similar_questions": [
      {
        "text": "List the datasets benchmarked under the Temporal Information Extraction research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Temporal Information Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "List the datasets benchmarked under the Triples extraction research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Triples extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0721": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the DRI Corpus dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the NYT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the SciCite dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0897": {
    "question": "List the metrics that are used to evaluate models on the Oxford-IIIT Pets benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the SciERC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1742": {
    "question": "What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential CIFAR-10 dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential MNIST dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Unpermuted Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Sequential MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CINIC-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0437": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STL-10 dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the UCF101 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ARC-PDN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC-PDN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0023": {
    "question": "Could you provide a list of models that have been tested on the SciCite benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the WNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MedNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0605": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Skiing dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Fishing Derby dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Assault dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1000": {
    "question": "List the metrics that are used to evaluate models on the VTAB-1k benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WOS-5736 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WikiText-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1637": {
    "question": "What is the name of the top performing model in terms of Score score when benchmarked on the Cart Pole (OpenAI Gym) dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the PWC Leaderboards (restricted) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Macro F1 score when benchmarked on the PWC Leaderboards (restricted) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2025": {
    "question": "List the code links in papers that use the Rfa-Gate-arccos model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the Sarsa-\u03c6-EB model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sarsa-\u03c6-EB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the GR-ConvNet model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GR-ConvNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1573": {
    "question": "Indicate the model that performed best in terms of F1 metric on the ShARe/CLEF eHealth corpus benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of NER Macro F1 metric on the ADE Corpus benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of SICK-E metric on the SentEval benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SICK-E\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0797": {
    "question": "What are the metrics of evaluation over the BioASQ dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SciFACT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1698": {
    "question": "What is the best performing model benchmarking the Atari 2600 Centipede dataset in terms of Score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Breakout dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Time Pilot dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1866": {
    "question": "What are the most commonly used benchmark datasets for the Natural Language Inference research field?",
    "similar_questions": [
      {
        "text": "What are the most commonly used benchmark datasets for the Phrase Extraction research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Phrase Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "What are the most commonly used benchmark datasets for the Text Generation research field?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Generation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0299": {
    "question": "What models are being evaluated on the Classic dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the X-Sum dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"X-Sum\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Paper Field dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Paper Field\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2397": {
    "question": "Where can I find code references in papers that have used the DeiT-Ti model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the DeiT-B model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeiT-B\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the ST-MoE model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ST-MoE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "HQ0027": {
    "question": "For which country of study overall prevalence of epilepsy is the highest?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Pearson Correlation score on the STS Benchmark benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Pearson Correlation\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STS Benchmark\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Accuracy (%) score on the Hendrycks Test benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0190": {
    "question": "Can you list the models that have been evaluated on the ShARe/CLEF eHealth corpus dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the PolyAI Reddit dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0101": {
    "question": "Could you provide a list of models that have been tested on the HMDB51 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the UCF101 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MRPC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MRPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0604": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Venture dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Freeway dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Freeway\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0816": {
    "question": "List the metrics that are used to evaluate models on the Rotowire (Content Selection) benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Cartpole, swingup (DMControl500k) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Penn Treebank (Word Level) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2380": {
    "question": "Where can I find code references in papers that have used the Tsetlin Machine model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the XDC model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XDC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the Linformer model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1272": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Breakout dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Venture dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 HERO dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0963": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Bowling dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Tennis dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Kangaroo dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2321": {
    "question": "List the code links in papers that use the FQF model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the MMDL model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MMDL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the KNN model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"KNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1373": {
    "question": "Indicate the model that performed best in terms of Sequence error metric on the FSNS - Test benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the SST-2 Binary classification benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SST-2 Binary classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the MNIST benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1163": {
    "question": "What is the top benchmark result (metric and value) over the dataset ARC (Challenge)?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset OA-STM?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"OA-STM\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset NLP-TDMS?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0348": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the SciREX dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the SciGEN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0696": {
    "question": "Can you list the metrics used to evaluate models on the TSE-NER dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1939": {
    "question": "Where can I find code references in papers that have used the Concept Mention Extraction model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the DAT model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DAT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the AVTS model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2094": {
    "question": "List the code links in papers that use the OTF spelling+lemma (single) model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the Transformer Base + adversarial MLE model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer Base + adversarial MLE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the NCBI_BERT(base) (P) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NCBI_BERT(base) (P)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2315": {
    "question": "Provide a list of papers that have utilized the A3C LSTM hs model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the SciNLP-KG model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1812": {
    "question": "Which model has achieved the highest Percentage error score on the SVHN benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Percentage error score on the MNIST benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Matched score on the MultiNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Matched\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2216": {
    "question": "Where can I find code references in papers that have used the LayerNorm HM-LSTM model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the HNEABP (BWEL) model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"HNEABP (BWEL)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the AWD-LSTM-MoS + ATOI model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS + ATOI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1905": {
    "question": "List the datasets benchmarked under the SPARQL query optimization research problem?",
    "similar_questions": [
      {
        "text": "List the datasets benchmarked under the SPARQL query optimization research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"SPARQL query optimization\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "List the datasets benchmarked under the Triples extraction research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Triples extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1320": {
    "question": "What is the highest benchmark result achieved on the Amazon-2 dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the VTAB-1k dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"VTAB-1k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the BC5CDR dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2207": {
    "question": "Can you provide links to code used in papers that benchmark the Temporal Convolutional Network model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the Random Forest model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Random Forest\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the Orthogonalized Soft VSM model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Orthogonalized Soft VSM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2437": {
    "question": "Provide a list of papers that have utilized the BiT-S (ResNet) model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the BiT-M (ResNet-152x4) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-M (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the EffNet-L2 (SAM) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EffNet-L2 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1176": {
    "question": "What is the highest benchmark result achieved on the WNLI dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the CORLL dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CORLL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1245": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the AAPD dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the NYT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WLPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0002": {
    "question": "What models are being evaluated on the FTD dataset dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1664": {
    "question": "What is the best performing model benchmarking the CIFAR-10 Image Classification dataset in terms of Percentage error metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of Parameters metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Parameters\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the HMDB51 dataset in terms of Top-1 Accuracy metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1233": {
    "question": "What is the highest benchmark result achieved on the Walker, walk (DMControl500k) dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Walker, walk (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the best performing model benchmarking the Walker, walk (DMControl500k) dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0713": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the SciGEN dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the SciCite dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the NYT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2311": {
    "question": "List the code links in papers that use the POP3D model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the DDRL A3C model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDRL A3C\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the LibSVM model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LibSVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1723": {
    "question": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Tennis benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Fishing Derby benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Asterix benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0786": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the UCF101 (finetuned) dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ARC (Challenge) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ORKG-TDM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0522": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the MPQA dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the EBM-NLP dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1212": {
    "question": "What is the highest benchmark result achieved on the BC5CDR-chemical dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the BC5CDR dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the Sequential CIFAR-10 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Sequential CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1649": {
    "question": "Which model has achieved the highest SUCCESS score on the Habitat 2020 Object Nav test-std benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest SUCCESS score on the Habitat 2020 Point Nav test-std benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SUCCESS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest DISTANCE_TO_GOAL score on the Habitat 2020 Object Nav test-std benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"DISTANCE_TO_GOAL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1337": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Paper Field dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the SNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the NYT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1673": {
    "question": "Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-German benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot German-to-French benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-Russian benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1267": {
    "question": "What is the highest benchmark result achieved on the Atari 2600 Double Dunk dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Robotank dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Frostbite dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2078": {
    "question": "Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (ensemble) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the ESIM + ELMo Ensemble model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ESIM + ELMo Ensemble\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the Prior+Duel hs model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior+Duel hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1231": {
    "question": "What is the top benchmark score and its metric on the Cheetah, run (DMControl500k) dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Cartpole, swingup (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the ARC (Easy) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0511": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STS Benchmark dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the NYT29 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT29\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1286": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Alien dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Amidar dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1353": {
    "question": "What is the highest benchmark result achieved on the Birdsnap dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the SciGEN dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciGEN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0287": {
    "question": "What models are being evaluated on the Atari 2600 Chopper Command dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Atari 2600 Private Eye dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Atari 2600 Star Gunner dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1767": {
    "question": "Indicate the model that performed best in terms of Accuracy metric on the Stanford Cars benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of PARAMS metric on the Stanford Cars benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the Oxford-IIIT Pets benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1492": {
    "question": "Indicate the model that performed best in terms of Precision metric on the RotoWire (Relation Generation) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Precision metric on the Rotowire (Content Selection) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of BLEU metric on the RotoWire benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0808": {
    "question": "List the metrics that are used to evaluate models on the SQuAD1.1 benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the SQuAD2.0 dev benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WikiText-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2130": {
    "question": "Provide a list of papers that have utilized the Large mLSTM model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Longformer Large model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Longformer Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0007": {
    "question": "What models are being evaluated on the ACL Anthology dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1787": {
    "question": "Which model has achieved the highest Score score on the Atari 2600 Yars Revenge benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Score score on the Atari 2600 Frostbite benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Score score on the Atari 2600 Krull benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0182": {
    "question": "What models are being evaluated on the NCBI-disease dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the BC5CDR-disease dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Pubmed dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Pubmed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1044": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Softcite dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the SciCite dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the SNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0779": {
    "question": "What are the metrics of evaluation over the Fashion-MNIST dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the MNIST dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SciFACT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1578": {
    "question": "What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-2 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-3 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-3\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the GigaWord dataset in terms of ROUGE-1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0474": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RotoWire (Relation Generation) dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DocRED (Human-annotated) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Cartpole, swingup (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2095": {
    "question": "Can you provide links to code used in papers that benchmark the Fine-Grained Gating model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the multi-head model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"multi-head\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the SpERT model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpERT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1788": {
    "question": "What is the best performing model benchmarking the Atari 2600 Montezuma's Revenge dataset in terms of Average Return (NoOp) metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Private Eye dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Atlantis dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2295": {
    "question": "Provide a list of papers that have utilized the Prior noop model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the Prior hs model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1416": {
    "question": "What is the best performing model benchmarking the WMT2016 English-Russian dataset in terms of BLEU score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the WMT2014 French-English dataset in terms of BLEU metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the IWSLT2015 German-English dataset in terms of BLEU score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1780": {
    "question": "What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford-IIIT Pets dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the Oxford-IIIT Pets dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford 102 Flowers dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Error Rate\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0445": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters-21578 dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-5736 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the UCF101 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0157": {
    "question": "What models are being evaluated on the Penn Treebank (Character Level) dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Penn Treebank (Word Level) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the HMDB51 (finetuned) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2376": {
    "question": "Provide a list of papers that have utilized the ANODE model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the PtGen model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PtGen\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the GShard model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GShard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2426": {
    "question": "Provide a list of papers that have utilized the DY-MobileNetV3-Small model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the DY-MobileNetV2 \u00d70.75 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d70.75\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the DY-MobileNetV2 \u00d71.0 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d71.0\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1070": {
    "question": "What is the highest benchmark result achieved on the FSNS - Test dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the STL-10 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2238": {
    "question": "Where can I find code references in papers that have used the MPAD-path model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the MP-EB model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MP-EB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the XLMft UDA model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLMft UDA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0114": {
    "question": "What are the models that have been benchmarked on the BoolQ dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the SciFACT dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1357": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the BUCC German-to-English dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the BUCC Russian-to-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Italian dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1638": {
    "question": "Which model has achieved the highest Score score on the Ball in cup, catch (DMControl100k) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Score score on the Ball in cup, catch (DMControl500k) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Macro Precision score on the PWC Leaderboards (restricted) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2087": {
    "question": "List the code links in papers that use the Multi-Perspective Matching (ensemble) model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the MEMEN (ensemble) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MEMEN (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the XLNet (Large) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet (Large)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1439": {
    "question": "What is the best performing model benchmarking the ImageNet 64x64 dataset in terms of Bits per dim metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the enwik8 dataset in terms of Bit per Character (BPC) metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwik8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Text8 dataset in terms of Bit per Character (BPC) metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1144": {
    "question": "What is the top benchmark result (metric and value) over the dataset CommonsenseQA?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset CommonsenseQA?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset SciFACT?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciFACT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "HQ0046": {
    "question": "Are children examined in the studies?",
    "similar_questions": [
      {
        "text": "What is the total number of patients in the studies?",
        "sparql": "SELECT SUM(?number_of_patients)\nWHERE {\n  orkgr:R33008 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15585 ?patients.\n  BIND(xsd:integer(?patients) AS ?number_of_patients)\n}"
      },
      {
        "text": "What is the total number of species examined in the studies?",
        "sparql": "SELECT (SUM(?number) AS ?total)\nWHERE {\n  orkgr:R58002 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P31024 ?number_of_species.\n  BIND(xsd:integer(?number_of_species) AS ?number)\n}"
      }
    ]
  },
  "AQ1142": {
    "question": "What is the highest benchmark result achieved on the CoQA dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the SciGEN dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciGEN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1345": {
    "question": "What is the top benchmark score and its metric on the ImageNet V2 dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the ImageNet 64x64 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet 64x64\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the WebNLG dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebNLG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1633": {
    "question": "Which model has achieved the highest Score score on the Reacher, easy (DMControl500k) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest 3-fold Accuracy score on the UCF101 (finetuned) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Macro Precision score on the PWC Leaderboards (restricted) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0792": {
    "question": "List the metrics that are used to evaluate models on the Quasart-T benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the GAD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the SNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0097": {
    "question": "Can you list the models that have been evaluated on the Multimodal PISA dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the CommonsenseQA dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the PubMedQA dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PubMedQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0914": {
    "question": "Can you list the metrics used to evaluate models on the Barabasi-Albert dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the LAMBADA dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"LAMBADA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the Hendrycks Test dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0933": {
    "question": "Can you list the metrics used to evaluate models on the Atari 2600 Zaxxon dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the Atari 2600 Centipede dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the Atari 2600 Phoenix dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1251": {
    "question": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-Spanish?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-French?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Reuters RCV1/RCV2 English-to-German?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 English-to-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1433": {
    "question": "Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-German benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of BLEU score metric on the WMT2014 German-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of BLEU metric on the WMT2016 English-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1886": {
    "question": "Provide a list of benchmarked datasets related to the Sentence Classification research area?",
    "similar_questions": [
      {
        "text": "Provide a list of benchmarked datasets related to the Relation Classification research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Relation Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Provide a list of benchmarked datasets related to the Document Classification research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Document Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0818": {
    "question": "List the metrics that are used to evaluate models on the RotoWire (Content Ordering) benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Cartpole, swingup (DMControl500k) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Penn Treebank (Word Level) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0912": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Italian dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-German dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Chinese dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1928": {
    "question": "Provide a list of papers that have utilized the Tokenlearner model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the GShard model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GShard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Depth DDPPO model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Depth DDPPO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0159": {
    "question": "What models are being evaluated on the MedSTS dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1567": {
    "question": "What is the best performing model benchmarking the CoNLL++ dataset in terms of F1 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the SciCite dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the SciERC dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0443": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the UCF101 (finetuned) dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoNLL04 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the ARC (Easy) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0653": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SciCite dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Softcite dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Softcite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2436": {
    "question": "Can you provide links to code used in papers that benchmark the ImageNet + iNat on WS-DAN model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the AdvSoft (+ 4 layer QRNN + dynamic eval) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AdvSoft (+ 4 layer QRNN + dynamic eval)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the AWD-LSTM + dynamic eval model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM + dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1017": {
    "question": "Can you list the metrics used to evaluate models on the BUCC Russian-to-English dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the BUCC German-to-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the WMT2016 German-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1687": {
    "question": "What is the best performing model benchmarking the AESLC dataset in terms of ROUGE-1 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the GigaWord dataset in terms of ROUGE-1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-3 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-3\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1361": {
    "question": "What is the top benchmark score and its metric on the ModelNet40 dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the MUTAG dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MUTAG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the NYT24 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0735": {
    "question": "List the metrics that are used to evaluate models on the Penn Treebank benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the PIQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the GAD benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0102": {
    "question": "Could you provide a list of models that have been tested on the Reuters-21578 benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the OA-STM benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the smallNLP-KG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"smallNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1689": {
    "question": "What is the best performing model benchmarking the Atari 2600 Seaquest dataset in terms of Score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Atlantis dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Breakout dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0726": {
    "question": "What are the metrics of evaluation over the seel.cse.lsu.edu/data/re17.zip  dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the WMT2016 Czech-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the BC5CDR-disease dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0666": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ObjectNet dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the GigaWord dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GigaWord\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the GENIA - UAS dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0970": {
    "question": "List the metrics that are used to evaluate models on the Atari 2600 HERO benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Robotank benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Demon Attack benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0634": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Amazon-2 dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the NYT-single dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT-single\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2318": {
    "question": "Provide a list of papers that have utilized the Rainbow+SEER model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the JointParsing model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"JointParsing\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Depth DDPPO model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Depth DDPPO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1449": {
    "question": "What is the name of the top performing model in terms of Accuracy (High) score when benchmarked on the RACE dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Accuracy (Middle) score when benchmarked on the RACE dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (Middle)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of F1 score when benchmarked on the NYT29 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT29\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0422": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Romanian dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Russian dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2014 English-German dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1023": {
    "question": "Can you list the metrics used to evaluate models on the MUTAG dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the SciERC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the SciREX dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0861": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the ESC-50 dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1466": {
    "question": "Which model has achieved the highest F1 score on the SQuAD1.1 dev benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest F1 score on the SQuAD2.0 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest F1 score on the NYT24 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0164": {
    "question": "What models are being evaluated on the TempEval-3 dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the ESC-50 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the STL-10 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1494": {
    "question": "What is the best performing model benchmarking the RotoWire (Content Ordering) dataset in terms of BLEU metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the RotoWire (Relation Generation) dataset in terms of count metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"count\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire (Relation Generation)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the ObjectNet (Bounding Box) dataset in terms of Top 5 Accuracy metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1263": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Seaquest dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 HERO dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Pong dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0172": {
    "question": "Could you provide a list of models that have been tested on the GENIA - LAS benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the Yelp-14 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-14\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the OA-STM benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0523": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Yelp Binary classification dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the nuScenes dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"nuScenes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1761": {
    "question": "Indicate the model that performed best in terms of Accuracy metric on the Amazon benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the MPQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MPQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Accuracy metric on the 20NEWS benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"20NEWS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0607": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Bank Heist dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Double Dunk dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Double Dunk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Up and Down dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Up and Down\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1513": {
    "question": "What is the name of the top performing model in terms of A2 score when benchmarked on the ANLI test dataset?",
    "similar_questions": [
      {
        "text": "What is the name of the top performing model in terms of Mean Accuracy score when benchmarked on the ModelNet40 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Mean Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ModelNet40\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the name of the top performing model in terms of Percentage correct score when benchmarked on the CIFAR-100 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0148": {
    "question": "Could you provide a list of models that have been tested on the QNLI benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the WNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the MedNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0611": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Asterix dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Gravitar dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Solaris dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2328": {
    "question": "Can you provide links to code used in papers that benchmark the MFEC model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the MPCM model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MPCM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the LSTM model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2411": {
    "question": "Can you provide links to code used in papers that benchmark the CAIT-XS-36 model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the CAIT-S-48 model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-S-48\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the CAIT-M-24 model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-M-24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0040": {
    "question": "What models are being evaluated on the seel.cse.lsu.edu/data/re17.zip  dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Cartpole, swingup (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Cartpole, swingup (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1752": {
    "question": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Montezuma's Revenge benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 James Bond benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Phoenix benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1810": {
    "question": "What is the best performing model benchmarking the ImageNet ReaL dataset in terms of Params metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the DTD dataset in terms of PARAMS metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DTD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the SentEval dataset in terms of STS metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"STS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ2418": {
    "question": "Can you provide links to code used in papers that benchmark the ResNet-152 (SAM) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the BiLSTM-TDN(ResNet-101) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-TDN(ResNet-101)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the BiT-S (ResNet-152x4) model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-S (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1073": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Pubmed dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the MedNLI dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MedNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the PubMed 20k RCT dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMed 20k RCT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0536": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Walker, walk (DMControl100k) dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Cheetah, run (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the SemEval-2010 Task 8 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1367": {
    "question": "What is the highest benchmark result achieved on the REDDIT-B dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the SciGEN dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciGEN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the CORLL dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CORLL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0015": {
    "question": "What models are being evaluated on the Softcite dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the RotoWire dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0181": {
    "question": "Could you provide a list of models that have been tested on the SST-2 Binary classification benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the SST-5 Fine-grained classification benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SST-5 Fine-grained classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the Yelp Binary classification benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp Binary classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1134": {
    "question": "What is the top benchmark score and its metric on the Hendrycks Test dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the  Jacquard dataset dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \" Jacquard dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the DROP Test dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DROP Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2348": {
    "question": "Can you provide links to code used in papers that benchmark the KD-LSTMreg model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the S-NLI model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"S-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the D-NLI model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"D-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0379": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the NLP-TDMS dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the TSE-NER dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0209": {
    "question": "Can you list the models that have been evaluated on the ClueWeb09-B dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the NYT24 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT24\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the CINIC-10 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1029": {
    "question": "Can you list the metrics used to evaluate models on the DocRED (Human-annotated) dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the BC5CDR dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the SciREX dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2413": {
    "question": "Provide a list of papers that have utilized the CvT-21 (384 res) model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the EffNet-L2 (SAM) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EffNet-L2 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the CeiT-T (384 finetune res) model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T (384 finetune res)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2071": {
    "question": "Can you provide links to code used in papers that benchmark the FG fine-grained gate model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the Multi-turn QA model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-turn QA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the D-NLI model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"D-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1082": {
    "question": "What is the highest benchmark result achieved on the NYT29 dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the BC5CDR dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the STL-10 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0834": {
    "question": "Can you list the metrics used to evaluate models on the QNLI dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the SciERC dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1405": {
    "question": "Which model has achieved the highest Entity F1 score on the SciERC benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest F1 score on the MedNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MedNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Relation F1 score on the SciERC benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Relation F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0863": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the SST-5 Fine-grained classification dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the OA-STM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1155": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Natural Questions (long) dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the Quora Question Pairs dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the X-Sum dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1116": {
    "question": "What is the top benchmark result (metric and value) over the dataset WMT2016 Czech-English?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset WMT2014 German-English?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset IWSLT2014 German-English?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "HQ0068": {
    "question": "Which sectors are modeled as energy sectors and how often?",
    "similar_questions": [
      {
        "text": "Which countries are considered in the papers about geopolitics?",
        "sparql": "SELECT DISTINCT ?location\nWHERE {\n  ?_ orkgp:compareContribution [\n    orkgp:P32 [\n      rdfs:label ?label\n    ];\n    orkgp:P5049 ?location\n  ]\n  FILTER(REGEX(STR(?label), \"geopoli?tics\"))\n}"
      },
      {
        "text": "Which scenario factsheets from the Open Energy Platform are used in studies with public funding?",
        "sparql": "SELECT ?paper\nWHERE {\n  orkgr:R113171 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont.\n  ?cont orkgp:P37586 ?hasFacts.\n  ?hasFacts orkgp:P37675 ?study.\n  ?study orkgp:P37663 ?sourceOfFunding.\n  FILTER(REGEX(?sourceOfFunding, \"public\"))\n}"
      }
    ]
  },
  "AQ0439": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Kinetics-600 dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Barabasi-Albert dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Yelp-2 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0473": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Rotowire (Content Selection) dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DocRED (Human-annotated) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Cartpole, swingup (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "HQ0058": {
    "question": "What are the precision, recall, and f1 values of all compared studies that used the algorithm naive bayes in combination with the machine learning feature bag of words to classfy user feedback as feature request? ",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the Cornell Grasp Dataset dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0551": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Dmlab-30 dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-5736 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the UCF101 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ0425": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 German-English dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 English-German dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the IWSLT2015 English-German dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1227": {
    "question": "What is the highest benchmark result achieved on the Cartpole, swingup (DMControl500k) dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Finger, spin (DMControl500k) dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the STEM-ECR v1.0 dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0033": {
    "question": "What are the models that have been benchmarked on the Automatically labeled Medline abstracts corpus dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the DRI Corpus dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the AAPD dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAPD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2167": {
    "question": "List the code links in papers that use the LSTM (Bai et al., 2018) model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the Zhao et al. (2015) (auto-encoder) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Zhao et al. (2015) (auto-encoder)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the MEMEN (ensemble) model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MEMEN (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1240": {
    "question": "What is the top benchmark result (metric and value) over the dataset Oxford-IIIT Pets?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset GENIA - UAS?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset SciREX?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciREX\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2226": {
    "question": "Can you provide links to code used in papers that benchmark the XLNet-Large model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the XLNet model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the CeiT-T model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2385": {
    "question": "Where can I find code references in papers that have used the EfficientNetV2-L model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the EfficientNetV2-S model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the XLMft UDA model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLMft UDA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0647": {
    "question": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-46985 dataset?",
    "similar_questions": [
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-5736 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the UCF101 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1168": {
    "question": "What is the highest benchmark result achieved on the Supervised: dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the CORLL dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CORLL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the HoC dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ1514": {
    "question": "What is the best performing model benchmarking the ANLI test dataset in terms of A3 metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the STL-10 dataset in terms of Percentage correct metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the SciERC dataset in terms of F1 metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1001": {
    "question": "What are the metrics of evaluation over the iNaturalist 2019 dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the SemEval-2021 Task 11 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2021 Task 11\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the CIFAR-10 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0282": {
    "question": "What are the models that have been benchmarked on the Atari 2600 Space Invaders dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the Atari 2600 Robotank dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the Atari 2600 Phoenix dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1430": {
    "question": "Which model has achieved the highest BLEU score score on the WMT2014 English-German benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest BLEU score score on the IWSLT2015 English-German benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest BLEU score on the WMT2016 German-English benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0543": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the Cart Pole (OpenAI Gym) dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Finger, spin (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the Cheetah, run (DMControl500k) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2308": {
    "question": "Provide a list of papers that have utilized the A3C FF hs model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the SciNLP-KG model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2073": {
    "question": "Where can I find code references in papers that have used the BiDAF + Self Attention + ELMo model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the SciBERT (full data) model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT (full data)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the DQN Best model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN Best\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0874": {
    "question": "List the metrics that are used to evaluate models on the NCBI Disease benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Pubmed benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Pubmed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the PIQA benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ2203": {
    "question": "Where can I find code references in papers that have used the 6-layer QRNN model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the XLMft UDA model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLMft UDA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the A2C + SIL model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C + SIL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0301": {
    "question": "What models are being evaluated on the WOS-11967 dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the WOS-5736 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the ESC-50 dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0410": {
    "question": "List the title and ID of research papers that contain a benchmark over the NYT24 dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the FB15k dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FB15k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the SVHN dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1878": {
    "question": "Name the datasets that have been used for benchmarking in the Robot Navigation research problem?",
    "similar_questions": [
      {
        "text": "Name the datasets that have been used for benchmarking in the PointGoal Navigation research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"PointGoal Navigation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Name the datasets that have been used for benchmarking in the Humor Detection research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Humor Detection\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ0039": {
    "question": "Could you provide a list of models that have been tested on the seel.cse.lsu.edu/data/refsq17.zip benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the UCF101 (finetuned) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the DocRED (Human-annotated) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0298": {
    "question": "Could you provide a list of models that have been tested on the IMDb-M benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the EBM-NLP benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the OA-STM benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2274": {
    "question": "Where can I find code references in papers that have used the PEGASUS model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the ELMo model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the BigBird model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BigBird\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1873": {
    "question": "Provide a list of benchmarked datasets related to the Audio Classification research area?",
    "similar_questions": [
      {
        "text": "Provide a list of benchmarked datasets related to the Music Modeling research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Music Modeling\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "Provide a list of benchmarked datasets related to the stochastic classification research area?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"stochastic classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1229": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the Cart Pole (OpenAI Gym) dataset?",
    "similar_questions": [
      {
        "text": "Can you list the metrics used to evaluate models on the Cart Pole (OpenAI Gym) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cart Pole (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the Cheetah, run (DMControl100k) dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0537": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the Reacher, easy (DMControl100k) dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the RotoWire dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 (finetuned) dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1622": {
    "question": "Which model has achieved the highest MACs score on the ImageNet benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Accuracy score on the MUTAG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MUTAG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Top 5 Accuracy score on the ObjectNet benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1088": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the ACE 2005 dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the FB15k dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FB15k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the CUB-200-2011 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CUB-200-2011\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0978": {
    "question": "List the metrics that are used to evaluate models on the DBpedia benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the SNLI benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1287": {
    "question": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Enduro?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Tutankham?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Tutankham\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Video Pinball?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0837": {
    "question": "What are the metrics of evaluation over the Hutter Prize dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the MNIST dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the SoMeSci dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SoMeSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1069": {
    "question": "Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/re17.zip  dataset?",
    "similar_questions": [
      {
        "text": "Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/refsq17.zip dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/refsq17.zip\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "Can you list the metrics used to evaluate models on the seel.cse.lsu.edu/data/refsq17.zip dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/refsq17.zip\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1296": {
    "question": "What is the top benchmark score and its metric on the Atari 2600 Wizard of Wor dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Zaxxon dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ2142": {
    "question": "List the code links in papers that use the 12-layer Transformer-XL model in any benchmark?",
    "similar_questions": [
      {
        "text": "List the code links in papers that use the 24-layer Transformer-XL model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"24-layer Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "List the code links in papers that use the Transformer-XL - 24 layers model in any benchmark?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL - 24 layers\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1718": {
    "question": "What is the best performing model benchmarking the Atari 2600 Up and Down dataset in terms of Score metric?",
    "similar_questions": [
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Time Pilot dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "What is the best performing model benchmarking the Atari 2600 Breakout dataset in terms of Score metric?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0336": {
    "question": "Could you provide a list of models that have been tested on the NLP-TDMS (Exp, arXiv only) benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the UCF101 (finetuned) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the DocRED (Human-annotated) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0163": {
    "question": "What are the models that have been benchmarked on the  Jacquard dataset dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the WLPC dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the DDI dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1009": {
    "question": "What are the metrics of evaluation over the ObjectNet dataset?",
    "similar_questions": [
      {
        "text": "What are the metrics of evaluation over the ImageNet dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What are the metrics of evaluation over the enwiki8 dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"enwiki8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0492": {
    "question": "Provide a list of research paper titles and IDs that have benchmarked models on the enwik8 dataset?",
    "similar_questions": [
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the CoNLL04 dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "Provide a list of research paper titles and IDs that have benchmarked models on the EBM-NLP dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1654": {
    "question": "Indicate the model that performed best in terms of PARAMS metric on the FGVC Aircraft benchmark dataset?",
    "similar_questions": [
      {
        "text": "Indicate the model that performed best in terms of Top-1 Error Rate metric on the FGVC Aircraft benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Error Rate\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Indicate the model that performed best in terms of ROUGE-L metric on the GigaWord benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-L\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ0964": {
    "question": "List the metrics that are used to evaluate models on the Atari 2600 Battle Zone benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Demon Attack benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the Atari 2600 Robotank benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0279": {
    "question": "What are the models that have been benchmarked on the Atari 2600 Road Runner dataset?",
    "similar_questions": [
      {
        "text": "What are the models that have been benchmarked on the Atari 2600 Zaxxon dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What are the models that have been benchmarked on the Atari 2600 Krull dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0281": {
    "question": "Can you list the models that have been evaluated on the Atari 2600 Boxing dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Fishing Derby dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 James Bond dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0762": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the WMT2014 French-English dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the WMT2014 German-English dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-German dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0329": {
    "question": "Can you list the models that have been evaluated on the BUCC French-to-English dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the WMT2014 French-English dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the IWSLT2014 German-English dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2081": {
    "question": "Can you provide links to code used in papers that benchmark the BiDAF + Self Attention + ELMo (single model) model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the Transformer Big + adversarial MLE model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer Big + adversarial MLE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the Prior+Duel hs model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior+Duel hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0233": {
    "question": "What models are being evaluated on the AESLC dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the CORLL dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the BC2GM dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0645": {
    "question": "What are the titles and IDs of research papers that include a benchmark for the HoC dataset?",
    "similar_questions": [
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the GAD dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "What are the titles and IDs of research papers that include a benchmark for the WebNLG dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ2176": {
    "question": "Where can I find code references in papers that have used the PAR Transformer Large model for benchmarking purposes?",
    "similar_questions": [
      {
        "text": "Where can I find code references in papers that have used the PAR Transformer 24B model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PAR Transformer 24B\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Where can I find code references in papers that have used the A2C + SIL model for benchmarking purposes?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C + SIL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2060": {
    "question": "Can you provide links to code used in papers that benchmark the BERTwwm + SQuAD 2 model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the CMLM+LAT+4 iterations model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CMLM+LAT+4 iterations\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the BertSumExtAbs model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BertSumExtAbs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1953": {
    "question": "Provide a list of papers that have utilized the CL-Titles-Parser model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the CvT-13-NAS model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-13-NAS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0206": {
    "question": "Could you provide a list of models that have been tested on the Habitat 2020 Object Nav test-std benchmark dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Habitat 2020 Point Nav test-std dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the UCF101 (finetuned) benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0235": {
    "question": "What models are being evaluated on the Atari 2600 Name This Game dataset?",
    "similar_questions": [
      {
        "text": "What models are being evaluated on the Atari 2600 Private Eye dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "What models are being evaluated on the Atari 2600 Gopher dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ1285": {
    "question": "What is the highest benchmark result achieved on the Atari 2600 Freeway dataset, including the metric and its value?",
    "similar_questions": [
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Phoenix dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the highest benchmark result achieved on the Atari 2600 Gopher dataset, including the metric and its value?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0250": {
    "question": "Could you provide a list of models that have been tested on the Atari 2600 River Raid benchmark dataset?",
    "similar_questions": [
      {
        "text": "Could you provide a list of models that have been tested on the Atari 2600 Breakout benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Could you provide a list of models that have been tested on the Atari 2600 Gravitar benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ2221": {
    "question": "Provide a list of papers that have utilized the AlexNet, MultiGrasp model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the DEQ-TrellisNet model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-TrellisNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the Hypernetworks model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hypernetworks\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ0240": {
    "question": "Can you list the models that have been evaluated on the Atari 2600 Ms. Pacman dataset?",
    "similar_questions": [
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Asterix dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      },
      {
        "text": "Can you list the models that have been evaluated on the Atari 2600 Berzerk dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
      }
    ]
  },
  "AQ0892": {
    "question": "What evaluation metrics are commonly used when benchmarking models on the Habitat 2020 Object Nav test-std dataset?",
    "similar_questions": [
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ChemProt dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ChemProt\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "What evaluation metrics are commonly used when benchmarking models on the ORKG-TDM dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1216": {
    "question": "What is the top benchmark score and its metric on the BC5CDR-disease dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the NCBI-disease dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI-disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark score and its metric on the NCBI Disease dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI Disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  },
  "AQ0778": {
    "question": "List the metrics that are used to evaluate models on the ImageNet 64x64 benchmark dataset?",
    "similar_questions": [
      {
        "text": "List the metrics that are used to evaluate models on the Text8 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      },
      {
        "text": "List the metrics that are used to evaluate models on the WikiText-2 benchmark dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ0635": {
    "question": "List the title and ID of research papers that contain a benchmark over the DBpedia dataset?",
    "similar_questions": [
      {
        "text": "List the title and ID of research papers that contain a benchmark over the DDI dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      },
      {
        "text": "List the title and ID of research papers that contain a benchmark over the CommonsenseQA dataset?",
        "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
      }
    ]
  },
  "AQ1994": {
    "question": "Provide a list of papers that have utilized the HRLRE model and include the links to their code?",
    "similar_questions": [
      {
        "text": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Provide a list of papers that have utilized the PtGen model and include the links to their code?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PtGen\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ2277": {
    "question": "Can you provide links to code used in papers that benchmark the T-ConvS2S model?",
    "similar_questions": [
      {
        "text": "Can you provide links to code used in papers that benchmark the AWD-LSTM-MoS model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      },
      {
        "text": "Can you provide links to code used in papers that benchmark the CeiT-T model?",
        "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
      }
    ]
  },
  "AQ1733": {
    "question": "Which model has achieved the highest Score score on the Atari 2600 Q*Bert benchmark dataset?",
    "similar_questions": [
      {
        "text": "Which model has achieved the highest Best Score score on the Atari 2600 Q*Bert benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      },
      {
        "text": "Which model has achieved the highest Score score on the Atari 2600 Krull benchmark dataset?",
        "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
      }
    ]
  },
  "AQ1169": {
    "question": "What is the top benchmark score and its metric on the Words in Context dataset?",
    "similar_questions": [
      {
        "text": "What is the top benchmark score and its metric on the DROP Test dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DROP Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What are the metrics of evaluation over the Words in Context dataset?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Words in Context\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
      }
    ]
  },
  "AQ1864": {
    "question": "List the datasets benchmarked under the Common Sense Reasoning research problem?",
    "similar_questions": [
      {
        "text": "List the datasets benchmarked under the Conversational Response Selection research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Conversational Response Selection\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      },
      {
        "text": "List the datasets benchmarked under the Robotic Grasping research problem?",
        "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Robotic Grasping\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
      }
    ]
  },
  "AQ1087": {
    "question": "What is the top benchmark result (metric and value) over the dataset ACE 2004?",
    "similar_questions": [
      {
        "text": "What is the top benchmark result (metric and value) over the dataset TREC-6?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TREC-6\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      },
      {
        "text": "What is the top benchmark result (metric and value) over the dataset SciREX?",
        "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciREX\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
      }
    ]
  }
}