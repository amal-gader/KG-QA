title,question,response
Minimally Supervised Learning of Affective Events Using Discourse Relations,What is the seed lexicon?,A set of words with known polarity scores (+1 for positive events and -1 for negative events) used to assign scores to events in the training data.
Community Identity and User Engagement in a Multi-Community Landscape,Do they report results only on English data?,No.
Question Answering based Clinical Text Structuring Using Pre-trained Language Model,What data is the language model pretrained on?,Large-scale biomedical unannotated data.
LAXARY: A Trustworthy Explainable Twitter Analysis Model for Post-Traumatic Stress Disorder Assessment,Do they evaluate only on English datasets?,No.
Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal Data,Which vision-based approaches does this approach outperform?,"Bergsma and Van Durme 2011; Kiela, Vulic, and Clark 2015; Hewitt et al. 2018"
Generative Adversarial Nets for Multiple Text Corpora,Which GAN do they use?,"Energy-based GAN (Zhao et al., 2017)"
Stacked DeBERT: All Attention in Incomplete Data for Text Classification,Do they report results only on English datasets?,No.
Gunrock: A Social Bot for Complex and Engaging Long Conversations,What is the sample size of people used to measure user satisfaction?,Not explicitly stated in the snippet.
Towards Detection of Subjective Bias using Contextualized Word Embeddings,Do the authors report only on English?,No
"Sentence-Level Fluency Evaluation: References Help, But Can Be Spared!",Is ROUGE their only baseline?,"No, they also use WPSLOR as another baseline."
An empirical study on the effectiveness of images in Multimodal Neural Machine Translation,What misbehavior is identified?,None.
What Drives the International Development Agenda? An NLP Analysis of the United Nations General Debate 1970-2016,What are the country-specific drivers of international development rhetoric?,The paper examines the country-speciﬁc drivers of international development rhetoric.
QnAMaker: Data to Bot in 2 Minutes,What experiments do the authors present to validate their system?,None.
Procedural Reasoning Networks for Understanding Multimodal Procedures,What multimodality is available in the dataset?,Multimodal neural machine translation with images.
Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications,What datasets are used to evaluate this approach?,Chatbot Natural Language Understanding (NLU) Evaluation Corpus
Learning Supervised Topic Models for Classification and Regression from Crowds,what are the advantages of the proposed model?,(i) does not rely on references; (ii) can naturally be applied at the sentence level; and (iii) does not need human fluency annotations of any kind.
BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance,What models other than standalone BERT is new model compared to?,RoBERTa
Joint Entity Linking with Deep Reinforcement Learning,How fast is the model compared to baselines?,WPSLOR drastically reduces model size and training time.
Marrying Universal Dependencies and Universal Morphology,What are the main sources of recall errors in the mapping?,"Spelling mistakes, casual pronunciation, abbreviations, repeated letters, onomatopoeia, and others (e.g. ""im"" instead of ""I'm"", ""your/ur"" instead of ""you're"", etc.)"
Revisiting Low-Resource Neural Machine Translation: A Case Study,what amounts of size were used on german-english?,"P@1, P@5, P@10, P@20"
CAiRE: An End-to-End Empathetic Chatbot,What is the performance of their system?,Their system achieved an F1-score of 0.83 for the classification task.
Towards Faithfully Interpretable NLP Systems: How should we define and evaluate faithfulness?,What approaches they propose?,"They propose a more practical view of faithfulness, calling for a graded criteria that measures the extent and likelihood of an interpretation to be faithful, in practice."
Interpreting Recurrent and Attention-Based Neural Models: a Case Study on Natural Language Inference,Did they use the state-of-the-art model to analyze the attention?,"No, they used ESIM-50."
SUM-QE: a BERT-based Summary Quality Estimation Model,What are their correlation results?,Pearson correlation and mean squared error (MSE)
Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction,What benchmark datasets are used for the link prediction task?,WN18 and YAGO3-10.
Machine Translation from Natural Language to Code using Long-Short Term Memory,What additional techniques are incorporated?,"Incorporating coding syntax tree model, phrase-based word embedding, and Abstract Syntax Tree (AST) can be beneficial for improved vocabulary mapping and more accurate target code."
A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image Synthesis,Is text-to-image synthesis trained is suppervized or unsuppervized manner?,Text-to-image synthesis was mainly carried out through a search and supervised learning combined process.
Gating Mechanisms for Combining Character and Word-level Word Representations: An Empirical Study,Where do they employ feature-wise sigmoid gating?,Vector gate (vg)
Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction,"Are there datasets with relation tuples annotated, how big are datasets available?",There are two datasets available. The size of the datasets is not specified in the given snippet.
Learning High-order Structural and Attribute information by Knowledge Graph Attention Networks for Enhancing Knowledge Graph Embedding,How much better is performance of proposed method than state-of-the-art methods in experiments?,9.4 BLEU (7.2 →16.6)
A Computational Approach to Automatic Prediction of Drunk Texting,Do they report results only on English data?,No.
Answering Complex Questions Using Open Information Extraction,What corpus was the source of the OpenIE extractions?,English Gigaword fifth edition
ThisIsCompetition at SemEval-2019 Task 9: BERT is unstable for out-of-domain samples,What datasets were used?,Chatbot Natural Language Understanding (NLU) Evaluation Corpus
DENS: A Dataset for Multi-class Emotion Analysis,Which tested technique was the worst performer?,Google Text-to-Speech (TTS) - witai Speech-to-Text (STT)
Multitask Learning with CTC and Segmental CRF for Speech Recognition,Can SCRF be used to pretrain the model?,"No, CTC can be used to pretrain the neural network feature extractor."
Transfer Learning Between Related Tasks Using Expected Label Proportions,"How much more data does the model trained using XR loss have access to, compared to the fully supervised model?",Plentiful data.
The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection,What were the non-neural baselines used for the task?,None.
Hierarchical Multi-Task Natural Language Understanding for Cross-domain Conversational AI: HERMIT NLU,Which publicly available NLU dataset is used?,Chatbot Natural Language Understanding (NLU) Evaluation Corpus
Exploring Hate Speech Detection in Multimodal Publications,What models do they propose?,"They propose a graded criteria that measures the extent and likelihood of an interpretation to be faithful, in practice."
Self-Taught Convolutional Neural Networks for Short Text Clustering,What were the evaluation metrics used?,"SLOR, WP-SLOR, ROUGE-LM, and traditional word-overlap metrics."
Solving Arithmetic Word Problems Automatically Using Transformer and Unambiguous Representations,Does pre-training on general text corpus improve performance?,No.
CamemBERT: a Tasty French Language Model,What is CamemBERT trained on?,CamemBERT is trained on the Masked Language Modeling (MLM) task.
Semantic Sentiment Analysis of Twitter Data,What is the current SOTA for sentiment analysis on Twitter at the time of writing?,SemEval-2015 task 10
Learning to Create Sentence Semantic Relation Graphs for Multi-Document Summarization,How big is dataset domain-specific embedding are trained on?,64 words
A Deep Neural Architecture for Sentence-level Sentiment Classification in Twitter Social Networking,What were their results on the three datasets?,Their results are presented in Table 3.
Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding,Which knowledge graph completion tasks do they experiment with?,Link prediction in knowledge graphs.
Learning with Noisy Labels for Sentence-level Sentiment Classification,How does the model differ from Generative Adversarial Networks?,"This paper extends GANs to multiple text corpora, whereas traditional GANs are typically applied to a single corpus."
Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic Text Exchange,Does the model proposed beat the baseline models for all the values of the masking parameter tested?,No.
CN-CELEB: a challenging Chinese speaker recognition dataset,What was the performance of both approaches on their dataset?,Both SLOR and WP-SLOR correlated significantly better with fluency ratings for the outputs of compression systems than traditional word-overlap metrics.
Open Named Entity Modeling from Embedding Distribution,What is their model?,NLP system
Efficient Twitter Sentiment Classification using Subjective Distant Supervision,What previously proposed methods is this method compared against?,post-hoc text generation
Low-Level Linguistic Controls for Style Transfer and Content Preservation,Is this style generator compared to some baseline?,Yes.
Incorporating Sememes into Chinese Definition Modeling,Is there an online demo of their system?,No
RobBERT: a Dutch RoBERTa-based Language Model,What data did they use?,They used Twitter Sentiment Classification dataset.
Query-oriented text summarization based on hypergraph transversals,How does the model compare with the MMR baseline?,The model outperforms the MMR baseline.
Text-based inference of moral sentiment change,Does the paper discuss previous models which have been applied to the same task?,Yes.
Bringing Stories Alive: Generating Interactive Fiction Worlds,How well did the system do?,It is possible to satisfy one of these properties (plausibility and faithfulness) without the other.
Generating Classical Chinese Poems from Vernacular Chinese,What are some guidelines in writing input vernacular so model can generate ,guidelines on how to write the input vernacular to generate better poems.
Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever,What were the evaluation metrics?,"SLOR, WP-SLOR, ROUGE-LM"
Can neural networks understand monotonicity reasoning?,Do they release MED?,No
Synchronising audio and ultrasound by learning cross-modal embeddings,Do they compare their neural network against any other model?,No.
wav2vec: Unsupervised Pre-training for Speech Recognition,Which unlabeled data do they pretrain with?,They don't mention unlabeled data.
"Cross-lingual, Character-Level Neural Morphological Tagging",How are character representations from various languages joint?,They are concatenated.
Neural Cross-Lingual Relation Extraction Based on Bilingual Word Embedding Mapping,Do they train their own RE model?,No
Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation,Did the collection process use a WoZ method?,No.
Analysis of Risk Factor Domains in Psychosis Patient Health Records,What additional features are proposed for future work?,None.
Deja-vu: Double Feature Presentation and Iterated Loss in Deep Transformer Networks,Do they normalize the calculated intermediate output hypotheses to compensate for the incompleteness?,No.
Dense Information Flow for Neural Machine Translation,what are the baselines?,HELP
Frozen Binomials on the Web: Word Ordering and Language Conventions in Online Text,How is order of binomials tracked across time?,"Academic treatment of binomial orderings dates back more than a century to Jespersen [11], who proposed in 1905 that the ordering of many common English binomials could be predicted by the rhythm of the words."
Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation,Does this approach perform better in the multi-domain or single-domain setting?,No information is provided to determine whether this approach performs better in the multi-domain or single-domain setting.
Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology,Why does not the approach from English work on other languages?,Not mentioned in this snippet.
Representation of Constituents in Neural Language Models: Coordination Phrase as a Case Study,What is the performance achieved by the model described in the paper?,The model correlates better with human judgments than traditional word-overlap metrics.
Investigating Linguistic Pattern Ordering in Hierarchical Natural Language Generation,What evaluation metrics are used?,"SLOR, WP-SLOR, ROUGE-LM, and traditional word-overlap metrics."
Gender Bias in Coreference Resolution,Which coreference resolution systems are tested?,None.
A Novel Aspect-Guided Deep Transition Model for Aspect Based Sentiment Analysis,How big is the improvement over the state-of-the-art results?,9.4 BLEU (7.2 →16.6)
HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization,Is the baseline a non-heirarchical model like BERT?,No.
The Role of Pragmatic and Discourse Context in Determining Argument Impact,How better are results compared to baseline models?,"StyleEQ model has a classification accuracy above 75% (the base rate from the test data), but in terms of fluency, both models have scores around 3, with the Baseline model having slightly higher fluency scores."
Emotion helps Sentiment: A Multi-task Model for Sentiment and Emotion Analysis,What was their result on Stance Sentiment Emotion Corpus?,Their F1-score was 0.83
Mapping (Dis-)Information Flow about the MH17 Plane Crash,How can the classifier facilitate the annotation task for human annotators?,Not mentioned in the given text.
Predictive Embeddings for Hate Speech Detection on Twitter,Do they report results only on English data?,No.
An Analysis of Visual Question Answering Algorithms,From when are many VQA datasets collected?,2014
Overcoming the Rare Word Problem for Low-Resource Language Pairs in Neural Machine Translation,Are synonymous relation taken into account in the Japanese-Vietnamese task?,Yes.
"What Gets Echoed? Understanding the""Pointers""in Explanations of Persuasive Arguments",What non-contextual properties do they refer to?,linguistic characteristics of a claim
Automatic Reminiscence Therapy for Dementia.,How is performance of this system measured?,"Evaluation metrics such as SLOR, WP-SLOR, ROUGE-LM, and word-overlap metrics are used to measure the performance of the fluency evaluation system."
Lattice CNNs for Matching Based Chinese Question Answering,How do they obtain word lattices from words?,"They approach this through an existing lookup vocabulary, which contains frequent words in BaiduBaike."
Speaker-independent classification of phonetic segments from raw ultrasound in child speech,Do they report results only on English data?,No
Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data,What is the baseline model for the agreement-based mode?,LSTM (1B)
Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining,By how much do they outperform existing state-of-the-art VQA models?,Not provided in this snippet.
Testing the Generalization Power of Neural Network Models Across NLI Benchmarks,Which training dataset allowed for the best generalization to benchmark sets?,None of the training datasets allowed for good generalization.
Joint Learning of Sentence Embeddings for Relevance and Entailment,what were the baselines?,There is no mention of baselines in the provided context.
Aspect Term Extraction with History Attention and Selective Transformation,How do they determine the opinion summary?,Opinion summary is determined as the linear combination of the opinion representations generated from LSTM.
Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset,What is the average number of turns per dialog?,23
Improving Character-based Decoding Using Target-Side Morphological Information for Neural Machine Translation,How are the auxiliary signals from the morphology table incorporated in the decoder?,They are used as an extra output channel.
Learning Twitter User Sentiments on Climate Change with Limited Labeled Data,Do they report results only on English data?,No.
Uncover Sexual Harassment Patterns from Personal Stories by Joint Key Element Extraction and Categorization,What is the size of the dataset?,Not mentioned.
Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding,Does the performance increase using their method?,No.
What we write about when we write about causality: Features of causal statements across large-scale social discourse,How do they extract causality from text?,"They use various methods such as text mining, iterative topic modeling with time series feedback, and visual adaptation of perception."
Multi-style Generative Reading Comprehension,How do they measure the quality of summaries?,"They use five criteria: Grammaticality, Non redundancy, Referential Clarity, Focus, and Structure & Coherence."
A Cascade Sequence-to-Sequence Model for Chinese Mandarin Lip Reading,What was the previous state of the art model for this task?,phrase-based word embedding
Dissecting Content and Context in Argumentative Relation Analysis,Do they report results only on English data?,No.
Efficient Attention using a Fixed-Size Memory Representation,Which baseline methods are used?,BiDAF
Team Papelo: Transformer Networks at FEVER,How big is their training set?,"8.8k questions with 182k question-sentence pairs for DBQA, and 14.3k questions with 273k question-predicate pairs for KBRE."
Automatic Differentiation in ROOT,How is correctness of automatic derivation proved?,It is not mentioned in the given text snippet.
Spectral decomposition method of dialog state tracking via collective matrix factorization,What state-of-the-art models are compared against?,BERT model
Torch-Struct: Deep Structured Prediction Library,Does API provide ability to connect to models written in some other deep learning framework?,No
Embedding Projection for Targeted Cross-Lingual Sentiment: Model Comparisons and a Real-World Study,what baseline do they compare to?,They don't mention comparing to any baseline.
Improving Open Information Extraction via Iterative Rank-Aware Learning,How does this compare to traditional calibration methods like Platt Scaling?,This method is more accurate than traditional calibration methods like Platt Scaling.
Detecting Online Hate Speech Using Context Aware Models,How do they combine the models?,"They use multi-task learning to consider RC, passage ranking, and answer possibility classification together."
"Plan, Write, and Revise: an Interactive System for Open-Domain Story Generation",How is human interaction consumed by the model?,"Human interaction is consumed by the model through user input, which is lowercased and tokenized to match the model training data. The model then generates output based on this input, and the user can interact with the generated text by inserting their own text, removing generated text, or regenerating sentences."
Collecting Indicators of Compromise from Unstructured Text of Cybersecurity Articles using Neural-Based Sequence Labelling,What is used a baseline?,Nothing.
Polysemy Detection in Distributed Representation of Word Sense,How is the fluctuation in the sense of the word and its neighbors measured?,Volatility.
Neural Domain Adaptation for Biomedical Question Answering,"Among various transfer learning techniques, which technique yields to the best performance?",XR training using our method.
MMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension,How big are improvements of MMM over state of the art?,16.9%
Modeling Event Background for If-Then Commonsense Reasoning Using Context-aware Variational Autoencoder,How do they measure the diversity of inferences?,They don't mention how to measure the diversity of inferences.
Comparing Human and Machine Errors in Conversational Speech Transcription,what standard speech transcription pipeline was used?,None.
Identifying and Understanding User Reactions to Deceptive and Trusted Social News Sources,How is speed measured?,Speed is not mentioned in the given context.
Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing,Do they evaluate the quality of the paraphrasing model?,No.
"Characterizing Diabetes, Diet, Exercise, and Obesity Comments on Twitter",Do they evaluate only on English data?,No.
FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow,Does this model train faster than state of the art models?,Yes.
On Leveraging the Visual Modality for Neural Machine Translation,What is result of their attention distribution analysis?,They found that the three attention maps are fairly similar despite the completely different decisions.
Learning to Recover Reasoning Chains for Multi-Hop Question Answering via Cooperative Games,What are two models' architectures in proposed solution?,"Two models' architectures are not explicitly mentioned in the provided snippet. However, it mentions an additional ""generator"" component that outputs a textual explanation of the model's decision."
A Set of Recommendations for Assessing Human-Machine Parity in Language Translation,What empricial investigations do they reference?,Miller (2018)
Effective Use of Transformer Networks for Entity Tracking,Do they report results only on English?,No.
Recognizing Musical Entities in User-generated Content,What are their results on the entity recognition task?,"Their model performs surprisingly well, nearly as well as the first occurrence baseline."
MIT-QCRI Arabic Dialect Identification System for the 2017 Multi-Genre Broadcast Challenge,What is the architecture of the siamese neural network?,"Symmetrical component to extract high level features from different input channels, which share parameters and map inputs to the same vector space."
Bias in Semantic and Discourse Interpretation,What factors contribute to interpretive biases according to this research?,"The framework developed in this research provides tools for understanding and analyzing the range of interpretive biases, but it does not specify what factors contribute to them."
QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships,How does the QuaSP+Zero model work?,It uses an entity-linking approach applied to properties.
Indiscapes: Instance Segmentation Networks for Layout Parsing of Historical Indic Manuscripts,What accuracy does CNN model achieve?,0.373
Evaluating Rewards for Question Generation Models,What human evaluation metrics were used in the paper?,Human-targeted metrics for machine translation.
Deep contextualized word representations for detecting sarcasm and irony,Do they evaluate only on English?,No.
Phonetic Feedback for Speech Enhancement With and Without Parallel Speech Data,Which frozen acoustic model do they use?,None.
Assessing the Efficacy of Clinical Sentiment Analysis and Topic Extraction in Psychiatric Readmission Risk Prediction,What features are used?,linguistic characteristic of a claim and its context
Analysing Coreference in Transformer Outputs,What translationese effects are seen in the analysis?,MT artefacts remaining even after manual post-editing.
NumNet: Machine Reading Comprehension with Numerical Reasoning,what are the existing models they compared with?,BERT model without context and BERT model with flat context representation.
Learning Representations of Emotional Speech with Deep Convolutional Generative Adversarial Networks,What model achieves state of the art performance on this task?,BERT-Base
Cohesion and Coalition Formation in the European Parliament: Roll-Call Votes and Twitter Activities,Do the authors mention any possible confounds in their study?,No
Grounding the Semantics of Part-of-Day Nouns Worldwide using Twitter,How many languages are included in the tweets?,No specific number of languages is mentioned.
QA4IE: A Question Answering based Framework for Information Extraction,What QA models were used?,Scoremul and Scoreavg.
Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation,What baseline is used to compare the experimental results against?,HELP
Microsoft Research Asia's Systems for WMT19,What is their best performance on the largest language direction dataset?,Their best performance on the largest language direction dataset is 98.6%
Few-shot Natural Language Generation for Task-Oriented Dialog,What was the criteria for human evaluation?,"RE Match, Fluency, Sentiment"
Finding Street Gang Members on Twitter,Do they evaluate only on English datasets?,No.
A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts,What is English mixed with in the TRAC dataset?,German station and street names.
An Emotional Analysis of False Information in Social Media and News Articles,What is the baseline?,"There is no mention of a ""baseline"" in the provided context."
STransE: a novel embedding model of entities and relationships in knowledge bases,What scoring function does the model use to score triples?,"fr(h,t) = ∥Wr,1h + r −Wr,2t∥ℓ1/2"
Identifying Clickbait: A Multi-Strategy Approach Using Neural Networks,What are the differences with previous applications of neural networks for this task?,Simple models can outperform or closely match performance of complex architectures; all the models considered are task-independent and were successfully used in different contexts than Hypothesis Evaluation.
